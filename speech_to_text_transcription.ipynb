{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCmjcOc9yEtQ"
      },
      "source": [
        "# Speech-to-Text | Get transcription with speakers (OpenAI Whisper + NeMo Speaker Diarization)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Author: [Pierre GUILLOU]()\n",
        "- Full Credit: this notebook is just an update of the notebook [Whisper_Transcription_%2B_NeMo_Diarization.ipynb](https://github.com/MahmoudAshraf97/whisper-diarization/blob/main/Whisper_Transcription_%2B_NeMo_Diarization.ipynb) of [Mahmoud Ashraf](https://github.com/MahmoudAshraf97) (all texts were kept)\n",
        "- Date: 07/12/2023\n",
        "- Blog post: [Speech-to-Text | Get transcription WITH SPEAKERS from large audio file in any language (OpenAI Whisper + NeMo Speaker Diarization)](https://medium.com/@pierre_guillou/speech-to-text-get-transcription-with-speakers-from-large-audio-file-in-any-language-openai-8da2312f1617)"
      ],
      "metadata": {
        "id": "Jz8FNiwFs8t2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "OKwioL2-uXYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[source: from [Mahmoud Ashraf](https://github.com/MahmoudAshraf97)] This notebook combines Whisper ASR capabilities with Voice Activity Detection (VAD) and Speaker Embedding to identify the speaker for each sentence in the transcription generated by Whisper. First, the vocals are extracted from the audio to increase the speaker embedding accuracy, then the transcription is generated using Whisper, then the timestamps are corrected and aligned using WhisperX to help minimize diarization error due to time shift. The audio is then passed into MarbleNet for VAD and segmentation to exclude silences, TitaNet is then used to extract speaker embeddings to identify the speaker for each segment, the result is then associated with the timestamps generated by WhisperX to detect the speaker for each word based on timestamps and then realigned using punctuation models to compensate for minor time shifts."
      ],
      "metadata": {
        "id": "wgx3_w9fucEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WARNING"
      ],
      "metadata": {
        "id": "3qcWPp6wvAJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This notebook runs on (free) Google Colab.\n",
        "- It was tested on GPU T4."
      ],
      "metadata": {
        "id": "3laKzNa2vDsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "bLs16T49rZbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s-55Dx_4GOJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check there is at least a T4 GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOB8S4ASuxq-",
        "outputId": "a1814ed7-691b-4472-9f11-241be539233d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Aug 26 02:17:09 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Dependencies"
      ],
      "metadata": {
        "id": "3SXrfNF3vzaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installing the libraries, it is necessary to restart the runtime (session) in Google Colab."
      ],
      "metadata": {
        "id": "b3AAqk7Mvo40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tn1c-CoDv2kw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/m-bain/whisperX.git@a5dca2cc65b1a37f32a347e574b2c56af3a7434a\n",
        "!pip install --no-build-isolation nemo_toolkit[asr]==1.21.0\n",
        "!pip install git+https://github.com/facebookresearch/demucs#egg=demucs\n",
        "!pip install deepmultilingualpunctuation\n",
        "!pip install wget pydub\n",
        "# !pip install --force-reinstall torch torchaudio torchvision\n",
        "# !pip uninstall -y nvidia-cudnn-cu12\n",
        "!pip install numba==0.58.0\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install whisperx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeosdTaZysrY",
        "outputId": "6230a988-0ed3-4fcf-cc28-98719adbcca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting whisperx\n",
            "  Downloading whisperx-3.1.5-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from whisperx) (2.0.1)\n",
            "Requirement already satisfied: torchaudio>=2 in /usr/local/lib/python3.10/dist-packages (from whisperx) (2.0.2)\n",
            "Collecting faster-whisper==1.0.1 (from whisperx)\n",
            "  Downloading faster_whisper-1.0.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from whisperx) (4.33.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from whisperx) (2.1.4)\n",
            "Requirement already satisfied: setuptools>=65 in /usr/local/lib/python3.10/dist-packages (from whisperx) (71.0.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from whisperx) (3.8.1)\n",
            "Collecting pyannote.audio==3.1.1 (from whisperx)\n",
            "  Downloading pyannote.audio-3.1.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting av==11.* (from faster-whisper==1.0.1->whisperx)\n",
            "  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper==1.0.1->whisperx)\n",
            "  Downloading ctranslate2-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.1->whisperx) (0.23.5)\n",
            "Requirement already satisfied: tokenizers<0.16,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.1->whisperx) (0.13.3)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper==1.0.1->whisperx)\n",
            "  Downloading onnxruntime-1.19.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting asteroid-filterbanks>=0.4 (from pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx) (0.8.0)\n",
            "Collecting lightning>=2.0.1 (from pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx) (5.1.0)\n",
            "Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx) (3.2.1)\n",
            "Collecting pyannote.pipeline>=3.0.1 (from pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading pyannote.pipeline-3.0.1-py3-none-any.whl.metadata (897 bytes)\n",
            "Collecting pytorch-metric-learning>=2.1.0 (from pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading pytorch_metric_learning-2.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx) (13.7.1)\n",
            "Collecting semver>=3.0.0 (from pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx) (0.12.1)\n",
            "Collecting speechbrain>=0.5.14 (from pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading speechbrain-1.0.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting tensorboardX>=2.6 (from pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting torch-audiomentations>=0.11.0 (from pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading torch_audiomentations-0.11.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx) (1.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=2->whisperx) (0.44.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2->whisperx) (3.30.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=2->whisperx) (18.1.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx) (4.66.5)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx) (2024.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx) (0.4.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==1.0.1->whisperx) (2024.6.1)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (0.11.6)\n",
            "INFO: pip is looking at multiple versions of lightning to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting lightning>=2.0.1 (from pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (2.0.7)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio==3.1.1->whisperx) (4.9.3)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper==1.0.1->whisperx)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.1->whisperx) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.1->whisperx) (3.20.3)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx) (1.13.1)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx) (0.12.4)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (1.3.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (3.7.1)\n",
            "Collecting optuna>=3.1 (from pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->whisperx) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx) (2.16.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx) (1.17.0)\n",
            "Collecting hyperpyyaml (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx) (0.1.99)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->whisperx) (1.3.0)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.2.7)\n",
            "Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.10.2.post1)\n",
            "Collecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading torch_pitch_shift-1.2.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->whisperx) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx) (2024.7.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (3.10.5)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (3.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.58.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.4.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (1.0.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio==3.1.1->whisperx) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (3.1.2)\n",
            "Collecting alembic>=1.5.0 (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx) (2.0.32)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx) (3.5.0)\n",
            "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx) (1.5.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==1.0.1->whisperx)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx) (0.18.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote.audio==3.1.1->whisperx) (4.0.3)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx) (4.2.2)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx) (0.2.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx) (3.0.3)\n",
            "Downloading whisperx-3.1.5-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faster_whisper-1.0.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.audio-3.1.1-py2.py3-none-any.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.7/208.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
            "Downloading ctranslate2-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (192.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.3/192.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.3.3-py3-none-any.whl (808 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyannote.pipeline-3.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading pytorch_metric_learning-2.6.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading speechbrain-1.0.0-py3-none-any.whl (760 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.1/760.1 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_audiomentations-0.11.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pitch_shift-1.2.4-py3-none-any.whl (4.9 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
            "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: primePy, tensorboardX, semver, Mako, humanfriendly, ctranslate2, colorlog, av, hyperpyyaml, coloredlogs, alembic, optuna, onnxruntime, faster-whisper, pyannote.pipeline, torch-pitch-shift, torch-audiomentations, speechbrain, pytorch-metric-learning, lightning, asteroid-filterbanks, pyannote.audio, whisperx\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 asteroid-filterbanks-0.4.0 av-11.0.0 coloredlogs-15.0.1 colorlog-6.8.2 ctranslate2-4.3.1 faster-whisper-1.0.1 humanfriendly-10.0 hyperpyyaml-1.2.2 lightning-2.3.3 onnxruntime-1.19.0 optuna-3.6.1 primePy-1.3 pyannote.audio-3.1.1 pyannote.pipeline-3.0.1 pytorch-metric-learning-2.6.0 semver-3.0.2 speechbrain-1.0.0 tensorboardX-2.6.2.2 torch-audiomentations-0.11.1 torch-pitch-shift-1.2.4 whisperx-3.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESTART the runtime now!**"
      ],
      "metadata": {
        "id": "VQ8dccH7vsyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "YvJ3VVUOv14T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wget"
      ],
      "metadata": {
        "id": "RHTW4AephJfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzhncHP0ytbQ",
        "outputId": "745e5c7f-dea9-4d9e-d7f4-eb5585322e2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:speechbrain.utils.train_logger:torchvision is not available - cannot save figures\n",
            "[NeMo W 2024-08-26 02:26:15 transformer_bpe_models:59] Could not import NeMo NLP collection which is required for speech translation model.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# import wget\n",
        "from omegaconf import OmegaConf\n",
        "import json\n",
        "import shutil\n",
        "from faster_whisper import WhisperModel\n",
        "import whisperx\n",
        "import torch\n",
        "from pydub import AudioSegment\n",
        "from nemo.collections.asr.models.msdd_models import NeuralDiarizer\n",
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "import re\n",
        "import logging\n",
        "import nltk\n",
        "from whisperx.alignment import DEFAULT_ALIGN_MODELS_HF, DEFAULT_ALIGN_MODELS_TORCH\n",
        "from whisperx.utils import LANGUAGES, TO_LANGUAGE_CODE\n",
        "\n",
        "import unidecode\n",
        "from unidecode import unidecode\n",
        "import pathlib\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbsUt3SwyhjD"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se6Hc7CZygxu"
      },
      "outputs": [],
      "source": [
        "punct_model_langs = [\n",
        "    \"en\",\n",
        "    \"fr\",\n",
        "    \"de\",\n",
        "    \"es\",\n",
        "    \"it\",\n",
        "    \"nl\",\n",
        "    \"pt\",\n",
        "    \"bg\",\n",
        "    \"pl\",\n",
        "    \"cs\",\n",
        "    \"sk\",\n",
        "    \"sl\",\n",
        "]\n",
        "wav2vec2_langs = list(DEFAULT_ALIGN_MODELS_TORCH.keys()) + list(\n",
        "    DEFAULT_ALIGN_MODELS_HF.keys()\n",
        ")\n",
        "\n",
        "whisper_langs = sorted(LANGUAGES.keys()) + sorted(\n",
        "    [k.title() for k in TO_LANGUAGE_CODE.keys()]\n",
        ")\n",
        "\n",
        "\n",
        "def create_config(output_dir, DOMAIN_TYPE = \"telephonic\"):\n",
        "    # DOMAIN_TYPE: can be meeting, telephonic, or general based on domain type of the audio file\n",
        "    CONFIG_FILE_NAME = f\"diar_infer_{DOMAIN_TYPE}.yaml\"\n",
        "    CONFIG_URL = f\"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/{CONFIG_FILE_NAME}\"\n",
        "    MODEL_CONFIG = os.path.join(output_dir, CONFIG_FILE_NAME)\n",
        "    if not os.path.exists(MODEL_CONFIG):\n",
        "        MODEL_CONFIG = wget.download(CONFIG_URL, output_dir)\n",
        "\n",
        "    config = OmegaConf.load(MODEL_CONFIG)\n",
        "\n",
        "    data_dir = os.path.join(output_dir, \"data\")\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    meta = {\n",
        "        \"audio_filepath\": os.path.join(output_dir, \"mono_file.wav\"),\n",
        "        \"offset\": 0,\n",
        "        \"duration\": None,\n",
        "        \"label\": \"infer\",\n",
        "        \"text\": \"-\",\n",
        "        \"rttm_filepath\": None,\n",
        "        \"uem_filepath\": None,\n",
        "    }\n",
        "    with open(os.path.join(data_dir, \"input_manifest.json\"), \"w\") as fp:\n",
        "        json.dump(meta, fp)\n",
        "        fp.write(\"\\n\")\n",
        "\n",
        "    pretrained_vad = \"vad_multilingual_marblenet\"\n",
        "    pretrained_speaker_model = \"titanet_large\"\n",
        "    config.num_workers = 0  # Workaround for multiprocessing hanging with ipython issue\n",
        "    config.diarizer.manifest_filepath = os.path.join(data_dir, \"input_manifest.json\")\n",
        "    config.diarizer.out_dir = (\n",
        "        output_dir  # Directory to store intermediate files and prediction outputs\n",
        "    )\n",
        "\n",
        "    config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
        "    config.diarizer.oracle_vad = (\n",
        "        False  # compute VAD provided with model_path to vad config\n",
        "    )\n",
        "    config.diarizer.clustering.parameters.oracle_num_speakers = False\n",
        "\n",
        "    # Here, we use our in-house pretrained NeMo VAD model\n",
        "    config.diarizer.vad.model_path = pretrained_vad\n",
        "    config.diarizer.vad.parameters.onset = 0.8\n",
        "    config.diarizer.vad.parameters.offset = 0.6\n",
        "    config.diarizer.vad.parameters.pad_offset = -0.05\n",
        "    config.diarizer.msdd_model.model_path = (\n",
        "        \"diar_msdd_telephonic\"  # Telephonic speaker diarization model\n",
        "    )\n",
        "\n",
        "    return config\n",
        "\n",
        "\n",
        "def get_word_ts_anchor(s, e, option=\"start\"):\n",
        "    if option == \"end\":\n",
        "        return e\n",
        "    elif option == \"mid\":\n",
        "        return (s + e) / 2\n",
        "    return s\n",
        "\n",
        "\n",
        "def get_words_speaker_mapping(wrd_ts, spk_ts, word_anchor_option=\"start\"):\n",
        "    s, e, sp = spk_ts[0]\n",
        "    wrd_pos, turn_idx = 0, 0\n",
        "    wrd_spk_mapping = []\n",
        "    for wrd_dict in wrd_ts:\n",
        "        ws, we, wrd = (\n",
        "            int(wrd_dict[\"start\"] * 1000),\n",
        "            int(wrd_dict[\"end\"] * 1000),\n",
        "            wrd_dict[\"word\"],\n",
        "        )\n",
        "        wrd_pos = get_word_ts_anchor(ws, we, word_anchor_option)\n",
        "        while wrd_pos > float(e):\n",
        "            turn_idx += 1\n",
        "            turn_idx = min(turn_idx, len(spk_ts) - 1)\n",
        "            s, e, sp = spk_ts[turn_idx]\n",
        "            if turn_idx == len(spk_ts) - 1:\n",
        "                e = get_word_ts_anchor(ws, we, option=\"end\")\n",
        "        wrd_spk_mapping.append(\n",
        "            {\"word\": wrd, \"start_time\": ws, \"end_time\": we, \"speaker\": sp}\n",
        "        )\n",
        "    return wrd_spk_mapping\n",
        "\n",
        "\n",
        "sentence_ending_punctuations = \".?!\"\n",
        "\n",
        "\n",
        "def get_first_word_idx_of_sentence(word_idx, word_list, speaker_list, max_words):\n",
        "    is_word_sentence_end = (\n",
        "        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
        "    )\n",
        "    left_idx = word_idx\n",
        "    while (\n",
        "        left_idx > 0\n",
        "        and word_idx - left_idx < max_words\n",
        "        and speaker_list[left_idx - 1] == speaker_list[left_idx]\n",
        "        and not is_word_sentence_end(left_idx - 1)\n",
        "    ):\n",
        "        left_idx -= 1\n",
        "\n",
        "    return left_idx if left_idx == 0 or is_word_sentence_end(left_idx - 1) else -1\n",
        "\n",
        "\n",
        "def get_last_word_idx_of_sentence(word_idx, word_list, max_words):\n",
        "    is_word_sentence_end = (\n",
        "        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
        "    )\n",
        "    right_idx = word_idx\n",
        "    while (\n",
        "        right_idx < len(word_list)\n",
        "        and right_idx - word_idx < max_words\n",
        "        and not is_word_sentence_end(right_idx)\n",
        "    ):\n",
        "        right_idx += 1\n",
        "\n",
        "    return (\n",
        "        right_idx\n",
        "        if right_idx == len(word_list) - 1 or is_word_sentence_end(right_idx)\n",
        "        else -1\n",
        "    )\n",
        "\n",
        "\n",
        "def get_realigned_ws_mapping_with_punctuation(\n",
        "    word_speaker_mapping, max_words_in_sentence=50\n",
        "):\n",
        "    is_word_sentence_end = (\n",
        "        lambda x: x >= 0\n",
        "        and word_speaker_mapping[x][\"word\"][-1] in sentence_ending_punctuations\n",
        "    )\n",
        "    wsp_len = len(word_speaker_mapping)\n",
        "\n",
        "    words_list, speaker_list = [], []\n",
        "    for k, line_dict in enumerate(word_speaker_mapping):\n",
        "        word, speaker = line_dict[\"word\"], line_dict[\"speaker\"]\n",
        "        words_list.append(word)\n",
        "        speaker_list.append(speaker)\n",
        "\n",
        "    k = 0\n",
        "    while k < len(word_speaker_mapping):\n",
        "        line_dict = word_speaker_mapping[k]\n",
        "        if (\n",
        "            k < wsp_len - 1\n",
        "            and speaker_list[k] != speaker_list[k + 1]\n",
        "            and not is_word_sentence_end(k)\n",
        "        ):\n",
        "            left_idx = get_first_word_idx_of_sentence(\n",
        "                k, words_list, speaker_list, max_words_in_sentence\n",
        "            )\n",
        "            right_idx = (\n",
        "                get_last_word_idx_of_sentence(\n",
        "                    k, words_list, max_words_in_sentence - k + left_idx - 1\n",
        "                )\n",
        "                if left_idx > -1\n",
        "                else -1\n",
        "            )\n",
        "            if min(left_idx, right_idx) == -1:\n",
        "                k += 1\n",
        "                continue\n",
        "\n",
        "            spk_labels = speaker_list[left_idx : right_idx + 1]\n",
        "            mod_speaker = max(set(spk_labels), key=spk_labels.count)\n",
        "            if spk_labels.count(mod_speaker) < len(spk_labels) // 2:\n",
        "                k += 1\n",
        "                continue\n",
        "\n",
        "            speaker_list[left_idx : right_idx + 1] = [mod_speaker] * (\n",
        "                right_idx - left_idx + 1\n",
        "            )\n",
        "            k = right_idx\n",
        "\n",
        "        k += 1\n",
        "\n",
        "    k, realigned_list = 0, []\n",
        "    while k < len(word_speaker_mapping):\n",
        "        line_dict = word_speaker_mapping[k].copy()\n",
        "        line_dict[\"speaker\"] = speaker_list[k]\n",
        "        realigned_list.append(line_dict)\n",
        "        k += 1\n",
        "\n",
        "    return realigned_list\n",
        "\n",
        "\n",
        "def get_sentences_speaker_mapping(word_speaker_mapping, spk_ts):\n",
        "    sentence_checker = nltk.tokenize.PunktSentenceTokenizer().text_contains_sentbreak\n",
        "    s, e, spk = spk_ts[0]\n",
        "    prev_spk = spk\n",
        "\n",
        "    snts = []\n",
        "    snt = {\"speaker\": f\"Speaker {spk}\", \"start_time\": s, \"end_time\": e, \"text\": \"\"}\n",
        "\n",
        "    for wrd_dict in word_speaker_mapping:\n",
        "        wrd, spk = wrd_dict[\"word\"], wrd_dict[\"speaker\"]\n",
        "        s, e = wrd_dict[\"start_time\"], wrd_dict[\"end_time\"]\n",
        "        if spk != prev_spk or sentence_checker(snt[\"text\"] + \" \" + wrd):\n",
        "            snts.append(snt)\n",
        "            snt = {\n",
        "                \"speaker\": f\"Speaker {spk}\",\n",
        "                \"start_time\": s,\n",
        "                \"end_time\": e,\n",
        "                \"text\": \"\",\n",
        "            }\n",
        "        else:\n",
        "            snt[\"end_time\"] = e\n",
        "        snt[\"text\"] += wrd + \" \"\n",
        "        prev_spk = spk\n",
        "\n",
        "    snts.append(snt)\n",
        "    return snts\n",
        "\n",
        "\n",
        "def get_speaker_aware_transcript(sentences_speaker_mapping, f):\n",
        "    previous_speaker = sentences_speaker_mapping[0][\"speaker\"]\n",
        "    f.write(f\"{previous_speaker}: \")\n",
        "\n",
        "    for sentence_dict in sentences_speaker_mapping:\n",
        "        speaker = sentence_dict[\"speaker\"]\n",
        "        sentence = sentence_dict[\"text\"]\n",
        "\n",
        "        # If this speaker doesn't match the previous one, start a new paragraph\n",
        "        if speaker != previous_speaker:\n",
        "            f.write(f\"\\n\\n{speaker}: \")\n",
        "            previous_speaker = speaker\n",
        "\n",
        "        # No matter what, write the current sentence\n",
        "        f.write(sentence + \" \")\n",
        "\n",
        "\n",
        "def format_timestamp(\n",
        "    milliseconds: float, always_include_hours: bool = False, decimal_marker: str = \".\"\n",
        "):\n",
        "    assert milliseconds >= 0, \"non-negative timestamp expected\"\n",
        "\n",
        "    hours = milliseconds // 3_600_000\n",
        "    milliseconds -= hours * 3_600_000\n",
        "\n",
        "    minutes = milliseconds // 60_000\n",
        "    milliseconds -= minutes * 60_000\n",
        "\n",
        "    seconds = milliseconds // 1_000\n",
        "    milliseconds -= seconds * 1_000\n",
        "\n",
        "    hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n",
        "    return (\n",
        "        f\"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def write_srt(transcript, file):\n",
        "    \"\"\"\n",
        "    Write a transcript to a file in SRT format.\n",
        "\n",
        "    \"\"\"\n",
        "    for i, segment in enumerate(transcript, start=1):\n",
        "        # write srt lines\n",
        "        print(\n",
        "            f\"{i}\\n\"\n",
        "            f\"{format_timestamp(segment['start_time'], always_include_hours=True, decimal_marker=',')} --> \"\n",
        "            f\"{format_timestamp(segment['end_time'], always_include_hours=True, decimal_marker=',')}\\n\"\n",
        "            f\"{segment['speaker']}: {segment['text'].strip().replace('-->', '->')}\\n\",\n",
        "            file=file,\n",
        "            flush=True,\n",
        "        )\n",
        "\n",
        "\n",
        "def find_numeral_symbol_tokens(tokenizer):\n",
        "    numeral_symbol_tokens = [\n",
        "        -1,\n",
        "    ]\n",
        "    for token, token_id in tokenizer.get_vocab().items():\n",
        "        has_numeral_symbol = any(c in \"0123456789%$£\" for c in token)\n",
        "        if has_numeral_symbol:\n",
        "            numeral_symbol_tokens.append(token_id)\n",
        "    return numeral_symbol_tokens\n",
        "\n",
        "\n",
        "def _get_next_start_timestamp(word_timestamps, current_word_index):\n",
        "    # if current word is the last word\n",
        "    if current_word_index == len(word_timestamps) - 1:\n",
        "        return word_timestamps[current_word_index][\"start\"]\n",
        "\n",
        "    next_word_index = current_word_index + 1\n",
        "    while current_word_index < len(word_timestamps) - 1:\n",
        "        if word_timestamps[next_word_index].get(\"start\") is None:\n",
        "            # if next word doesn't have a start timestamp\n",
        "            # merge it with the current word and delete it\n",
        "            word_timestamps[current_word_index][\"word\"] += (\n",
        "                \" \" + word_timestamps[next_word_index][\"word\"]\n",
        "            )\n",
        "\n",
        "            word_timestamps[next_word_index][\"word\"] = None\n",
        "            next_word_index += 1\n",
        "\n",
        "        else:\n",
        "            return word_timestamps[next_word_index][\"start\"]\n",
        "\n",
        "\n",
        "def filter_missing_timestamps(word_timestamps):\n",
        "    # handle the first and last word\n",
        "    if word_timestamps[0].get(\"start\") is None:\n",
        "        word_timestamps[0][\"start\"] = 0\n",
        "        word_timestamps[0][\"end\"] = _get_next_start_timestamp(word_timestamps, 0)\n",
        "\n",
        "    result = [\n",
        "        word_timestamps[0],\n",
        "    ]\n",
        "\n",
        "    for i, ws in enumerate(word_timestamps[1:], start=1):\n",
        "        # if ws doesn't have a start and end\n",
        "        # use the previous end as start and next start as end\n",
        "        if ws.get(\"start\") is None and ws.get(\"word\") is not None:\n",
        "            ws[\"start\"] = word_timestamps[i - 1][\"end\"]\n",
        "            ws[\"end\"] = _get_next_start_timestamp(word_timestamps, i)\n",
        "\n",
        "        if ws[\"word\"] is not None:\n",
        "            result.append(ws)\n",
        "    return result\n",
        "\n",
        "\n",
        "def cleanup(path: str):\n",
        "    \"\"\"path could either be relative or absolute.\"\"\"\n",
        "    # check if file or directory exists\n",
        "    if os.path.isfile(path) or os.path.islink(path):\n",
        "        # remove file\n",
        "        os.remove(path)\n",
        "    elif os.path.isdir(path):\n",
        "        # remove directory and all its content\n",
        "        shutil.rmtree(path)\n",
        "    else:\n",
        "        raise ValueError(\"Path {} is not a file or dir.\".format(path))\n",
        "\n",
        "\n",
        "def process_language_arg(language: str, model_name: str):\n",
        "    \"\"\"\n",
        "    Process the language argument to make sure it's valid and convert language names to language codes.\n",
        "    \"\"\"\n",
        "    if language is not None:\n",
        "        language = language.lower()\n",
        "    if language not in LANGUAGES:\n",
        "        if language in TO_LANGUAGE_CODE:\n",
        "            language = TO_LANGUAGE_CODE[language]\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported language: {language}\")\n",
        "\n",
        "    if model_name.endswith(\".en\") and language != \"en\":\n",
        "        if language is not None:\n",
        "            logging.warning(\n",
        "                f\"{model_name} is an English-only model but received '{language}'; using English instead.\"\n",
        "            )\n",
        "        language = \"en\"\n",
        "    return language\n",
        "\n",
        "\n",
        "def transcribe(\n",
        "    audio_file: str,\n",
        "    language: str,\n",
        "    model_name: str,\n",
        "    compute_dtype: str,\n",
        "    suppress_numerals: bool,\n",
        "    device: str,\n",
        "):\n",
        "    from faster_whisper import WhisperModel\n",
        "    from helpers import find_numeral_symbol_tokens, wav2vec2_langs\n",
        "\n",
        "    # Faster Whisper non-batched\n",
        "    # Run on GPU with FP16\n",
        "    whisper_model = WhisperModel(model_name, device=device, compute_type=compute_dtype)\n",
        "\n",
        "    # or run on GPU with INT8\n",
        "    # model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
        "    # or run on CPU with INT8\n",
        "    # model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
        "\n",
        "    if suppress_numerals:\n",
        "        numeral_symbol_tokens = find_numeral_symbol_tokens(whisper_model.hf_tokenizer)\n",
        "    else:\n",
        "        numeral_symbol_tokens = None\n",
        "\n",
        "    if language is not None and language in wav2vec2_langs:\n",
        "        word_timestamps = False\n",
        "    else:\n",
        "        word_timestamps = True\n",
        "\n",
        "    segments, info = whisper_model.transcribe(\n",
        "        audio_file,\n",
        "        language=language,\n",
        "        beam_size=5,\n",
        "        word_timestamps=word_timestamps,  # TODO: disable this if the language is supported by wav2vec2\n",
        "        suppress_tokens=numeral_symbol_tokens,\n",
        "        vad_filter=True,\n",
        "    )\n",
        "    whisper_results = []\n",
        "    for segment in segments:\n",
        "        whisper_results.append(segment._asdict())\n",
        "    # clear gpu vram\n",
        "    del whisper_model\n",
        "    torch.cuda.empty_cache()\n",
        "    return whisper_results, language\n",
        "\n",
        "\n",
        "def transcribe_batched(\n",
        "    audio_file: str,\n",
        "    language: str,\n",
        "    batch_size: int,\n",
        "    model_name: str,\n",
        "    compute_dtype: str,\n",
        "    suppress_numerals: bool,\n",
        "    device: str,\n",
        "):\n",
        "    import whisperx\n",
        "\n",
        "    # Faster Whisper batched\n",
        "    whisper_model = whisperx.load_model(\n",
        "        model_name,\n",
        "        device,\n",
        "        compute_type=compute_dtype,\n",
        "        asr_options={\"suppress_numerals\": suppress_numerals},\n",
        "    )\n",
        "    audio = whisperx.load_audio(audio_file)\n",
        "    result = whisper_model.transcribe(audio, language=language, batch_size=batch_size)\n",
        "    del whisper_model\n",
        "    torch.cuda.empty_cache()\n",
        "    return result[\"segments\"], result[\"language\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# no space, punctuation, accent in lower string\n",
        "def cleanString(string):\n",
        "    cleanString = unidecode(string)\n",
        "    # cleanString = re.sub('\\W+','_', cleanString)\n",
        "    cleanString = re.sub(r'[^\\w\\s]','',cleanString)\n",
        "    cleanString = cleanString.replace(\" \", \"_\")\n",
        "    return cleanString.lower()\n",
        "\n",
        "# rename audio filename to get name without accent, no space, in lower case\n",
        "def rename_file(filepath):\n",
        "    suffix = Path(filepath).suffix\n",
        "    if str(Path(filepath).parent) != \".\":\n",
        "        new_filepath = str(Path(filepath).parent) + cleanString(filepath.replace(suffix, \"\")) + suffix\n",
        "    else:\n",
        "        new_filepath = cleanString(filepath.replace(suffix, \"\")) + suffix\n",
        "    os.rename(filepath, new_filepath)\n",
        "    return new_filepath"
      ],
      "metadata": {
        "id": "CxDrdPzKD4_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7qWQb--1Xcw"
      },
      "source": [
        "### Setup options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONlFrSnD0FOp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "dad64e35-c262-470d-9717-2ff093ce6970"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '00bcae999c09402cb74a20549a188040_20230429t15_03_utc.wav' -> '00bcae999c09402cb74a20549a188040_20230429t15_03_utc.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-040b18398f71>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# rename audio filename if necessary to get string without accent, space, in lower case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0maudio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrename_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-03e70b2774df>\u001b[0m in \u001b[0;36mrename_file\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnew_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_filepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '00bcae999c09402cb74a20549a188040_20230429t15_03_utc.wav' -> '00bcae999c09402cb74a20549a188040_20230429t15_03_utc.wav'"
          ]
        }
      ],
      "source": [
        "# Name of the audio file\n",
        "audio_path = \"00bcae999c09402cb74a20549a188040_20230429t15_03_utc.wav\"\n",
        "# audio_path = \"audio1.wav\"\n",
        "# audio_path = \"audio2.wav\"\n",
        "\n",
        "# rename audio filename if necessary to get string without accent, space, in lower case\n",
        "audio_path = rename_file(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Option) Whether to enable music removal from speech, helps increase diarization quality but uses alot of ram\n",
        "enable_stemming = False\n",
        "\n",
        "# (choose from 'tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large')\n",
        "# whisper_model_name = \"large-v2\"\n",
        "whisper_model_name = \"large-v3\"\n",
        "\n",
        "# replaces numerical digits with their pronounciation, increases diarization accuracy\n",
        "suppress_numerals = True\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "language = None  # autodetect language\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "-JTNHNtbnzm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check device\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9LlSGeKy8M9s",
        "outputId": "9f7d2448-9bb7-471c-86c7-0d4353eb6370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-cY1ZEy2KVI"
      },
      "source": [
        "# Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZS4xXmE2NGP"
      },
      "source": [
        "## (Option) Separating music from speech using Demucs\n",
        "\n",
        "---\n",
        "\n",
        "By isolating the vocals from the rest of the audio, it becomes easier to identify and track individual speakers based on the spectral and temporal characteristics of their speech signals. Source separation is just one of many techniques that can be used as a preprocessing step to help improve the accuracy and reliability of the overall diarization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKcgQUrAzsJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda9a0dd-066d-4d1e-b483-cbd8301c7585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
            "Wall time: 8.82 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if enable_stemming:\n",
        "    # Isolate vocals from the rest of the audio\n",
        "\n",
        "    return_code = os.system(\n",
        "        f'python3 -m demucs.separate -n htdemucs --two-stems=vocals \"{audio_path}\" -o \"temp_outputs\"'\n",
        "    )\n",
        "\n",
        "    if return_code != 0:\n",
        "        logging.warning(\"Source splitting failed, using original audio file.\")\n",
        "        vocal_target = audio_path\n",
        "    else:\n",
        "        vocal_target = os.path.join(\n",
        "            \"temp_outputs\",\n",
        "            \"htdemucs\",\n",
        "            os.path.splitext(os.path.basename(audio_path))[0],\n",
        "            \"vocals.wav\",\n",
        "        )\n",
        "else:\n",
        "    vocal_target = audio_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYg9VWb22Tz8"
      },
      "source": [
        "## Transcriping audio using Whisper and realligning timestamps using Wav2Vec2\n",
        "---\n",
        "This code uses two different open-source models to transcribe speech and perform forced alignment on the resulting transcription.\n",
        "\n",
        "The first model is called OpenAI Whisper, which is a speech recognition model that can transcribe speech with high accuracy. The code loads the whisper model and uses it to transcribe the vocal_target file.\n",
        "\n",
        "The output of the transcription process is a set of text segments with corresponding timestamps indicating when each segment was spoken.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-VKFn530oTl",
        "outputId": "b9f37c9b-454b-4f3b-a00a-698f3682f420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "404e2ec0ab7a4735bcc96a2719847ecb",
            "03bdc159423046fe9ea83676b03674bc",
            "d977aa1edeaf43849a4072a2487679d2",
            "56c75c10f38a4fd79b1cc5ca83881ccd",
            "3a760dae306743f88c54a783119ea105",
            "d03e56025add4853aeaf6e4e93c940ab",
            "37f013907f4842e585723ba74d289791",
            "b895d698e40e4c34bd8221086e5c5d0e",
            "2ec20086a8d54e9a81495555059c8c3a",
            "26306b99c8eb404d9cbd9f41741dde45",
            "c43c41c7d8fa4a6ab2d035471786174d",
            "bf43b48196694150bd31218bbb2e8050",
            "e955d5489d1045c8af56a48077ee1b37",
            "0d018eddf87c4f35a70aeb7327ec8511",
            "98da45b17a064156b0393ae868317bd4",
            "0aaa63999115472095e0ea060ec269f1",
            "710e0b80643a4fad9214c1f63591c208",
            "b7b3baa2828443b8a6fa2886500e1461",
            "1b080a7f09fe4ddbad3260f5e2a89b70",
            "1359cdd249164b80966011d94dafd635",
            "1625f7d161df4655b9c61e6123f4c7cb",
            "56a15dc4ed744567891d84006197bf4b",
            "51532465ae3b4c21a15b2b77e6d3a308",
            "f4a393836591408593488fbbb1440642",
            "b1baa9617f514b96ada539a7079814da",
            "e69a66fefa104ab88a5801c26d3616b8",
            "ed2fd1f4a8504b3699c8cd51c3aa1ed9",
            "130b28c42cb74ce598eeef23dd3baf5a",
            "93b10363791e4899a866413ab3aedb28",
            "df02a4048b8d4274a3dbfc999e9e8749",
            "a7bde9c865084a1aa33fc9a05f8d3917",
            "cfc6fa9504554c58967b2797af760309",
            "ac9b55a4ce094b279a6433b5335c6180",
            "22b50ee6f06d41edb84bfebea77dc54f",
            "b810d094b25a47fdb381d227be509971",
            "22b701e82dd1405398eea537504970fe",
            "a3b6729348304d8e9d4533aebec15743",
            "443ddfad0e3f4b66bf5543e5d06a3c77",
            "54d448873108423c8d42edda401dc4c7",
            "ffaa0d3154114b439ed4a2feab7cee35",
            "87668cc97443484fa8c7f4e7167ff68c",
            "dc384ba284d8430889e26d19290cdc6b",
            "e3e06b166a3e48adb7e5cdfa5e956dd9",
            "649234e51c9249fcb77390136f235037",
            "82ce3db711bb4df694f509bc89f79814",
            "524002c6ccb54322becee70596b2e838",
            "ab2ada9c47ef4ea9a2b04127e4b58a5f",
            "7cfe5eeaa38640969b0e16847082caaa",
            "040e908918ac43edab2d2cdef6b1b9c4",
            "548b57f056e841549e976b0eb88bb0e1",
            "d84d953ace7e4176ab746e58a53841bb",
            "29434cb665814faea734403aaa925fc3",
            "1b1a4eec8ccb4c5aada1c97a2f568ae3",
            "1c76cfab2d6d47c2809119591b0f8d07",
            "4d60bd791af24538a8d5b6cdec7a82ea"
          ],
          "height": 353
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "404e2ec0ab7a4735bcc96a2719847ecb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.39k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf43b48196694150bd31218bbb2e8050"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51532465ae3b4c21a15b2b77e6d3a308"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22b50ee6f06d41edb84bfebea77dc54f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocabulary.json:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82ce3db711bb4df694f509bc89f79814"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 16.9M/16.9M [00:01<00:00, 10.3MiB/s]\n",
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Detected language: es (0.99) in first 30s of audio...\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "CPU times: user 13 s, sys: 9.35 s, total: 22.3 s\n",
            "Wall time: 46.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if device == \"cuda\": compute_type = \"float16\"\n",
        "# or run on GPU with INT8\n",
        "# compute_type = \"int8_float16\"\n",
        "# or run on CPU with INT8\n",
        "else: compute_type = \"int8\"\n",
        "\n",
        "if batch_size != 0:\n",
        "    whisper_results, language = transcribe_batched(\n",
        "        vocal_target,\n",
        "        language,\n",
        "        batch_size,\n",
        "        whisper_model_name,\n",
        "        compute_type,\n",
        "        suppress_numerals,\n",
        "        device,\n",
        "    )\n",
        "else:\n",
        "    whisper_results, language = transcribe(\n",
        "        vocal_target,\n",
        "        language,\n",
        "        whisper_model_name,\n",
        "        compute_type,\n",
        "        suppress_numerals,\n",
        "        device,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRJFzumCxd-I"
      },
      "source": [
        "## Aligning the transcription with the original audio using Wav2Vec2\n",
        "---\n",
        "The second model used is called wav2vec2, which is a large-scale neural network that is designed to learn representations of speech that are useful for a variety of speech processing tasks, including speech recognition and alignment.\n",
        "\n",
        "The code loads the wav2vec2 alignment model and uses it to align the transcription segments with the original audio signal contained in the vocal_target file. This process involves finding the exact timestamps in the audio signal where each segment was spoken and aligning the text accordingly.\n",
        "\n",
        "By combining the outputs of the two models, the code produces a fully aligned transcription of the speech contained in the vocal_target file. This aligned transcription can be useful for a variety of speech processing tasks, such as speaker diarization, sentiment analysis, and language identification.\n",
        "\n",
        "If there's no Wav2Vec2 model available for your language, word timestamps generated by whisper will be used instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O15cfnDxd-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77305521-f51b-4f4e-919e-cb81c6841865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_voxpopuli_base_10k_asr_es.pt\" to /root/.cache/torch/hub/checkpoints/wav2vec2_voxpopuli_base_10k_asr_es.pt\n",
            "100%|██████████| 360M/360M [00:02<00:00, 143MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8.28 s, sys: 1.81 s, total: 10.1 s\n",
            "Wall time: 11.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if language in wav2vec2_langs:\n",
        "    device = \"cuda\"\n",
        "    alignment_model, metadata = whisperx.load_align_model(\n",
        "        language_code=language, device=device\n",
        "    )\n",
        "    result_aligned = whisperx.align(\n",
        "        whisper_results, alignment_model, metadata, vocal_target, device\n",
        "    )\n",
        "    word_timestamps = filter_missing_timestamps(result_aligned[\"word_segments\"])\n",
        "\n",
        "    # clear gpu vram\n",
        "    del alignment_model\n",
        "    torch.cuda.empty_cache()\n",
        "else:\n",
        "    assert batch_size == 0, (  # TODO: add a better check for word timestamps existence\n",
        "        f\"Unsupported language: {language}, use --batch_size to 0\"\n",
        "        \" to generate word timestamps using whisper directly and fix this error.\"\n",
        "    )\n",
        "    word_timestamps = []\n",
        "    for segment in whisper_results:\n",
        "        for word in segment[\"words\"]:\n",
        "            word_timestamps.append({\"word\": word[2], \"start\": word[0], \"end\": word[1]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EEaJPsQ21Rx"
      },
      "source": [
        "## Convert audio to mono for NeMo combatibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG0kNnGMxd-I",
        "outputId": "e957f40c-d62e-4e0a-969a-79325c37e594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 33.8 ms, sys: 15.6 ms, total: 49.4 ms\n",
            "Wall time: 96.7 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/temp_outputs/mono_file.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "%%time\n",
        "sound = AudioSegment.from_file(vocal_target).set_channels(1)\n",
        "ROOT = os.getcwd()\n",
        "temp_path = os.path.join(ROOT, \"temp_outputs\")\n",
        "os.makedirs(temp_path, exist_ok=True)\n",
        "sound.export(os.path.join(temp_path, \"mono_file.wav\"), format=\"wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1gkViCf2-CV"
      },
      "source": [
        "## Speaker Diarization using NeMo MSDD Model\n",
        "---\n",
        "This code uses a model called Nvidia NeMo MSDD (Multi-scale Diarization Decoder) to perform speaker diarization on an audio signal. Speaker diarization is the process of separating an audio signal into different segments based on who is speaking at any given time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7jIpBCH02RL",
        "outputId": "48fb3236-5140-42ac-d673-bf3742428dd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:33:38 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-17 16:33:38 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/diar_msdd_telephonic/versions/1.0.1/files/diar_msdd_telephonic.nemo to /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-17 16:33:39 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-17 16:33:41 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-17 16:33:41 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-17 16:33:41 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:33:41 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-17 16:33:41 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-17 16:33:43 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-17 16:33:43 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-17 16:33:44 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-17 16:33:44 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/vad_multilingual_marblenet/versions/1.10.0/files/vad_multilingual_marblenet.nemo to /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-17 16:33:44 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-17 16:33:45 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-17 16:33:45 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-17 16:33:45 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:33:45 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-17 16:33:45 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-17 16:33:45 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-17 16:33:45 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-08-17 16:33:45 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-17 16:33:45 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:17<00:00, 17.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:03 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-17 16:34:03 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-17 16:34:03 collections:302] Dataset loaded with 8 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-17 16:34:03 collections:304] # 8 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 8/8 [00:02<00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:05 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:09 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-17 16:34:10 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-17 16:34:10 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-17 16:34:10 collections:302] Dataset loaded with 349 items, total duration of  0.14 hours.\n",
            "[NeMo I 2024-08-17 16:34:10 collections:304] # 349 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:11 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-17 16:34:11 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-17 16:34:11 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-17 16:34:11 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-17 16:34:11 collections:302] Dataset loaded with 421 items, total duration of  0.14 hours.\n",
            "[NeMo I 2024-08-17 16:34:11 collections:304] # 421 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  5.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:12 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-17 16:34:12 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-17 16:34:12 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:12 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-17 16:34:12 collections:302] Dataset loaded with 529 items, total duration of  0.14 hours.\n",
            "[NeMo I 2024-08-17 16:34:12 collections:304] # 529 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  6.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:13 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-17 16:34:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:14 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-17 16:34:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-17 16:34:14 collections:302] Dataset loaded with 715 items, total duration of  0.15 hours.\n",
            "[NeMo I 2024-08-17 16:34:14 collections:304] # 715 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 12/12 [00:01<00:00,  6.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:16 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-17 16:34:16 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:16 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-17 16:34:16 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-17 16:34:16 collections:302] Dataset loaded with 1087 items, total duration of  0.15 hours.\n",
            "[NeMo I 2024-08-17 16:34:16 collections:304] # 1087 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 17/17 [00:02<00:00,  8.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:18 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:19 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-17 16:34:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:19 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-17 16:34:19 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-17 16:34:19 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-17 16:34:19 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-17 16:34:19 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-17 16:34:19 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-17 16:34:20 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-17 16:34:20 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:20 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-17 16:34:20 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-17 16:34:20 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-17 16:34:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:20 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-17 16:34:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:20 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-17 16:34:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-17 16:34:20 msdd_models:1431]   \n",
            "    \n",
            "CPU times: user 36.5 s, sys: 1.48 s, total: 38 s\n",
            "Wall time: 42.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Initialize NeMo MSDD diarization model\n",
        "# DOMAIN_TYPE: can be meeting, telephonic, or general based on domain type of the audio file\n",
        "msdd_model = NeuralDiarizer(cfg=create_config(temp_path, DOMAIN_TYPE=\"telephonic\")).to(\"cuda\")\n",
        "msdd_model.diarize()\n",
        "\n",
        "del msdd_model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmkZYaDAEOAg"
      },
      "source": [
        "## Mapping Spekers to Sentences According to Timestamps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E65LUGQe02zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55c1aef-a172-491e-8383-a290098a650e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.91 ms, sys: 934 µs, total: 4.84 ms\n",
            "Wall time: 4.71 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Reading timestamps <> Speaker Labels mapping\n",
        "\n",
        "speaker_ts = []\n",
        "with open(os.path.join(temp_path, \"pred_rttms\", \"mono_file.rttm\"), \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        line_list = line.split(\" \")\n",
        "        s = int(float(line_list[5]) * 1000)\n",
        "        e = s + int(float(line_list[8]) * 1000)\n",
        "        speaker_ts.append([s, e, int(line_list[11].split(\"_\")[-1])])\n",
        "\n",
        "wsm = get_words_speaker_mapping(word_timestamps, speaker_ts, \"start\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wsm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF3c2e615UG1",
        "outputId": "a20eee37-a938-454d-e392-fb280b4f1e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'word': 'Buen', 'start_time': 1450, 'end_time': 1590, 'speaker': 0}, {'word': 'día,', 'start_time': 1630, 'end_time': 1730, 'speaker': 0}, {'word': 'le', 'start_time': 1790, 'end_time': 1890, 'speaker': 0}, {'word': 'habla', 'start_time': 1970, 'end_time': 2230, 'speaker': 0}, {'word': 'Vanessa.', 'start_time': 5051, 'end_time': 5191, 'speaker': 1}, {'word': '¿En', 'start_time': 5211, 'end_time': 5291, 'speaker': 1}, {'word': 'qué', 'start_time': 5351, 'end_time': 5471, 'speaker': 1}, {'word': 'le', 'start_time': 5511, 'end_time': 5571, 'speaker': 1}, {'word': 'puedo', 'start_time': 5631, 'end_time': 5851, 'speaker': 1}, {'word': 'ayudar?', 'start_time': 5871, 'end_time': 6191, 'speaker': 1}, {'word': 'Hola,', 'start_time': 6211, 'end_time': 6792, 'speaker': 1}, {'word': 'buenos', 'start_time': 7052, 'end_time': 7232, 'speaker': 1}, {'word': 'días.', 'start_time': 7252, 'end_time': 7552, 'speaker': 1}, {'word': 'Habla', 'start_time': 7572, 'end_time': 7852, 'speaker': 1}, {'word': 'Joan', 'start_time': 7912, 'end_time': 8112, 'speaker': 1}, {'word': 'Camilo.', 'start_time': 8151, 'end_time': 8512, 'speaker': 1}, {'word': 'Perdona', 'start_time': 9293, 'end_time': 10033, 'speaker': 1}, {'word': 'la', 'start_time': 10153, 'end_time': 10233, 'speaker': 1}, {'word': 'bulla.', 'start_time': 10293, 'end_time': 10613, 'speaker': 1}, {'word': 'Lo', 'start_time': 11934, 'end_time': 12014, 'speaker': 1}, {'word': 'que', 'start_time': 12054, 'end_time': 12134, 'speaker': 1}, {'word': 'pasa', 'start_time': 12174, 'end_time': 12334, 'speaker': 1}, {'word': 'es', 'start_time': 12374, 'end_time': 12474, 'speaker': 1}, {'word': 'que', 'start_time': 12534, 'end_time': 12654, 'speaker': 1}, {'word': 'a', 'start_time': 12674, 'end_time': 12694, 'speaker': 1}, {'word': 'mí', 'start_time': 12894, 'end_time': 12974, 'speaker': 1}, {'word': 'me', 'start_time': 13034, 'end_time': 13114, 'speaker': 1}, {'word': 'interesaría', 'start_time': 13154, 'end_time': 13875, 'speaker': 1}, {'word': 'ingresar', 'start_time': 14495, 'end_time': 14875, 'speaker': 1}, {'word': 'a', 'start_time': 14895, 'end_time': 14935, 'speaker': 1}, {'word': 'estudiar', 'start_time': 14995, 'end_time': 15455, 'speaker': 1}, {'word': 'enfermería.', 'start_time': 15495, 'end_time': 16236, 'speaker': 1}, {'word': 'Dime,', 'start_time': 18256, 'end_time': 18677, 'speaker': 0}, {'word': 'ya', 'start_time': 19277, 'end_time': 19397, 'speaker': 0}, {'word': 'terminaste.', 'start_time': 19417, 'end_time': 20057, 'speaker': 0}, {'word': 'Dime.', 'start_time': 20277, 'end_time': 21978, 'speaker': 0}, {'word': 'Perdón.', 'start_time': 21998, 'end_time': 22258, 'speaker': 1}, {'word': 'Este,', 'start_time': 22691, 'end_time': 23471, 'speaker': 1}, {'word': 'me', 'start_time': 23812, 'end_time': 23912, 'speaker': 1}, {'word': 'gustaría', 'start_time': 23992, 'end_time': 24432, 'speaker': 1}, {'word': 'empezar', 'start_time': 24492, 'end_time': 24892, 'speaker': 1}, {'word': 'a', 'start_time': 24912, 'end_time': 24932, 'speaker': 1}, {'word': 'estudiar', 'start_time': 24952, 'end_time': 25332, 'speaker': 1}, {'word': 'enfermería,', 'start_time': 25392, 'end_time': 25993, 'speaker': 1}, {'word': 'yo', 'start_time': 26013, 'end_time': 26213, 'speaker': 1}, {'word': 'ya', 'start_time': 26293, 'end_time': 26413, 'speaker': 1}, {'word': 'tengo', 'start_time': 26533, 'end_time': 26773, 'speaker': 1}, {'word': 'bachiller,', 'start_time': 26793, 'end_time': 27513, 'speaker': 1}, {'word': 'yo', 'start_time': 27613, 'end_time': 27713, 'speaker': 1}, {'word': 'tengo', 'start_time': 27813, 'end_time': 28214, 'speaker': 1}, {'word': 'dos', 'start_time': 28594, 'end_time': 28774, 'speaker': 1}, {'word': 'títulos,', 'start_time': 28994, 'end_time': 29594, 'speaker': 1}, {'word': 'bueno,', 'start_time': 29754, 'end_time': 29994, 'speaker': 1}, {'word': 'un', 'start_time': 30115, 'end_time': 30195, 'speaker': 1}, {'word': 'título,', 'start_time': 30295, 'end_time': 30635, 'speaker': 1}, {'word': 'estoy', 'start_time': 30675, 'end_time': 30895, 'speaker': 1}, {'word': 'cursando', 'start_time': 30955, 'end_time': 31415, 'speaker': 1}, {'word': 'el', 'start_time': 31475, 'end_time': 31555, 'speaker': 1}, {'word': 'último,', 'start_time': 31615, 'end_time': 31915, 'speaker': 1}, {'word': 'estoy', 'start_time': 31935, 'end_time': 32156, 'speaker': 1}, {'word': 'haciendo', 'start_time': 32176, 'end_time': 32516, 'speaker': 1}, {'word': 'las', 'start_time': 32595, 'end_time': 32716, 'speaker': 1}, {'word': 'prácticas,', 'start_time': 32816, 'end_time': 33296, 'speaker': 1}, {'word': 'pero', 'start_time': 33976, 'end_time': 34237, 'speaker': 1}, {'word': 'pues', 'start_time': 34337, 'end_time': 34537, 'speaker': 1}, {'word': 'yo', 'start_time': 34577, 'end_time': 34677, 'speaker': 1}, {'word': 'quisiera', 'start_time': 34757, 'end_time': 35077, 'speaker': 1}, {'word': 'como', 'start_time': 35137, 'end_time': 35277, 'speaker': 1}, {'word': 'averiguar', 'start_time': 35317, 'end_time': 35757, 'speaker': 1}, {'word': 'con', 'start_time': 35817, 'end_time': 35977, 'speaker': 1}, {'word': 'tiempo,', 'start_time': 36077, 'end_time': 36338, 'speaker': 1}, {'word': '¿me', 'start_time': 36398, 'end_time': 36458, 'speaker': 1}, {'word': 'hago', 'start_time': 36478, 'end_time': 36618, 'speaker': 1}, {'word': 'entender?', 'start_time': 36638, 'end_time': 37058, 'speaker': 1}, {'word': 'Sí,', 'start_time': 38078, 'end_time': 38198, 'speaker': 0}, {'word': '¿y', 'start_time': 38659, 'end_time': 38719, 'speaker': 0}, {'word': 'qué', 'start_time': 38779, 'end_time': 38919, 'speaker': 0}, {'word': 'deseas', 'start_time': 38939, 'end_time': 39059, 'speaker': 0}, {'word': 'saber?', 'start_time': 39079, 'end_time': 39799, 'speaker': 0}, {'word': 'Yo', 'start_time': 41340, 'end_time': 41440, 'speaker': 1}, {'word': 'quiero', 'start_time': 41480, 'end_time': 41680, 'speaker': 1}, {'word': 'estudiar', 'start_time': 41740, 'end_time': 42080, 'speaker': 1}, {'word': 'enfermería,', 'start_time': 42140, 'end_time': 42641, 'speaker': 1}, {'word': 'pero', 'start_time': 42861, 'end_time': 43061, 'speaker': 1}, {'word': 'pues', 'start_time': 43161, 'end_time': 43361, 'speaker': 1}, {'word': 'mis', 'start_time': 43621, 'end_time': 43801, 'speaker': 1}, {'word': 'recursos,', 'start_time': 43901, 'end_time': 44581, 'speaker': 1}, {'word': 'la', 'start_time': 45242, 'end_time': 45302, 'speaker': 1}, {'word': 'verdad,', 'start_time': 45342, 'end_time': 45722, 'speaker': 1}, {'word': 'son', 'start_time': 45742, 'end_time': 46142, 'speaker': 1}, {'word': 'como', 'start_time': 46182, 'end_time': 46322, 'speaker': 1}, {'word': 'un', 'start_time': 46382, 'end_time': 46442, 'speaker': 1}, {'word': 'poco', 'start_time': 46502, 'end_time': 46702, 'speaker': 1}, {'word': 'limitados', 'start_time': 46762, 'end_time': 47243, 'speaker': 1}, {'word': 'y', 'start_time': 47363, 'end_time': 47403, 'speaker': 1}, {'word': 'a', 'start_time': 47503, 'end_time': 47543, 'speaker': 1}, {'word': 'mí', 'start_time': 47583, 'end_time': 47663, 'speaker': 1}, {'word': 'me', 'start_time': 47723, 'end_time': 47803, 'speaker': 1}, {'word': 'llegaron', 'start_time': 47863, 'end_time': 48243, 'speaker': 1}, {'word': 'a', 'start_time': 48263, 'end_time': 48283, 'speaker': 1}, {'word': 'hablar', 'start_time': 48303, 'end_time': 48543, 'speaker': 1}, {'word': 'sobre', 'start_time': 48643, 'end_time': 48984, 'speaker': 1}, {'word': 'una', 'start_time': 49064, 'end_time': 49204, 'speaker': 1}, {'word': 'beca,', 'start_time': 49404, 'end_time': 49704, 'speaker': 1}, {'word': 'algo', 'start_time': 49724, 'end_time': 49964, 'speaker': 1}, {'word': 'que', 'start_time': 49984, 'end_time': 50084, 'speaker': 1}, {'word': 'se', 'start_time': 50104, 'end_time': 50224, 'speaker': 1}, {'word': 'llama', 'start_time': 50264, 'end_time': 50484, 'speaker': 1}, {'word': 'como', 'start_time': 50544, 'end_time': 50724, 'speaker': 1}, {'word': 'la', 'start_time': 50784, 'end_time': 50844, 'speaker': 1}, {'word': 'generación', 'start_time': 50904, 'end_time': 51545, 'speaker': 1}, {'word': 'E.', 'start_time': 51765, 'end_time': 51785, 'speaker': 1}, {'word': 'Tengo', 'start_time': 52930, 'end_time': 53170, 'speaker': 1}, {'word': 'como', 'start_time': 53230, 'end_time': 53631, 'speaker': 1}, {'word': 'dos,', 'start_time': 53951, 'end_time': 54231, 'speaker': 1}, {'word': 'tres', 'start_time': 54331, 'end_time': 54571, 'speaker': 1}, {'word': 'compañeros', 'start_time': 54631, 'end_time': 55232, 'speaker': 1}, {'word': 'allá', 'start_time': 55472, 'end_time': 55812, 'speaker': 1}, {'word': 'en', 'start_time': 55932, 'end_time': 56072, 'speaker': 1}, {'word': 'donde', 'start_time': 56112, 'end_time': 56332, 'speaker': 1}, {'word': 'estoy', 'start_time': 56352, 'end_time': 56472, 'speaker': 1}, {'word': 'haciendo', 'start_time': 56492, 'end_time': 56773, 'speaker': 1}, {'word': 'mis', 'start_time': 56853, 'end_time': 56973, 'speaker': 1}, {'word': 'prácticas', 'start_time': 57013, 'end_time': 57393, 'speaker': 1}, {'word': 'que', 'start_time': 57433, 'end_time': 57533, 'speaker': 1}, {'word': 'me', 'start_time': 57573, 'end_time': 57633, 'speaker': 1}, {'word': 'hablaron', 'start_time': 57673, 'end_time': 58013, 'speaker': 1}, {'word': 'de', 'start_time': 58033, 'end_time': 58133, 'speaker': 1}, {'word': 'eso,', 'start_time': 58233, 'end_time': 58394, 'speaker': 1}, {'word': 'que', 'start_time': 58434, 'end_time': 58514, 'speaker': 1}, {'word': 'ellos', 'start_time': 58534, 'end_time': 58714, 'speaker': 1}, {'word': 'estudiaron', 'start_time': 58794, 'end_time': 59274, 'speaker': 1}, {'word': 'en', 'start_time': 59294, 'end_time': 59374, 'speaker': 1}, {'word': 'diferentes', 'start_time': 59394, 'end_time': 59834, 'speaker': 1}, {'word': 'universidades', 'start_time': 59854, 'end_time': 60475, 'speaker': 1}, {'word': 'y', 'start_time': 60495, 'end_time': 60515, 'speaker': 1}, {'word': 'pues', 'start_time': 60835, 'end_time': 60995, 'speaker': 1}, {'word': 'yo', 'start_time': 61015, 'end_time': 61075, 'speaker': 1}, {'word': 'estuve', 'start_time': 61095, 'end_time': 61395, 'speaker': 1}, {'word': 'mirando', 'start_time': 61435, 'end_time': 61736, 'speaker': 1}, {'word': 'como', 'start_time': 61756, 'end_time': 61936, 'speaker': 1}, {'word': 'en', 'start_time': 61956, 'end_time': 61996, 'speaker': 1}, {'word': 'las', 'start_time': 62016, 'end_time': 62116, 'speaker': 1}, {'word': 'páginas', 'start_time': 62196, 'end_time': 62616, 'speaker': 1}, {'word': 'y', 'start_time': 62636, 'end_time': 62656, 'speaker': 1}, {'word': 'sale', 'start_time': 63677, 'end_time': 63957, 'speaker': 1}, {'word': 'la', 'start_time': 63997, 'end_time': 64057, 'speaker': 1}, {'word': 'opción', 'start_time': 64137, 'end_time': 64596, 'speaker': 1}, {'word': 'de', 'start_time': 64617, 'end_time': 64657, 'speaker': 1}, {'word': 'esa', 'start_time': 64798, 'end_time': 66459, 'speaker': 1}, {'word': 'beca,', 'start_time': 66519, 'end_time': 66779, 'speaker': 1}, {'word': 'como', 'start_time': 66819, 'end_time': 66959, 'speaker': 1}, {'word': 'inscribirse', 'start_time': 66999, 'end_time': 67519, 'speaker': 1}, {'word': 'a', 'start_time': 67559, 'end_time': 67619, 'speaker': 1}, {'word': 'eso.', 'start_time': 67719, 'end_time': 68000, 'speaker': 1}, {'word': 'Yo', 'start_time': 69180, 'end_time': 69280, 'speaker': 1}, {'word': 'la', 'start_time': 69320, 'end_time': 69380, 'speaker': 1}, {'word': 'verdad', 'start_time': 69420, 'end_time': 69661, 'speaker': 1}, {'word': 'no', 'start_time': 69681, 'end_time': 69781, 'speaker': 1}, {'word': 'conozco', 'start_time': 69821, 'end_time': 70201, 'speaker': 1}, {'word': 'muy', 'start_time': 70241, 'end_time': 70341, 'speaker': 1}, {'word': 'bien', 'start_time': 70381, 'end_time': 70521, 'speaker': 1}, {'word': 'sobre', 'start_time': 70561, 'end_time': 70741, 'speaker': 1}, {'word': 'el', 'start_time': 70761, 'end_time': 70841, 'speaker': 1}, {'word': 'proceso,', 'start_time': 70901, 'end_time': 71522, 'speaker': 1}, {'word': 'ellos', 'start_time': 71542, 'end_time': 71822, 'speaker': 1}, {'word': 'pues', 'start_time': 72362, 'end_time': 72863, 'speaker': 1}, {'word': 'no', 'start_time': 72903, 'end_time': 72983, 'speaker': 1}, {'word': 'me', 'start_time': 73043, 'end_time': 73123, 'speaker': 1}, {'word': 'explicaron', 'start_time': 73163, 'end_time': 73583, 'speaker': 1}, {'word': 'bien.', 'start_time': 73603, 'end_time': 73783, 'speaker': 1}, {'word': '¿A', 'start_time': 74324, 'end_time': 74404, 'speaker': 1}, {'word': 'qué', 'start_time': 74584, 'end_time': 74724, 'speaker': 0}, {'word': 'número', 'start_time': 74764, 'end_time': 75084, 'speaker': 0}, {'word': 'marcaste?', 'start_time': 75184, 'end_time': 75824, 'speaker': 0}, {'word': '¿Cuál', 'start_time': 77025, 'end_time': 78246, 'speaker': 0}, {'word': 'fue', 'start_time': 78266, 'end_time': 78446, 'speaker': 0}, {'word': 'el', 'start_time': 78506, 'end_time': 78586, 'speaker': 0}, {'word': 'número?', 'start_time': 78626, 'end_time': 78886, 'speaker': 0}, {'word': 'Sí,', 'start_time': 79187, 'end_time': 79367, 'speaker': 0}, {'word': 'en', 'start_time': 79547, 'end_time': 79627, 'speaker': 0}, {'word': 'este', 'start_time': 79687, 'end_time': 79887, 'speaker': 0}, {'word': 'momento,', 'start_time': 79947, 'end_time': 80267, 'speaker': 0}, {'word': '¿qué', 'start_time': 80327, 'end_time': 80407, 'speaker': 0}, {'word': 'número', 'start_time': 80467, 'end_time': 80728, 'speaker': 0}, {'word': 'marcaste?', 'start_time': 80788, 'end_time': 81208, 'speaker': 0}, {'word': 'Un', 'start_time': 82955, 'end_time': 83035, 'speaker': 1}, {'word': 'seis', 'start_time': 83115, 'end_time': 83315, 'speaker': 1}, {'word': 'cero', 'start_time': 83335, 'end_time': 83515, 'speaker': 1}, {'word': 'dos', 'start_time': 83555, 'end_time': 83835, 'speaker': 1}, {'word': 'tres', 'start_time': 84015, 'end_time': 84175, 'speaker': 1}, {'word': 'noventa', 'start_time': 84235, 'end_time': 84556, 'speaker': 1}, {'word': 'y', 'start_time': 84596, 'end_time': 84636, 'speaker': 1}, {'word': 'ocho', 'start_time': 84736, 'end_time': 84916, 'speaker': 1}, {'word': 'once', 'start_time': 84936, 'end_time': 85276, 'speaker': 1}, {'word': 'cuarenta', 'start_time': 85356, 'end_time': 85736, 'speaker': 1}, {'word': 'y', 'start_time': 85756, 'end_time': 85776, 'speaker': 1}, {'word': 'siete,', 'start_time': 86056, 'end_time': 86376, 'speaker': 1}, {'word': 'porque', 'start_time': 86596, 'end_time': 86916, 'speaker': 1}, {'word': 'ya', 'start_time': 86976, 'end_time': 87096, 'speaker': 1}, {'word': 'me', 'start_time': 87176, 'end_time': 87256, 'speaker': 1}, {'word': 'hago', 'start_time': 87276, 'end_time': 87416, 'speaker': 1}, {'word': 'como', 'start_time': 87496, 'end_time': 87676, 'speaker': 1}, {'word': 'un', 'start_time': 87716, 'end_time': 87776, 'speaker': 1}, {'word': 'tres', 'start_time': 87856, 'end_time': 88076, 'speaker': 1}, {'word': 'veintiuno,', 'start_time': 88136, 'end_time': 88577, 'speaker': 1}, {'word': 'creo.', 'start_time': 88677, 'end_time': 88917, 'speaker': 1}, {'word': 'También', 'start_time': 89697, 'end_time': 89937, 'speaker': 1}, {'word': 'que', 'start_time': 89977, 'end_time': 90037, 'speaker': 1}, {'word': 'me', 'start_time': 90077, 'end_time': 90177, 'speaker': 1}, {'word': 'salió', 'start_time': 90237, 'end_time': 90437, 'speaker': 1}, {'word': 'en', 'start_time': 90457, 'end_time': 90497, 'speaker': 1}, {'word': 'la', 'start_time': 90557, 'end_time': 90617, 'speaker': 1}, {'word': 'plataforma,', 'start_time': 90677, 'end_time': 91177, 'speaker': 1}, {'word': 'pero', 'start_time': 91317, 'end_time': 91597, 'speaker': 1}, {'word': 'no', 'start_time': 91897, 'end_time': 92017, 'speaker': 1}, {'word': 'contestan', 'start_time': 92137, 'end_time': 92598, 'speaker': 1}, {'word': 'nada,', 'start_time': 92798, 'end_time': 93118, 'speaker': 1}, {'word': 'o', 'start_time': 93198, 'end_time': 93278, 'speaker': 1}, {'word': 'sea,', 'start_time': 93318, 'end_time': 93498, 'speaker': 1}, {'word': 'no,', 'start_time': 93538, 'end_time': 93658, 'speaker': 1}, {'word': 'nada.', 'start_time': 93738, 'end_time': 93938, 'speaker': 1}, {'word': 'Debes', 'start_time': 93978, 'end_time': 94278, 'speaker': 0}, {'word': 'de', 'start_time': 94338, 'end_time': 94598, 'speaker': 0}, {'word': 'comunicarte', 'start_time': 94698, 'end_time': 95278, 'speaker': 0}, {'word': 'por', 'start_time': 95338, 'end_time': 95478, 'speaker': 0}, {'word': 'ese', 'start_time': 95498, 'end_time': 95698, 'speaker': 0}, {'word': 'medio', 'start_time': 95778, 'end_time': 95998, 'speaker': 0}, {'word': 'para', 'start_time': 96078, 'end_time': 96218, 'speaker': 0}, {'word': 'que', 'start_time': 96278, 'end_time': 96358, 'speaker': 0}, {'word': 'te', 'start_time': 96418, 'end_time': 96498, 'speaker': 0}, {'word': 'puedan', 'start_time': 96558, 'end_time': 96779, 'speaker': 0}, {'word': 'transferir', 'start_time': 96839, 'end_time': 97299, 'speaker': 0}, {'word': 'al', 'start_time': 97339, 'end_time': 97439, 'speaker': 0}, {'word': 'área', 'start_time': 97479, 'end_time': 97659, 'speaker': 0}, {'word': 'financiera,', 'start_time': 97719, 'end_time': 98259, 'speaker': 0}, {'word': 'que', 'start_time': 98279, 'end_time': 98339, 'speaker': 0}, {'word': 'en', 'start_time': 98539, 'end_time': 98679, 'speaker': 0}, {'word': 'eso,', 'start_time': 98759, 'end_time': 99299, 'speaker': 0}, {'word': 'que', 'start_time': 99339, 'end_time': 99439, 'speaker': 0}, {'word': 'te', 'start_time': 99639, 'end_time': 99759, 'speaker': 0}, {'word': 'pueden', 'start_time': 99839, 'end_time': 100179, 'speaker': 0}, {'word': 'brindar', 'start_time': 100219, 'end_time': 100519, 'speaker': 0}, {'word': 'información', 'start_time': 100579, 'end_time': 101140, 'speaker': 0}, {'word': 'sobre', 'start_time': 101620, 'end_time': 102060, 'speaker': 0}, {'word': 'esta', 'start_time': 102160, 'end_time': 102380, 'speaker': 0}, {'word': 'beca.', 'start_time': 102440, 'end_time': 102720, 'speaker': 0}, {'word': 'Una', 'start_time': 105661, 'end_time': 105781, 'speaker': 1}, {'word': 'pregunta,', 'start_time': 105841, 'end_time': 106161, 'speaker': 1}, {'word': '¿qué', 'start_time': 106221, 'end_time': 106321, 'speaker': 1}, {'word': 'me', 'start_time': 106361, 'end_time': 106461, 'speaker': 1}, {'word': 'podrían', 'start_time': 106521, 'end_time': 106921, 'speaker': 1}, {'word': 'dar', 'start_time': 107021, 'end_time': 107141, 'speaker': 1}, {'word': 'información', 'start_time': 107221, 'end_time': 107741, 'speaker': 1}, {'word': 'sobre', 'start_time': 107801, 'end_time': 108021, 'speaker': 1}, {'word': 'la', 'start_time': 108081, 'end_time': 108141, 'speaker': 1}, {'word': 'carrera', 'start_time': 108201, 'end_time': 108581, 'speaker': 1}, {'word': 'en', 'start_time': 108601, 'end_time': 108681, 'speaker': 1}, {'word': 'sí?', 'start_time': 108701, 'end_time': 108882, 'speaker': 1}, {'word': 'Sí.', 'start_time': 109502, 'end_time': 109702, 'speaker': 1}, {'word': 'La', 'start_time': 109782, 'end_time': 109822, 'speaker': 1}, {'word': 'parte', 'start_time': 109882, 'end_time': 110122, 'speaker': 1}, {'word': 'de', 'start_time': 110162, 'end_time': 110242, 'speaker': 1}, {'word': 'la', 'start_time': 110282, 'end_time': 110322, 'speaker': 1}, {'word': 'beca.', 'start_time': 110402, 'end_time': 110622, 'speaker': 1}, {'word': '¿Me', 'start_time': 110984, 'end_time': 112405, 'speaker': 1}, {'word': 'puedes,', 'start_time': 112445, 'end_time': 114886, 'speaker': 1}, {'word': 'por', 'start_time': 114906, 'end_time': 114986, 'speaker': 1}, {'word': 'favor,', 'start_time': 115046, 'end_time': 115206, 'speaker': 1}, {'word': 'dar', 'start_time': 115226, 'end_time': 115306, 'speaker': 1}, {'word': 'información', 'start_time': 115326, 'end_time': 115627, 'speaker': 1}, {'word': 'para', 'start_time': 115647, 'end_time': 115847, 'speaker': 1}, {'word': 'saber', 'start_time': 115867, 'end_time': 116227, 'speaker': 1}, {'word': 'más', 'start_time': 116347, 'end_time': 116407, 'speaker': 0}, {'word': 'o', 'start_time': 116427, 'end_time': 116447, 'speaker': 0}, {'word': 'menos', 'start_time': 116467, 'end_time': 116707, 'speaker': 0}, {'word': 'también?', 'start_time': 116727, 'end_time': 117228, 'speaker': 0}, {'word': 'Mira,', 'start_time': 117248, 'end_time': 117368, 'speaker': 0}, {'word': 'si', 'start_time': 117388, 'end_time': 117428, 'speaker': 0}, {'word': 'estás', 'start_time': 117488, 'end_time': 117608, 'speaker': 0}, {'word': 'interesado', 'start_time': 117648, 'end_time': 118168, 'speaker': 0}, {'word': 'para', 'start_time': 118228, 'end_time': 118388, 'speaker': 0}, {'word': 'el', 'start_time': 118408, 'end_time': 118448, 'speaker': 0}, {'word': 'dos', 'start_time': 118588, 'end_time': 118688, 'speaker': 0}, {'word': 'mil', 'start_time': 118728, 'end_time': 118829, 'speaker': 0}, {'word': 'veintitrés,', 'start_time': 118889, 'end_time': 119429, 'speaker': 0}, {'word': 'ya', 'start_time': 119449, 'end_time': 119489, 'speaker': 0}, {'word': 'están', 'start_time': 119649, 'end_time': 119869, 'speaker': 0}, {'word': 'abiertas', 'start_time': 119949, 'end_time': 120309, 'speaker': 0}, {'word': 'las', 'start_time': 120369, 'end_time': 120489, 'speaker': 0}, {'word': 'inscripciones,', 'start_time': 120570, 'end_time': 121270, 'speaker': 0}, {'word': 'siempre', 'start_time': 121290, 'end_time': 121750, 'speaker': 0}, {'word': 'los', 'start_time': 121810, 'end_time': 121910, 'speaker': 0}, {'word': 'valores', 'start_time': 122030, 'end_time': 122491, 'speaker': 0}, {'word': 'anualmente', 'start_time': 122511, 'end_time': 123051, 'speaker': 0}, {'word': 'cambian,', 'start_time': 123191, 'end_time': 123511, 'speaker': 0}, {'word': 'así', 'start_time': 123531, 'end_time': 123591, 'speaker': 0}, {'word': 'que', 'start_time': 123951, 'end_time': 124152, 'speaker': 0}, {'word': 'si', 'start_time': 124492, 'end_time': 124572, 'speaker': 0}, {'word': 'estás', 'start_time': 124612, 'end_time': 124832, 'speaker': 0}, {'word': 'interesado', 'start_time': 124872, 'end_time': 125352, 'speaker': 0}, {'word': 'para', 'start_time': 125452, 'end_time': 125632, 'speaker': 0}, {'word': 'otro', 'start_time': 125732, 'end_time': 125973, 'speaker': 0}, {'word': 'año,', 'start_time': 126033, 'end_time': 126213, 'speaker': 0}, {'word': 'deberás', 'start_time': 126293, 'end_time': 126693, 'speaker': 0}, {'word': 'consultar', 'start_time': 126753, 'end_time': 127153, 'speaker': 0}, {'word': 'nuevamente', 'start_time': 127213, 'end_time': 127794, 'speaker': 0}, {'word': 'que', 'start_time': 128154, 'end_time': 128314, 'speaker': 0}, {'word': 'la', 'start_time': 128413, 'end_time': 128514, 'speaker': 0}, {'word': 'información', 'start_time': 128633, 'end_time': 129133, 'speaker': 0}, {'word': 'sea', 'start_time': 129154, 'end_time': 129875, 'speaker': 0}, {'word': 'actualizada', 'start_time': 129935, 'end_time': 130475, 'speaker': 0}, {'word': 'para', 'start_time': 130574, 'end_time': 130735, 'speaker': 0}, {'word': 'ese', 'start_time': 130815, 'end_time': 131014, 'speaker': 0}, {'word': 'año', 'start_time': 131096, 'end_time': 131316, 'speaker': 0}, {'word': 'de', 'start_time': 131596, 'end_time': 131696, 'speaker': 0}, {'word': 'ingreso.', 'start_time': 131736, 'end_time': 132156, 'speaker': 0}, {'word': 'Tiene', 'start_time': 132937, 'end_time': 133217, 'speaker': 0}, {'word': 'una', 'start_time': 133277, 'end_time': 133397, 'speaker': 0}, {'word': 'duración', 'start_time': 133477, 'end_time': 133857, 'speaker': 0}, {'word': 'de', 'start_time': 133917, 'end_time': 134017, 'speaker': 0}, {'word': 'nueve', 'start_time': 134097, 'end_time': 134337, 'speaker': 0}, {'word': 'semestres,', 'start_time': 134417, 'end_time': 134958, 'speaker': 0}, {'word': 'es', 'start_time': 134978, 'end_time': 135018, 'speaker': 0}, {'word': 'completamente', 'start_time': 135358, 'end_time': 136158, 'speaker': 0}, {'word': 'presencial,', 'start_time': 136278, 'end_time': 137019, 'speaker': 0}, {'word': 'La', 'start_time': 137481, 'end_time': 137561, 'speaker': 0}, {'word': 'inscripción', 'start_time': 137621, 'end_time': 138161, 'speaker': 0}, {'word': 'tiene', 'start_time': 138241, 'end_time': 138421, 'speaker': 0}, {'word': 'un', 'start_time': 138481, 'end_time': 138541, 'speaker': 0}, {'word': 'valor', 'start_time': 138581, 'end_time': 138801, 'speaker': 0}, {'word': 'de', 'start_time': 138841, 'end_time': 139662, 'speaker': 0}, {'word': 'USD-CAD', 'start_time': 139702, 'end_time': 140522, 'speaker': 0}, {'word': 'y', 'start_time': 140682, 'end_time': 140762, 'speaker': 0}, {'word': 'el', 'start_time': 140802, 'end_time': 140882, 'speaker': 0}, {'word': 'semestre', 'start_time': 140962, 'end_time': 143203, 'speaker': 0}, {'word': 'de', 'start_time': 143223, 'end_time': 143263, 'speaker': 0}, {'word': 'USD-CAD', 'start_time': 143983, 'end_time': 145583, 'speaker': 0}, {'word': '.', 'start_time': 145583, 'end_time': 146864, 'speaker': 0}, {'word': 'El', 'start_time': 146864, 'end_time': 147864, 'speaker': 0}, {'word': 'proceso', 'start_time': 147904, 'end_time': 148284, 'speaker': 0}, {'word': 'de', 'start_time': 148324, 'end_time': 148404, 'speaker': 0}, {'word': 'inscripción', 'start_time': 148464, 'end_time': 148964, 'speaker': 0}, {'word': 'debes', 'start_time': 148984, 'end_time': 149264, 'speaker': 0}, {'word': 'realizarlo', 'start_time': 149324, 'end_time': 149944, 'speaker': 0}, {'word': 'completamente', 'start_time': 150004, 'end_time': 150665, 'speaker': 0}, {'word': 'virtual.', 'start_time': 150785, 'end_time': 151265, 'speaker': 0}, {'word': 'Debes', 'start_time': 151725, 'end_time': 151945, 'speaker': 0}, {'word': 'adjuntar', 'start_time': 152085, 'end_time': 152525, 'speaker': 0}, {'word': 'tu', 'start_time': 152605, 'end_time': 152705, 'speaker': 0}, {'word': 'documento', 'start_time': 152745, 'end_time': 153245, 'speaker': 0}, {'word': 'de', 'start_time': 153265, 'end_time': 153365, 'speaker': 0}, {'word': 'identidad,', 'start_time': 153425, 'end_time': 153965, 'speaker': 0}, {'word': 'las', 'start_time': 153985, 'end_time': 154045, 'speaker': 0}, {'word': 'notas', 'start_time': 154626, 'end_time': 154946, 'speaker': 0}, {'word': 'certificado', 'start_time': 155066, 'end_time': 155626, 'speaker': 0}, {'word': 'original', 'start_time': 155686, 'end_time': 156106, 'speaker': 0}, {'word': 'de', 'start_time': 156126, 'end_time': 156226, 'speaker': 0}, {'word': 'notas', 'start_time': 156286, 'end_time': 156586, 'speaker': 0}, {'word': 'de', 'start_time': 156646, 'end_time': 156726, 'speaker': 0}, {'word': 'noveno', 'start_time': 156786, 'end_time': 157166, 'speaker': 0}, {'word': 'a', 'start_time': 157186, 'end_time': 157266, 'speaker': 0}, {'word': 'once', 'start_time': 157406, 'end_time': 157706, 'speaker': 0}, {'word': 'y', 'start_time': 157886, 'end_time': 157946, 'speaker': 0}, {'word': 'el', 'start_time': 158006, 'end_time': 158106, 'speaker': 0}, {'word': 'resultado', 'start_time': 158146, 'end_time': 158527, 'speaker': 0}, {'word': 'de', 'start_time': 158567, 'end_time': 158627, 'speaker': 0}, {'word': 'las', 'start_time': 158667, 'end_time': 158747, 'speaker': 0}, {'word': 'pruebas', 'start_time': 158827, 'end_time': 159087, 'speaker': 0}, {'word': 'AVER', 'start_time': 159207, 'end_time': 159467, 'speaker': 0}, {'word': 'con', 'start_time': 159827, 'end_time': 159967, 'speaker': 0}, {'word': 'un', 'start_time': 160027, 'end_time': 160087, 'speaker': 0}, {'word': 'puntaje', 'start_time': 160127, 'end_time': 160487, 'speaker': 0}, {'word': 'mínimo', 'start_time': 160587, 'end_time': 160887, 'speaker': 0}, {'word': 'obtenido', 'start_time': 160947, 'end_time': 161387, 'speaker': 0}, {'word': 'de', 'start_time': 161447, 'end_time': 161527, 'speaker': 0}, {'word': 'doscientos', 'start_time': 161587, 'end_time': 162008, 'speaker': 0}, {'word': 'cincuenta', 'start_time': 162068, 'end_time': 162488, 'speaker': 0}, {'word': 'puntos', 'start_time': 162568, 'end_time': 162848, 'speaker': 0}, {'word': 'en', 'start_time': 162868, 'end_time': 162908, 'speaker': 0}, {'word': 'adelante.', 'start_time': 163288, 'end_time': 163728, 'speaker': 0}, {'word': 'Una', 'start_time': 164449, 'end_time': 164629, 'speaker': 0}, {'word': 'vez', 'start_time': 164689, 'end_time': 164869, 'speaker': 0}, {'word': 'te', 'start_time': 165109, 'end_time': 165189, 'speaker': 0}, {'word': 'eligencies', 'start_time': 165209, 'end_time': 165670, 'speaker': 0}, {'word': 'el', 'start_time': 165710, 'end_time': 165790, 'speaker': 0}, {'word': 'formulario', 'start_time': 165830, 'end_time': 166270, 'speaker': 0}, {'word': 'de', 'start_time': 166310, 'end_time': 166370, 'speaker': 0}, {'word': 'inscripción', 'start_time': 166430, 'end_time': 166950, 'speaker': 0}, {'word': 'y', 'start_time': 166970, 'end_time': 166990, 'speaker': 0}, {'word': 'pagues', 'start_time': 167270, 'end_time': 167591, 'speaker': 0}, {'word': 'los', 'start_time': 167671, 'end_time': 167771, 'speaker': 0}, {'word': 'derechos', 'start_time': 167831, 'end_time': 168171, 'speaker': 0}, {'word': 'de', 'start_time': 168191, 'end_time': 168271, 'speaker': 0}, {'word': 'inscripción,', 'start_time': 168331, 'end_time': 168891, 'speaker': 0}, {'word': 'al', 'start_time': 169312, 'end_time': 169432, 'speaker': 0}, {'word': 'correo', 'start_time': 169492, 'end_time': 169872, 'speaker': 0}, {'word': 'se', 'start_time': 169912, 'end_time': 169992, 'speaker': 0}, {'word': 'te', 'start_time': 170072, 'end_time': 170192, 'speaker': 0}, {'word': 'va', 'start_time': 170232, 'end_time': 170272, 'speaker': 0}, {'word': 'a', 'start_time': 170292, 'end_time': 170312, 'speaker': 0}, {'word': 'enviar', 'start_time': 170332, 'end_time': 170672, 'speaker': 0}, {'word': 'una', 'start_time': 170832, 'end_time': 170952, 'speaker': 0}, {'word': 'cita', 'start_time': 171052, 'end_time': 171313, 'speaker': 0}, {'word': 'para', 'start_time': 171393, 'end_time': 171553, 'speaker': 0}, {'word': 'que', 'start_time': 171613, 'end_time': 171713, 'speaker': 0}, {'word': 'presentes', 'start_time': 171793, 'end_time': 172273, 'speaker': 0}, {'word': 'una', 'start_time': 172313, 'end_time': 172433, 'speaker': 0}, {'word': 'entrevista', 'start_time': 172473, 'end_time': 173033, 'speaker': 0}, {'word': 'con', 'start_time': 173113, 'end_time': 173213, 'speaker': 0}, {'word': 'el', 'start_time': 173253, 'end_time': 173334, 'speaker': 0}, {'word': 'director', 'start_time': 173354, 'end_time': 173754, 'speaker': 0}, {'word': 'del', 'start_time': 173794, 'end_time': 173934, 'speaker': 0}, {'word': 'programa.', 'start_time': 173974, 'end_time': 174394, 'speaker': 0}, {'word': 'Después', 'start_time': 174914, 'end_time': 175234, 'speaker': 0}, {'word': 'de', 'start_time': 175274, 'end_time': 175335, 'speaker': 0}, {'word': 'la', 'start_time': 175395, 'end_time': 175475, 'speaker': 0}, {'word': 'entrevista', 'start_time': 175495, 'end_time': 175955, 'speaker': 0}, {'word': 'se', 'start_time': 175975, 'end_time': 176015, 'speaker': 0}, {'word': 'te', 'start_time': 176055, 'end_time': 176135, 'speaker': 0}, {'word': 'enviará', 'start_time': 176215, 'end_time': 176615, 'speaker': 0}, {'word': 'el', 'start_time': 176735, 'end_time': 176815, 'speaker': 0}, {'word': 'resultado', 'start_time': 176875, 'end_time': 177235, 'speaker': 0}, {'word': 'de', 'start_time': 177275, 'end_time': 177356, 'speaker': 0}, {'word': 'admisión', 'start_time': 177376, 'end_time': 177756, 'speaker': 0}, {'word': 'por', 'start_time': 177876, 'end_time': 177996, 'speaker': 0}, {'word': 'correo', 'start_time': 178076, 'end_time': 178336, 'speaker': 0}, {'word': 'electrónico.', 'start_time': 178396, 'end_time': 179016, 'speaker': 0}, {'word': 'Nosotros', 'start_time': 180337, 'end_time': 180757, 'speaker': 0}, {'word': 'desde', 'start_time': 180837, 'end_time': 181318, 'speaker': 0}, {'word': 'la', 'start_time': 181418, 'end_time': 181478, 'speaker': 0}, {'word': 'universidad', 'start_time': 181538, 'end_time': 182098, 'speaker': 0}, {'word': 'realizamos', 'start_time': 182118, 'end_time': 182738, 'speaker': 0}, {'word': 'procesos', 'start_time': 182798, 'end_time': 183198, 'speaker': 0}, {'word': 'de', 'start_time': 183238, 'end_time': 183299, 'speaker': 0}, {'word': 'homologación,', 'start_time': 183339, 'end_time': 184039, 'speaker': 0}, {'word': 'pero', 'start_time': 184339, 'end_time': 184599, 'speaker': 0}, {'word': 'solamente', 'start_time': 184999, 'end_time': 185560, 'speaker': 0}, {'word': 'si', 'start_time': 185580, 'end_time': 185840, 'speaker': 0}, {'word': 'es', 'start_time': 185880, 'end_time': 186020, 'speaker': 0}, {'word': 'de', 'start_time': 186120, 'end_time': 186240, 'speaker': 0}, {'word': 'un', 'start_time': 186320, 'end_time': 186400, 'speaker': 0}, {'word': 'pregrado', 'start_time': 186460, 'end_time': 186960, 'speaker': 0}, {'word': 'a', 'start_time': 187180, 'end_time': 187240, 'speaker': 0}, {'word': 'otro', 'start_time': 187341, 'end_time': 187581, 'speaker': 0}, {'word': 'pregrado.', 'start_time': 187661, 'end_time': 189682, 'speaker': 0}, {'word': 'Listo.', 'start_time': 189802, 'end_time': 190082, 'speaker': 1}, {'word': 'Entonces,', 'start_time': 191396, 'end_time': 192116, 'speaker': 1}, {'word': 'en', 'start_time': 192156, 'end_time': 192236, 'speaker': 1}, {'word': 'cuestión', 'start_time': 192276, 'end_time': 192657, 'speaker': 1}, {'word': 'para', 'start_time': 192877, 'end_time': 193077, 'speaker': 1}, {'word': 'lo', 'start_time': 193137, 'end_time': 193237, 'speaker': 1}, {'word': 'de', 'start_time': 193337, 'end_time': 193417, 'speaker': 1}, {'word': 'la', 'start_time': 193477, 'end_time': 193558, 'speaker': 1}, {'word': 'beca', 'start_time': 193598, 'end_time': 193898, 'speaker': 1}, {'word': 'de', 'start_time': 193918, 'end_time': 193978, 'speaker': 1}, {'word': 'esas', 'start_time': 193998, 'end_time': 194178, 'speaker': 1}, {'word': 'generaciones,', 'start_time': 194238, 'end_time': 194899, 'speaker': 1}, {'word': 'yo', 'start_time': 194939, 'end_time': 195059, 'speaker': 1}, {'word': 'tengo', 'start_time': 195099, 'end_time': 195299, 'speaker': 1}, {'word': 'que', 'start_time': 195319, 'end_time': 195399, 'speaker': 1}, {'word': 'llamar', 'start_time': 195459, 'end_time': 195699, 'speaker': 1}, {'word': 'esa', 'start_time': 195759, 'end_time': 195859, 'speaker': 1}, {'word': 'al', 'start_time': 195899, 'end_time': 195960, 'speaker': 1}, {'word': 'tres', 'start_time': 196000, 'end_time': 196100, 'speaker': 1}, {'word': 'veintiuno,', 'start_time': 196120, 'end_time': 196640, 'speaker': 1}, {'word': '¿cierto?', 'start_time': 196720, 'end_time': 197000, 'speaker': 1}, {'word': 'Sí,', 'start_time': 197161, 'end_time': 197681, 'speaker': 0}, {'word': 'señor.', 'start_time': 197741, 'end_time': 198041, 'speaker': 0}, {'word': 'Y', 'start_time': 198241, 'end_time': 198462, 'speaker': 0}, {'word': 'solicitar', 'start_time': 198522, 'end_time': 199102, 'speaker': 0}, {'word': 'que', 'start_time': 199182, 'end_time': 199262, 'speaker': 0}, {'word': 'te', 'start_time': 199342, 'end_time': 199422, 'speaker': 0}, {'word': 'comuniquen', 'start_time': 199502, 'end_time': 200043, 'speaker': 0}, {'word': 'con', 'start_time': 200143, 'end_time': 200283, 'speaker': 0}, {'word': 'área', 'start_time': 200463, 'end_time': 200663, 'speaker': 0}, {'word': 'financiera.', 'start_time': 200723, 'end_time': 201284, 'speaker': 0}, {'word': 'Listo.', 'start_time': 202485, 'end_time': 202885, 'speaker': 1}, {'word': 'Yo', 'start_time': 203366, 'end_time': 203866, 'speaker': 1}, {'word': 'voy', 'start_time': 204066, 'end_time': 204266, 'speaker': 1}, {'word': 'a...', 'start_time': 204347, 'end_time': 204707, 'speaker': 1}, {'word': '¿Voy', 'start_time': 205247, 'end_time': 205467, 'speaker': 1}, {'word': 'a', 'start_time': 205748, 'end_time': 205768, 'speaker': 1}, {'word': 'qué?', 'start_time': 206488, 'end_time': 207469, 'speaker': 1}, {'word': '¿Me', 'start_time': 207489, 'end_time': 207569, 'speaker': 1}, {'word': 'puedes', 'start_time': 207629, 'end_time': 207829, 'speaker': 1}, {'word': 'dar', 'start_time': 207869, 'end_time': 208010, 'speaker': 1}, {'word': 'el', 'start_time': 208070, 'end_time': 208170, 'speaker': 1}, {'word': 'número,', 'start_time': 208210, 'end_time': 208530, 'speaker': 1}, {'word': 'por', 'start_time': 208630, 'end_time': 208790, 'speaker': 1}, {'word': 'favor?', 'start_time': 208830, 'end_time': 209931, 'speaker': 1}, {'word': 'O', 'start_time': 210151, 'end_time': 210432, 'speaker': 1}, {'word': 'permíteme', 'start_time': 210472, 'end_time': 210972, 'speaker': 1}, {'word': 'mejor.', 'start_time': 211032, 'end_time': 212133, 'speaker': 0}, {'word': 'Te', 'start_time': 212153, 'end_time': 212253, 'speaker': 0}, {'word': 'voy', 'start_time': 212293, 'end_time': 212493, 'speaker': 0}, {'word': 'a', 'start_time': 212513, 'end_time': 212533, 'speaker': 0}, {'word': 'compartir', 'start_time': 212593, 'end_time': 213094, 'speaker': 0}, {'word': 'mejor', 'start_time': 213174, 'end_time': 213434, 'speaker': 0}, {'word': 'el', 'start_time': 213454, 'end_time': 213754, 'speaker': 0}, {'word': 'contacto', 'start_time': 213874, 'end_time': 214415, 'speaker': 0}, {'word': 'del', 'start_time': 214435, 'end_time': 214795, 'speaker': 0}, {'word': 'profesional', 'start_time': 214855, 'end_time': 215456, 'speaker': 0}, {'word': 'a', 'start_time': 215516, 'end_time': 215536, 'speaker': 0}, {'word': 'cargo', 'start_time': 215616, 'end_time': 215976, 'speaker': 0}, {'word': 'de', 'start_time': 216056, 'end_time': 216156, 'speaker': 0}, {'word': 'la', 'start_time': 216216, 'end_time': 216296, 'speaker': 0}, {'word': 'carrera.', 'start_time': 216377, 'end_time': 216757, 'speaker': 0}, {'word': 'para', 'start_time': 217455, 'end_time': 217636, 'speaker': 0}, {'word': 'que', 'start_time': 217716, 'end_time': 217916, 'speaker': 0}, {'word': 'esta', 'start_time': 218016, 'end_time': 218216, 'speaker': 0}, {'word': 'persona', 'start_time': 218337, 'end_time': 218777, 'speaker': 0}, {'word': 'te', 'start_time': 218917, 'end_time': 219018, 'speaker': 0}, {'word': 'pueda', 'start_time': 219118, 'end_time': 219298, 'speaker': 0}, {'word': 'orientar', 'start_time': 219338, 'end_time': 219759, 'speaker': 0}, {'word': 'sobre', 'start_time': 219879, 'end_time': 220159, 'speaker': 0}, {'word': 'la', 'start_time': 220259, 'end_time': 220360, 'speaker': 0}, {'word': 'beca', 'start_time': 220440, 'end_time': 220820, 'speaker': 0}, {'word': 'y', 'start_time': 221321, 'end_time': 221401, 'speaker': 0}, {'word': 'te', 'start_time': 221521, 'end_time': 221621, 'speaker': 0}, {'word': 'pueda', 'start_time': 221722, 'end_time': 221922, 'speaker': 0}, {'word': 'abrir', 'start_time': 222002, 'end_time': 222222, 'speaker': 0}, {'word': 'más', 'start_time': 222543, 'end_time': 222723, 'speaker': 0}, {'word': 'información', 'start_time': 222803, 'end_time': 223344, 'speaker': 0}, {'word': 'sobre', 'start_time': 223624, 'end_time': 224285, 'speaker': 0}, {'word': 'el', 'start_time': 226328, 'end_time': 226408, 'speaker': 0}, {'word': 'programa.', 'start_time': 226469, 'end_time': 226869, 'speaker': 0}, {'word': 'Permíteme', 'start_time': 227270, 'end_time': 227791, 'speaker': 0}, {'word': 'un', 'start_time': 227811, 'end_time': 227851, 'speaker': 0}, {'word': 'momento,', 'start_time': 227891, 'end_time': 228211, 'speaker': 0}, {'word': 'te', 'start_time': 228231, 'end_time': 228271, 'speaker': 0}, {'word': 'doy', 'start_time': 228532, 'end_time': 228752, 'speaker': 0}, {'word': 'el', 'start_time': 228812, 'end_time': 228872, 'speaker': 0}, {'word': 'dato', 'start_time': 228952, 'end_time': 229213, 'speaker': 0}, {'word': 'de', 'start_time': 229253, 'end_time': 229333, 'speaker': 0}, {'word': 'la', 'start_time': 229373, 'end_time': 229453, 'speaker': 0}, {'word': 'persona', 'start_time': 229513, 'end_time': 229814, 'speaker': 0}, {'word': 'encargada.', 'start_time': 229874, 'end_time': 230394, 'speaker': 0}, {'word': 'Muchas', 'start_time': 230935, 'end_time': 232337, 'speaker': 0}, {'word': 'gracias.', 'start_time': 232437, 'end_time': 232778, 'speaker': 1}, {'word': 'El', 'start_time': 263305, 'end_time': 263405, 'speaker': 0}, {'word': 'nombre', 'start_time': 263485, 'end_time': 263745, 'speaker': 0}, {'word': 'del', 'start_time': 263785, 'end_time': 263925, 'speaker': 0}, {'word': 'profesional', 'start_time': 264005, 'end_time': 264686, 'speaker': 0}, {'word': 'a', 'start_time': 264746, 'end_time': 264766, 'speaker': 0}, {'word': 'cargo', 'start_time': 264866, 'end_time': 265246, 'speaker': 0}, {'word': 'es', 'start_time': 265366, 'end_time': 265466, 'speaker': 0}, {'word': 'Laura', 'start_time': 265546, 'end_time': 265906, 'speaker': 0}, {'word': 'Correa', 'start_time': 265986, 'end_time': 266427, 'speaker': 0}, {'word': 'y', 'start_time': 266447, 'end_time': 266467, 'speaker': 0}, {'word': 'su', 'start_time': 266767, 'end_time': 266887, 'speaker': 0}, {'word': 'número', 'start_time': 266967, 'end_time': 267267, 'speaker': 0}, {'word': 'de', 'start_time': 267307, 'end_time': 267387, 'speaker': 0}, {'word': 'WhatsApp', 'start_time': 267467, 'end_time': 268028, 'speaker': 0}, {'word': 'es...', 'start_time': 268348, 'end_time': 268568, 'speaker': 0}, {'word': '¿Cuál?', 'start_time': 269609, 'end_time': 270209, 'speaker': 1}, {'word': 'Tres', 'start_time': 271930, 'end_time': 273411, 'speaker': 1}, {'word': 'once', 'start_time': 273511, 'end_time': 273832, 'speaker': 0}, {'word': 'cuatro', 'start_time': 274052, 'end_time': 274332, 'speaker': 0}, {'word': 'cincuenta', 'start_time': 274412, 'end_time': 274892, 'speaker': 0}, {'word': 'y', 'start_time': 274932, 'end_time': 274992, 'speaker': 0}, {'word': 'ocho.', 'start_time': 275093, 'end_time': 275333, 'speaker': 0}, {'word': 'Ajá.', 'start_time': 275353, 'end_time': 277594, 'speaker': 0}, {'word': 'Cuarenta', 'start_time': 277654, 'end_time': 277994, 'speaker': 0}, {'word': 'y', 'start_time': 278015, 'end_time': 278055, 'speaker': 0}, {'word': 'cuatro', 'start_time': 278135, 'end_time': 278395, 'speaker': 0}, {'word': 'sesenta', 'start_time': 278475, 'end_time': 278835, 'speaker': 0}, {'word': 'y', 'start_time': 278875, 'end_time': 278915, 'speaker': 0}, {'word': 'tres.', 'start_time': 279015, 'end_time': 279295, 'speaker': 0}, {'word': 'Recuerda', 'start_time': 279976, 'end_time': 280316, 'speaker': 0}, {'word': 'que', 'start_time': 280356, 'end_time': 280476, 'speaker': 0}, {'word': 'este', 'start_time': 280516, 'end_time': 280736, 'speaker': 0}, {'word': 'número', 'start_time': 280816, 'end_time': 281137, 'speaker': 0}, {'word': 'es', 'start_time': 281277, 'end_time': 281397, 'speaker': 0}, {'word': 'un', 'start_time': 281457, 'end_time': 281537, 'speaker': 0}, {'word': 'contacto', 'start_time': 281597, 'end_time': 282097, 'speaker': 0}, {'word': 'de', 'start_time': 282297, 'end_time': 282477, 'speaker': 0}, {'word': 'WhatsApp,', 'start_time': 282638, 'end_time': 283118, 'speaker': 0}, {'word': 'así', 'start_time': 283218, 'end_time': 283378, 'speaker': 0}, {'word': 'que', 'start_time': 283398, 'end_time': 283518, 'speaker': 0}, {'word': 'debes', 'start_time': 283578, 'end_time': 283778, 'speaker': 0}, {'word': 'escribirle,', 'start_time': 283858, 'end_time': 284599, 'speaker': 0}, {'word': 'no', 'start_time': 285219, 'end_time': 285359, 'speaker': 0}, {'word': 'es', 'start_time': 285439, 'end_time': 285520, 'speaker': 0}, {'word': 'de', 'start_time': 285540, 'end_time': 285640, 'speaker': 0}, {'word': 'llamadas.', 'start_time': 285680, 'end_time': 286160, 'speaker': 0}, {'word': 'Y', 'start_time': 286753, 'end_time': 286833, 'speaker': 0}, {'word': 'el', 'start_time': 286893, 'end_time': 286973, 'speaker': 0}, {'word': 'correo', 'start_time': 287033, 'end_time': 287353, 'speaker': 0}, {'word': 'de', 'start_time': 287373, 'end_time': 287453, 'speaker': 0}, {'word': 'Laura', 'start_time': 287493, 'end_time': 287854, 'speaker': 0}, {'word': 'es', 'start_time': 287954, 'end_time': 288074, 'speaker': 0}, {'word': 'laura.correa', 'start_time': 288174, 'end_time': 289435, 'speaker': 0}, {'word': 'Bueno,', 'start_time': 291236, 'end_time': 292876, 'speaker': 1}, {'word': 'laura.correa,', 'start_time': 292916, 'end_time': 293457, 'speaker': 1}, {'word': 'todo', 'start_time': 293477, 'end_time': 293757, 'speaker': 1}, {'word': 'en', 'start_time': 293857, 'end_time': 294357, 'speaker': 1}, {'word': 'minúscula,', 'start_time': 294397, 'end_time': 295118, 'speaker': 1}, {'word': '¿cierto?', 'start_time': 295198, 'end_time': 295498, 'speaker': 1}, {'word': 'Sí,', 'start_time': 295898, 'end_time': 296098, 'speaker': 0}, {'word': 'y', 'start_time': 296238, 'end_time': 296358, 'speaker': 0}, {'word': 'junto,', 'start_time': 296518, 'end_time': 296899, 'speaker': 0}, {'word': 'vdevaca', 'start_time': 298059, 'end_time': 298820, 'speaker': 0}, {'word': 'arroba', 'start_time': 301781, 'end_time': 302222, 'speaker': 0}, {'word': 'javerianacali', 'start_time': 302242, 'end_time': 303262, 'speaker': 0}, {'word': 'punto', 'start_time': 306284, 'end_time': 306584, 'speaker': 0}, {'word': 'edu', 'start_time': 306604, 'end_time': 307104, 'speaker': 0}, {'word': 'punto', 'start_time': 307164, 'end_time': 307504, 'speaker': 0}, {'word': 'co', 'start_time': 307584, 'end_time': 307885, 'speaker': 0}, {'word': 'edu', 'start_time': 308925, 'end_time': 309225, 'speaker': 1}, {'word': 'punto', 'start_time': 309305, 'end_time': 309586, 'speaker': 1}, {'word': 'co', 'start_time': 309866, 'end_time': 310146, 'speaker': 1}, {'word': 'punto', 'start_time': 310606, 'end_time': 310966, 'speaker': 0}, {'word': 'edu', 'start_time': 311307, 'end_time': 311587, 'speaker': 0}, {'word': 'punto', 'start_time': 311727, 'end_time': 312047, 'speaker': 0}, {'word': 'co', 'start_time': 312107, 'end_time': 312447, 'speaker': 0}, {'word': 'Listo.', 'start_time': 312927, 'end_time': 313408, 'speaker': 1}, {'word': 'Entonces', 'start_time': 314601, 'end_time': 315302, 'speaker': 0}, {'word': 'más', 'start_time': 315362, 'end_time': 315442, 'speaker': 0}, {'word': 'bien', 'start_time': 315542, 'end_time': 315722, 'speaker': 0}, {'word': 'le', 'start_time': 315762, 'end_time': 315842, 'speaker': 0}, {'word': 'escribes', 'start_time': 315922, 'end_time': 316263, 'speaker': 0}, {'word': 'a', 'start_time': 316343, 'end_time': 316423, 'speaker': 0}, {'word': 'ella', 'start_time': 316643, 'end_time': 316883, 'speaker': 0}, {'word': 'para', 'start_time': 316983, 'end_time': 317143, 'speaker': 0}, {'word': 'que', 'start_time': 317203, 'end_time': 317283, 'speaker': 0}, {'word': 'ella', 'start_time': 317323, 'end_time': 317444, 'speaker': 0}, {'word': 'te', 'start_time': 317484, 'end_time': 317584, 'speaker': 0}, {'word': 'pueda', 'start_time': 317624, 'end_time': 317804, 'speaker': 0}, {'word': 'ampliar', 'start_time': 317864, 'end_time': 318144, 'speaker': 0}, {'word': 'la', 'start_time': 318184, 'end_time': 318244, 'speaker': 0}, {'word': 'información,', 'start_time': 318284, 'end_time': 318765, 'speaker': 0}, {'word': 'ya', 'start_time': 318785, 'end_time': 318825, 'speaker': 0}, {'word': 'que', 'start_time': 319025, 'end_time': 319105, 'speaker': 0}, {'word': 'por', 'start_time': 320066, 'end_time': 320186, 'speaker': 0}, {'word': 'el', 'start_time': 320246, 'end_time': 320326, 'speaker': 0}, {'word': 'otro', 'start_time': 320386, 'end_time': 320566, 'speaker': 0}, {'word': 'número', 'start_time': 320606, 'end_time': 320886, 'speaker': 0}, {'word': 'no', 'start_time': 320946, 'end_time': 321026, 'speaker': 0}, {'word': 'te', 'start_time': 321086, 'end_time': 321186, 'speaker': 0}, {'word': 'contestan,', 'start_time': 321267, 'end_time': 321867, 'speaker': 0}, {'word': 'pero', 'start_time': 322367, 'end_time': 322668, 'speaker': 0}, {'word': 'bueno,', 'start_time': 324109, 'end_time': 324269, 'speaker': 0}, {'word': 'sí,', 'start_time': 324369, 'end_time': 324489, 'speaker': 0}, {'word': 'escríbele', 'start_time': 324969, 'end_time': 325390, 'speaker': 0}, {'word': 'a', 'start_time': 325410, 'end_time': 325470, 'speaker': 0}, {'word': 'ella', 'start_time': 325530, 'end_time': 325710, 'speaker': 0}, {'word': 'y', 'start_time': 325790, 'end_time': 325850, 'speaker': 0}, {'word': 'ella', 'start_time': 325870, 'end_time': 326010, 'speaker': 0}, {'word': 'ya', 'start_time': 326030, 'end_time': 326150, 'speaker': 0}, {'word': 'te', 'start_time': 326210, 'end_time': 326290, 'speaker': 0}, {'word': 'brinda', 'start_time': 326330, 'end_time': 326611, 'speaker': 0}, {'word': 'la', 'start_time': 326671, 'end_time': 326731, 'speaker': 0}, {'word': 'información.', 'start_time': 326771, 'end_time': 327291, 'speaker': 0}, {'word': 'Pero', 'start_time': 328812, 'end_time': 328993, 'speaker': 1}, {'word': 'ella', 'start_time': 329053, 'end_time': 329233, 'speaker': 1}, {'word': 'hoy', 'start_time': 329253, 'end_time': 329413, 'speaker': 1}, {'word': 'no', 'start_time': 329453, 'end_time': 329553, 'speaker': 1}, {'word': 'atiende,', 'start_time': 329573, 'end_time': 329933, 'speaker': 1}, {'word': '¿cierto', 'start_time': 329993, 'end_time': 330133, 'speaker': 1}, {'word': 'que', 'start_time': 330153, 'end_time': 330254, 'speaker': 1}, {'word': 'no?', 'start_time': 330434, 'end_time': 330574, 'speaker': 1}, {'word': 'Es', 'start_time': 330994, 'end_time': 331094, 'speaker': 0}, {'word': 'que', 'start_time': 331154, 'end_time': 331234, 'speaker': 0}, {'word': 'eso', 'start_time': 331254, 'end_time': 331394, 'speaker': 0}, {'word': 'es', 'start_time': 331435, 'end_time': 331475, 'speaker': 0}, {'word': 'lo', 'start_time': 331515, 'end_time': 331575, 'speaker': 0}, {'word': 'que', 'start_time': 331595, 'end_time': 331675, 'speaker': 0}, {'word': 'te', 'start_time': 331735, 'end_time': 331795, 'speaker': 0}, {'word': 'iba', 'start_time': 331815, 'end_time': 331895, 'speaker': 0}, {'word': 'a', 'start_time': 331915, 'end_time': 331935, 'speaker': 0}, {'word': 'decir,', 'start_time': 331975, 'end_time': 332155, 'speaker': 0}, {'word': 'pero', 'start_time': 332255, 'end_time': 332455, 'speaker': 0}, {'word': 'no', 'start_time': 332515, 'end_time': 332595, 'speaker': 0}, {'word': 'sé', 'start_time': 332615, 'end_time': 332655, 'speaker': 0}, {'word': 'si', 'start_time': 332675, 'end_time': 332716, 'speaker': 0}, {'word': 'de', 'start_time': 332756, 'end_time': 333016, 'speaker': 0}, {'word': 'pronto', 'start_time': 333136, 'end_time': 333496, 'speaker': 0}, {'word': 'a', 'start_time': 333516, 'end_time': 333536, 'speaker': 0}, {'word': 'ella', 'start_time': 333756, 'end_time': 334977, 'speaker': 0}, {'word': 'el', 'start_time': 335237, 'end_time': 335318, 'speaker': 0}, {'word': 'día', 'start_time': 335338, 'end_time': 335478, 'speaker': 0}, {'word': 'de', 'start_time': 335518, 'end_time': 335618, 'speaker': 0}, {'word': 'hoy', 'start_time': 335638, 'end_time': 335738, 'speaker': 0}, {'word': 'le', 'start_time': 335778, 'end_time': 335878, 'speaker': 0}, {'word': 'toque', 'start_time': 335898, 'end_time': 336138, 'speaker': 0}, {'word': 'la', 'start_time': 336198, 'end_time': 336258, 'speaker': 0}, {'word': 'oral,', 'start_time': 336338, 'end_time': 336579, 'speaker': 0}, {'word': 'no', 'start_time': 336659, 'end_time': 336759, 'speaker': 0}, {'word': 'sé', 'start_time': 336839, 'end_time': 336999, 'speaker': 0}, {'word': 'cómo', 'start_time': 337119, 'end_time': 337279, 'speaker': 0}, {'word': 'esté', 'start_time': 337339, 'end_time': 337539, 'speaker': 0}, {'word': 'en', 'start_time': 337579, 'end_time': 337639, 'speaker': 0}, {'word': 'los', 'start_time': 337679, 'end_time': 337759, 'speaker': 0}, {'word': 'horarios', 'start_time': 337800, 'end_time': 338100, 'speaker': 0}, {'word': 'de', 'start_time': 338160, 'end_time': 338220, 'speaker': 0}, {'word': 'la', 'start_time': 338260, 'end_time': 338340, 'speaker': 0}, {'word': 'oral.', 'start_time': 338400, 'end_time': 338560, 'speaker': 0}, {'word': 'En', 'start_time': 338620, 'end_time': 338840, 'speaker': 0}, {'word': 'WhatsApp', 'start_time': 339221, 'end_time': 340101, 'speaker': 1}, {'word': 'aparece', 'start_time': 340121, 'end_time': 340482, 'speaker': 1}, {'word': 'que', 'start_time': 340582, 'end_time': 341202, 'speaker': 1}, {'word': 'está', 'start_time': 341302, 'end_time': 341643, 'speaker': 1}, {'word': 'cerrado', 'start_time': 341703, 'end_time': 342023, 'speaker': 1}, {'word': 'todos', 'start_time': 342103, 'end_time': 342283, 'speaker': 1}, {'word': 'los', 'start_time': 342303, 'end_time': 342403, 'speaker': 1}, {'word': 'días', 'start_time': 342443, 'end_time': 342703, 'speaker': 1}, {'word': 'menos', 'start_time': 342723, 'end_time': 342924, 'speaker': 1}, {'word': 'los', 'start_time': 342964, 'end_time': 343064, 'speaker': 1}, {'word': 'viernes.', 'start_time': 343124, 'end_time': 343404, 'speaker': 1}, {'word': 'O', 'start_time': 344247, 'end_time': 345788, 'speaker': 1}, {'word': 'sea,', 'start_time': 345808, 'end_time': 346388, 'speaker': 1}, {'word': 'los', 'start_time': 347348, 'end_time': 347428, 'speaker': 1}, {'word': 'viernes', 'start_time': 347588, 'end_time': 347969, 'speaker': 1}, {'word': 'de', 'start_time': 348089, 'end_time': 348229, 'speaker': 1}, {'word': 'ocho', 'start_time': 348349, 'end_time': 348589, 'speaker': 1}, {'word': 'a', 'start_time': 348609, 'end_time': 348629, 'speaker': 1}, {'word': 'ocho', 'start_time': 348889, 'end_time': 349069, 'speaker': 1}, {'word': 'y', 'start_time': 349089, 'end_time': 349129, 'speaker': 1}, {'word': 'cinco', 'start_time': 349189, 'end_time': 349449, 'speaker': 1}, {'word': 'AM.', 'start_time': 349489, 'end_time': 350069, 'speaker': 1}, {'word': 'Ok,', 'start_time': 350129, 'end_time': 350510, 'speaker': 0}, {'word': 'escríbele', 'start_time': 350590, 'end_time': 351290, 'speaker': 0}, {'word': 'y', 'start_time': 351410, 'end_time': 351490, 'speaker': 0}, {'word': 'ella', 'start_time': 351650, 'end_time': 351850, 'speaker': 0}, {'word': 'ya', 'start_time': 351910, 'end_time': 352070, 'speaker': 0}, {'word': 'te', 'start_time': 352630, 'end_time': 352731, 'speaker': 0}, {'word': 'brindará', 'start_time': 352771, 'end_time': 353171, 'speaker': 0}, {'word': 'toda', 'start_time': 353271, 'end_time': 353431, 'speaker': 0}, {'word': 'la', 'start_time': 353491, 'end_time': 353531, 'speaker': 0}, {'word': 'información', 'start_time': 353571, 'end_time': 354131, 'speaker': 0}, {'word': 'o', 'start_time': 354151, 'end_time': 354171, 'speaker': 0}, {'word': 'comunícate', 'start_time': 354411, 'end_time': 355031, 'speaker': 0}, {'word': 'por', 'start_time': 355111, 'end_time': 355252, 'speaker': 0}, {'word': 'el', 'start_time': 355292, 'end_time': 355392, 'speaker': 0}, {'word': 'otro', 'start_time': 355472, 'end_time': 355772, 'speaker': 0}, {'word': 'número', 'start_time': 355872, 'end_time': 356192, 'speaker': 0}, {'word': 'que', 'start_time': 356252, 'end_time': 356352, 'speaker': 0}, {'word': 'te', 'start_time': 356452, 'end_time': 356712, 'speaker': 0}, {'word': 'acabo', 'start_time': 356912, 'end_time': 357212, 'speaker': 0}, {'word': 'de', 'start_time': 357252, 'end_time': 357312, 'speaker': 0}, {'word': 'brindar.', 'start_time': 357352, 'end_time': 357713, 'speaker': 0}, {'word': 'Muchísimas', 'start_time': 359733, 'end_time': 360093, 'speaker': 1}, {'word': 'gracias.', 'start_time': 360113, 'end_time': 360374, 'speaker': 1}, {'word': 'Con', 'start_time': 360414, 'end_time': 360494, 'speaker': 1}, {'word': 'gusto,', 'start_time': 360534, 'end_time': 360774, 'speaker': 1}, {'word': 'hasta', 'start_time': 360794, 'end_time': 361014, 'speaker': 0}, {'word': 'luego.', 'start_time': 361034, 'end_time': 361274, 'speaker': 0}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ruxc8S1EXtW"
      },
      "source": [
        "## Realligning Speech segments using Punctuation\n",
        "---\n",
        "\n",
        "This code provides a method for disambiguating speaker labels in cases where a sentence is split between two different speakers. It uses punctuation markings to determine the dominant speaker for each sentence in the transcription.\n",
        "\n",
        "```\n",
        "Speaker A: It's got to come from somewhere else. Yeah, that one's also fun because you know the lows are\n",
        "Speaker B: going to suck, right? So it's actually it hits you on both sides.\n",
        "```\n",
        "\n",
        "For example, if a sentence is split between two speakers, the code takes the mode of speaker labels for each word in the sentence, and uses that speaker label for the whole sentence. This can help to improve the accuracy of speaker diarization, especially in cases where the Whisper model may not take fine utterances like \"hmm\" and \"yeah\" into account, but the Diarization Model (Nemo) may include them, leading to inconsistent results.\n",
        "\n",
        "The code also handles cases where one speaker is giving a monologue while other speakers are making occasional comments in the background. It ignores the comments and assigns the entire monologue to the speaker who is speaking the majority of the time. This provides a robust and reliable method for realigning speech segments to their respective speakers based on punctuation in the transcription."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgfC5hA41BXu",
        "outputId": "a23a56c6-d2f5-4504-e81e-d46c4b1028f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "7804b32e55784165abad6e91ce95253a",
            "00b0ded93cec4ea2897261ae0b81c98a",
            "739ad7ba6b9f4719b1e099890eeb0fc2",
            "ca018c1daefe4aecb390bb76f87f0a28",
            "ea53fd9f9564421e95d837ac1585ad56",
            "0463281965614b818900fca48032ba30",
            "396328b5d96d438082e99a7922328573",
            "1cc829ae815d4595875c33e294dad8eb",
            "7ba6f81e0be74a529b35bf279fa619d4",
            "a7fba5eecb974ab39fef405abd56d442",
            "0512760b3c574326bd26914bd9fb0dd9",
            "0a28b47772b94fd78de612a3e027b96c",
            "ffed692863bd40408a5dd1a27b57d97a",
            "f7105121e9bb42eb8f4073751f73be0c",
            "716cdd2d4f4e40e2be07a73a322e62b2",
            "79526b987072410b91d18c77884796bd",
            "64f9a8856d3249e39e04b2bada2a0224",
            "a2d982fbca7d4e3b88982ec785fe43c9",
            "92f29d594e3d4debb7fad47a18d0ff2f",
            "1da3c50f534741f1a9a8d7c06d3e1122",
            "db81cd424253471e9c32dbddc2717bed",
            "3aa6d016c6a94c4e96781e52d2cb394e",
            "b65741d2ebb94003b1cf2c12d04f3d57",
            "eef8f13c3aba43fdbdf9857de7ef2209",
            "0d2387bfe4014a359e3b4142bc839f1a",
            "3dd938d27ef34150b30f185f7a31dc92",
            "5d8699facbf94132bc45922c6f5adaba",
            "0fcb9cbf37bb42fab8c63f52179a84ad",
            "5ba2024463b5403894df8de9ec907523",
            "b9ca0bae6bb74bbf89f6891193f3070a",
            "ca48d213dbcc43faa408b1506614d899",
            "bd2dbf24ec3f4f74a638adc330b502b5",
            "ffcdcddd045b4018bda632292f034a09",
            "d27f1f1b1d9b438a8a90fd63f9052eed",
            "1723cd4ca07147a6ab8f8116906efbdc",
            "d134d5df4e3f4f919bdb7afe86a83cca",
            "7b23caa1446e43088e6e6a0e5cf9eca8",
            "d13ae54a0f8d4b00b660477d81c3f668",
            "b60fe8c182544d31b3c39885f7da6b8c",
            "1b1c28f6fddd442cb4aa3f3b29f702c2",
            "64c790466c8b46c6abfee5dc257b78df",
            "1b2a130378794e4d9f3834f836620523",
            "f81e123bcbb845ba8fbb998dfc1cd084",
            "8822166341414125b16ecc6cf6040fb7",
            "e8cb6f24f910452d9d062ed2e7892253",
            "17023a4f10dc4df6a56975bdb616cd48",
            "498ae801f830431c8322138e22a4e4b1",
            "56164122d8464606b126f7f7dffea1b1",
            "79dc6ad0078e46b1ae565f1c1fcff10c",
            "61392568360b42629762d61a445975a1",
            "fccaee18ec824375ad1e552701373a5f",
            "7ade71e71e094619a856dfe37b6de8cc",
            "2302fc381f15427e9c1f560832e61b36",
            "ed1713926d954eec99197ca70af91953",
            "871a115d294e45288cf45153d4156677"
          ],
          "height": 212
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/914 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7804b32e55784165abad6e91ce95253a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a28b47772b94fd78de612a3e027b96c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/447 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b65741d2ebb94003b1cf2c12d04f3d57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d27f1f1b1d9b438a8a90fd63f9052eed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8cb6f24f910452d9d062ed2e7892253"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.41 s, sys: 4.8 s, total: 12.2 s\n",
            "Wall time: 20.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "if language in punct_model_langs:\n",
        "    # restoring punctuation in the transcript to help realign the sentences\n",
        "    punct_model = PunctuationModel(model=\"kredor/punctuate-all\")\n",
        "\n",
        "    words_list = list(map(lambda x: x[\"word\"], wsm))\n",
        "\n",
        "    labled_words = punct_model.predict(words_list)\n",
        "\n",
        "    ending_puncts = \".?!\"\n",
        "    model_puncts = \".,;:!?\"\n",
        "\n",
        "    # We don't want to punctuate U.S.A. with a period. Right?\n",
        "    is_acronym = lambda x: re.fullmatch(r\"\\b(?:[a-zA-Z]\\.){2,}\", x)\n",
        "\n",
        "    for word_dict, labeled_tuple in zip(wsm, labled_words):\n",
        "        word = word_dict[\"word\"]\n",
        "        if (\n",
        "            word\n",
        "            and labeled_tuple[1] in ending_puncts\n",
        "            and (word[-1] not in model_puncts or is_acronym(word))\n",
        "        ):\n",
        "            word += labeled_tuple[1]\n",
        "            if word.endswith(\"..\"):\n",
        "                word = word.rstrip(\".\")\n",
        "            word_dict[\"word\"] = word\n",
        "\n",
        "else:\n",
        "    logging.warning(\n",
        "        f\"Punctuation restoration is not available for {language} language. Using the original punctuation.\"\n",
        "    )\n",
        "\n",
        "wsm = get_realigned_ws_mapping_with_punctuation(wsm)\n",
        "ssm = get_sentences_speaker_mapping(wsm, speaker_ts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ssm)"
      ],
      "metadata": {
        "id": "9iU-CSQJ6wEf",
        "outputId": "d2f54802-1c7e-497e-d2c4-8000813366bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'speaker': 'Speaker 0', 'start_time': 0, 'end_time': 5191, 'text': 'Buen día, le habla Vanessa. '}, {'speaker': 'Speaker 1', 'start_time': 5211, 'end_time': 6191, 'text': '¿En qué le puedo ayudar? '}, {'speaker': 'Speaker 1', 'start_time': 6211, 'end_time': 7552, 'text': 'Hola, buenos días. '}, {'speaker': 'Speaker 1', 'start_time': 7572, 'end_time': 8512, 'text': 'Habla Joan Camilo. '}, {'speaker': 'Speaker 1', 'start_time': 9293, 'end_time': 10613, 'text': 'Perdona la bulla. '}, {'speaker': 'Speaker 1', 'start_time': 11934, 'end_time': 16236, 'text': 'Lo que pasa es que a mí me interesaría ingresar a estudiar enfermería. '}, {'speaker': 'Speaker 0', 'start_time': 18256, 'end_time': 20057, 'text': 'Dime, ya terminaste. '}, {'speaker': 'Speaker 0', 'start_time': 20277, 'end_time': 21978, 'text': 'Dime. '}, {'speaker': 'Speaker 1', 'start_time': 21998, 'end_time': 22258, 'text': 'Perdón. '}, {'speaker': 'Speaker 1', 'start_time': 22691, 'end_time': 37058, 'text': 'Este, me gustaría empezar a estudiar enfermería, yo ya tengo bachiller, yo tengo dos títulos, bueno, un título, estoy cursando el último, estoy haciendo las prácticas, pero pues yo quisiera como averiguar con tiempo, ¿me hago entender? '}, {'speaker': 'Speaker 0', 'start_time': 38078, 'end_time': 39799, 'text': 'Sí, ¿y qué deseas saber? '}, {'speaker': 'Speaker 1', 'start_time': 41340, 'end_time': 47243, 'text': 'Yo quiero estudiar enfermería, pero pues mis recursos, la verdad, son como un poco limitados. '}, {'speaker': 'Speaker 1', 'start_time': 47363, 'end_time': 60475, 'text': 'y a mí me llegaron a hablar sobre una beca, algo que se llama como la generación E. Tengo como dos, tres compañeros allá en donde estoy haciendo mis prácticas que me hablaron de eso, que ellos estudiaron en diferentes universidades. '}, {'speaker': 'Speaker 1', 'start_time': 60495, 'end_time': 68000, 'text': 'y pues yo estuve mirando como en las páginas y sale la opción de esa beca, como inscribirse a eso. '}, {'speaker': 'Speaker 1', 'start_time': 69180, 'end_time': 73783, 'text': 'Yo la verdad no conozco muy bien sobre el proceso, ellos pues no me explicaron bien. '}, {'speaker': 'Speaker 0', 'start_time': 74324, 'end_time': 75824, 'text': '¿A qué número marcaste? '}, {'speaker': 'Speaker 0', 'start_time': 77025, 'end_time': 78886, 'text': '¿Cuál fue el número? '}, {'speaker': 'Speaker 0', 'start_time': 79187, 'end_time': 81208, 'text': 'Sí, en este momento, ¿qué número marcaste? '}, {'speaker': 'Speaker 1', 'start_time': 82955, 'end_time': 88917, 'text': 'Un seis cero dos tres noventa y ocho once cuarenta y siete, porque ya me hago como un tres veintiuno, creo. '}, {'speaker': 'Speaker 1', 'start_time': 89697, 'end_time': 93938, 'text': 'También que me salió en la plataforma, pero no contestan nada, o sea, no, nada. '}, {'speaker': 'Speaker 0', 'start_time': 93978, 'end_time': 102720, 'text': 'Debes de comunicarte por ese medio para que te puedan transferir al área financiera, que en eso, que te pueden brindar información sobre esta beca. '}, {'speaker': 'Speaker 1', 'start_time': 105661, 'end_time': 108882, 'text': 'Una pregunta, ¿qué me podrían dar información sobre la carrera en sí? '}, {'speaker': 'Speaker 1', 'start_time': 109502, 'end_time': 109702, 'text': 'Sí. '}, {'speaker': 'Speaker 1', 'start_time': 109782, 'end_time': 110622, 'text': 'La parte de la beca. '}, {'speaker': 'Speaker 1', 'start_time': 110984, 'end_time': 117228, 'text': '¿Me puedes, por favor, dar información para saber más o menos también? '}, {'speaker': 'Speaker 0', 'start_time': 117248, 'end_time': 132156, 'text': 'Mira, si estás interesado para el dos mil veintitrés, ya están abiertas las inscripciones, siempre los valores anualmente cambian, así que si estás interesado para otro año, deberás consultar nuevamente que la información sea actualizada para ese año de ingreso. '}, {'speaker': 'Speaker 0', 'start_time': 132937, 'end_time': 146864, 'text': 'Tiene una duración de nueve semestres, es completamente presencial, La inscripción tiene un valor de USD-CAD y el semestre de USD-CAD . '}, {'speaker': 'Speaker 0', 'start_time': 146864, 'end_time': 151265, 'text': 'El proceso de inscripción debes realizarlo completamente virtual. '}, {'speaker': 'Speaker 0', 'start_time': 151725, 'end_time': 163728, 'text': 'Debes adjuntar tu documento de identidad, las notas certificado original de notas de noveno a once y el resultado de las pruebas AVER con un puntaje mínimo obtenido de doscientos cincuenta puntos en adelante. '}, {'speaker': 'Speaker 0', 'start_time': 164449, 'end_time': 174394, 'text': 'Una vez te eligencies el formulario de inscripción y pagues los derechos de inscripción, al correo se te va a enviar una cita para que presentes una entrevista con el director del programa. '}, {'speaker': 'Speaker 0', 'start_time': 174914, 'end_time': 179016, 'text': 'Después de la entrevista se te enviará el resultado de admisión por correo electrónico. '}, {'speaker': 'Speaker 0', 'start_time': 180337, 'end_time': 189682, 'text': 'Nosotros desde la universidad realizamos procesos de homologación, pero solamente si es de un pregrado a otro pregrado. '}, {'speaker': 'Speaker 1', 'start_time': 189802, 'end_time': 190082, 'text': 'Listo. '}, {'speaker': 'Speaker 1', 'start_time': 191396, 'end_time': 197000, 'text': 'Entonces, en cuestión para lo de la beca de esas generaciones, yo tengo que llamar esa al tres veintiuno, ¿cierto? '}, {'speaker': 'Speaker 0', 'start_time': 197161, 'end_time': 198041, 'text': 'Sí, señor. '}, {'speaker': 'Speaker 0', 'start_time': 198241, 'end_time': 201284, 'text': 'Y solicitar que te comuniquen con área financiera. '}, {'speaker': 'Speaker 1', 'start_time': 202485, 'end_time': 202885, 'text': 'Listo. '}, {'speaker': 'Speaker 1', 'start_time': 203366, 'end_time': 207469, 'text': 'Yo voy a... ¿Voy a qué? '}, {'speaker': 'Speaker 1', 'start_time': 207489, 'end_time': 209931, 'text': '¿Me puedes dar el número, por favor? '}, {'speaker': 'Speaker 1', 'start_time': 210151, 'end_time': 212133, 'text': 'O permíteme mejor. '}, {'speaker': 'Speaker 0', 'start_time': 212153, 'end_time': 216757, 'text': 'Te voy a compartir mejor el contacto del profesional a cargo de la carrera. '}, {'speaker': 'Speaker 0', 'start_time': 217455, 'end_time': 226869, 'text': 'para que esta persona te pueda orientar sobre la beca y te pueda abrir más información sobre el programa. '}, {'speaker': 'Speaker 0', 'start_time': 227270, 'end_time': 230394, 'text': 'Permíteme un momento, te doy el dato de la persona encargada. '}, {'speaker': 'Speaker 0', 'start_time': 230935, 'end_time': 232778, 'text': 'Muchas gracias. '}, {'speaker': 'Speaker 0', 'start_time': 263305, 'end_time': 268568, 'text': 'El nombre del profesional a cargo es Laura Correa y su número de WhatsApp es... '}, {'speaker': 'Speaker 1', 'start_time': 269609, 'end_time': 270209, 'text': '¿Cuál? '}, {'speaker': 'Speaker 0', 'start_time': 271930, 'end_time': 275333, 'text': 'Tres once cuatro cincuenta y ocho. '}, {'speaker': 'Speaker 0', 'start_time': 275353, 'end_time': 277594, 'text': 'Ajá. '}, {'speaker': 'Speaker 0', 'start_time': 277654, 'end_time': 279295, 'text': 'Cuarenta y cuatro sesenta y tres. '}, {'speaker': 'Speaker 0', 'start_time': 279976, 'end_time': 286160, 'text': 'Recuerda que este número es un contacto de WhatsApp, así que debes escribirle, no es de llamadas. '}, {'speaker': 'Speaker 0', 'start_time': 286753, 'end_time': 289435, 'text': 'Y el correo de Laura es laura.correa. '}, {'speaker': 'Speaker 1', 'start_time': 291236, 'end_time': 295498, 'text': 'Bueno, laura.correa, todo en minúscula, ¿cierto? '}, {'speaker': 'Speaker 0', 'start_time': 295898, 'end_time': 307104, 'text': 'Sí, y junto, vdevaca arroba javerianacali punto edu. '}, {'speaker': 'Speaker 0', 'start_time': 307164, 'end_time': 313408, 'text': 'punto co edu punto co punto edu punto co Listo. '}, {'speaker': 'Speaker 0', 'start_time': 314601, 'end_time': 327291, 'text': 'Entonces más bien le escribes a ella para que ella te pueda ampliar la información, ya que por el otro número no te contestan, pero bueno, sí, escríbele a ella y ella ya te brinda la información. '}, {'speaker': 'Speaker 1', 'start_time': 328812, 'end_time': 330574, 'text': 'Pero ella hoy no atiende, ¿cierto que no? '}, {'speaker': 'Speaker 0', 'start_time': 330994, 'end_time': 338560, 'text': 'Es que eso es lo que te iba a decir, pero no sé si de pronto a ella el día de hoy le toque la oral, no sé cómo esté en los horarios de la oral. '}, {'speaker': 'Speaker 1', 'start_time': 338620, 'end_time': 343404, 'text': 'En WhatsApp aparece que está cerrado todos los días menos los viernes. '}, {'speaker': 'Speaker 1', 'start_time': 344247, 'end_time': 350069, 'text': 'O sea, los viernes de ocho a ocho y cinco AM. '}, {'speaker': 'Speaker 0', 'start_time': 350129, 'end_time': 357713, 'text': 'Ok, escríbele y ella ya te brindará toda la información o comunícate por el otro número que te acabo de brindar. '}, {'speaker': 'Speaker 1', 'start_time': 359733, 'end_time': 360374, 'text': 'Muchísimas gracias. '}, {'speaker': 'Speaker 0', 'start_time': 360414, 'end_time': 361274, 'text': 'Con gusto, hasta luego. '}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF2QAtLOFvwZ"
      },
      "source": [
        "## Cleanup and downloading the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFTyKI6B1MI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5daed022-7050-473e-9a90-047e9a71e958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.6 ms, sys: 2.66 ms, total: 6.26 ms\n",
            "Wall time: 9.82 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "path_textfile_with_speakers = f\"{os.path.splitext(audio_path)[0]}.txt\"\n",
        "path_srtfile_with_speakers = f\"{os.path.splitext(audio_path)[0]}.srt\"\n",
        "\n",
        "with open(path_textfile_with_speakers, \"w\", encoding=\"utf-8-sig\") as f:\n",
        "    get_speaker_aware_transcript(ssm, f)\n",
        "\n",
        "with open(path_srtfile_with_speakers, \"w\", encoding=\"utf-8-sig\") as srt:\n",
        "    write_srt(ssm, srt)\n",
        "\n",
        "cleanup(temp_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleanup text file with speakers\n",
        "with open(path_textfile_with_speakers, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    lines = [re.sub(' +', ' ', line.strip(\"\\ufeff\").strip()) for line in lines if line != \"\\n\"]\n",
        "\n",
        "with open(path_textfile_with_speakers, \"w\", encoding=\"utf-8-sig\") as f:\n",
        "    for i,line in enumerate(lines):\n",
        "        if i < len(lines) - 1: f.write(f\"{line}\\n\\n\")\n",
        "        else: f.write(f\"{line}\")"
      ],
      "metadata": {
        "id": "wzsSoy37_1Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descargar Archivo"
      ],
      "metadata": {
        "id": "PJgCHKYvJm_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download files\n",
        "from google.colab import files\n",
        "files.download(path_textfile_with_speakers)\n",
        "files.download(path_srtfile_with_speakers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "eV2uNYT80g0V",
        "outputId": "9c9793f3-e8ae-4337-e275-5acf9faf8f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b436531e-105e-4c9c-a97a-bb90754c57d1\", \"audio1.txt\", 4696)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a65bfd31-d5dd-4c47-a5bf-52ac3af01b17\", \"audio1.srt\", 7179)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SETUP BUNCH"
      ],
      "metadata": {
        "id": "l3797gv7QRnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ENLISTA ARCHIVOS"
      ],
      "metadata": {
        "id": "auhOxTwYQmd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# # Listar todos los archivos en la carpeta raíz\n",
        "# files = os.listdir('/')\n",
        "# print(files)\n",
        "\n",
        "# Listar todos los archivos en una carpeta específica, por ejemplo, '/content'\n",
        "files = os.listdir('/content')\n",
        "# print(files)\n",
        "\n",
        "wav_files = [file for file in files if file.endswith('.wav')]\n",
        "print(wav_files)\n",
        "\n",
        "# # Usar glob para listar todos los archivos con una extensión específica en una carpeta\n",
        "# files = glob.glob('/content/*.csv')  # Cambia la extensión según tus necesidades\n",
        "# print(files)\n"
      ],
      "metadata": {
        "id": "Sxiip8p0Qjwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1880ae57-38e7-47f6-cc71-65799ab40787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a32ef11a-6884-41e7-928b-cf63a386514b_20230506T15_14_UTC.wav', 'ec8aa41a-dfd3-4a1c-b2ea-edf54a679155_20230422T16_33_UTC.wav', '1841240f-f1ab-4df6-96c7-6987b97d4068_20230411T16_35_UTC.wav', '8524c81b-ba37-4acc-a3b5-d1303fab469d_20230603T15_45_UTC.wav', '2423c4d4-01d1-424a-b384-3e5ddda79e7a_20230610T16_50_UTC.wav', 'e0913f30-a778-47f8-9585-f9219bb14dd5_20230610T16_29_UTC.wav', 'ae031a33-d308-40e9-aab5-fd43bf33b425_20230513T15_47_UTC.wav', '1c602ea2-8bef-4b22-9990-ef7ae3bdede8_20230415T14_53_UTC.wav', '5439e31b-4b86-4077-b1e1-4e1fd161a670_20230513T13_55_UTC.wav', '77dc4488-e978-4884-82aa-79d5b5197056_20230411T13_49_UTC.wav', 'f7e4b691-c321-4c6f-b91f-83888f96589f_20230422T14_39_UTC.wav', 'd15a221c-5dce-4a34-ac2d-8bda6ed71ebd_20230610T13_57_UTC.wav', 'ece40026-e149-425b-8c37-f0eb1f33deb4_20230513T15_41_UTC.wav', '2dea44d0-a836-446f-adf6-677088ca215c_20230411T14_37_UTC.wav', '00bcae99-9c09-402c-b74a-20549a188040_20230429T15_03_UTC.wav', 'dee55130-9aee-45f7-981f-694edfbcba81_20230506T15_21_UTC.wav', 'beaafdc4-bb5e-467d-ac18-3346e5812f04_20230422T14_56_UTC.wav', 'e2b0299e-e174-44ff-b09a-70a045d46b01_20230401T16_38_UTC.wav', '23067596-8526-41e2-aac8-c28e87963f9e_20230603T16_24_UTC.wav', 'b8a8797f-fd9d-4ae7-b90c-6774678e48c9_20230603T14_05_UTC.wav', '8937cfec-bdab-454d-baa3-174d29c5a510_20230603T16_53_UTC.wav', '5bc3093b-ce55-48c2-9034-3b5f4ea53ce8_20230411T14_01_UTC.wav', 'e8b27442-e140-404d-873d-421dee5393c3_20230415T13_18_UTC.wav', '8c649d07-7643-4bd2-a49a-06abe02085aa_20230411T17_35_UTC.wav', '6cf2ef1c-3dd0-4ab2-a6c3-dc6c8bf42313_20230411T15_10_UTC.wav', '3493df4a-f52d-4477-8508-579ddf93be38_20230422T15_02_UTC.wav', '5da331d5-2a4d-4161-b024-ae16e6a7c18d_20230506T16_41_UTC.wav', '0d8bbe9b-d20c-4f29-bf85-82e5cc07ce64_20230422T16_55_UTC.wav', '24596086-15d9-43c4-b671-17aa4344908d_20230513T13_48_UTC.wav', '5745019e-be6d-43cf-9274-39c2c420f543_20230520T16_38_UTC.wav', '3aa55085-a0e0-4782-864d-bcdbbbf2d76b_20230411T20_15_UTC.wav', 'e0817392-734d-4fa4-a55c-a89311f5ed03_20230422T13_40_UTC.wav', '5bcb144e-7f90-4876-a8e2-a50ab780ab24_20230520T14_57_UTC.wav', '164a732e-d1e9-4514-9261-3312ec7bae79_20230422T13_38_UTC.wav', '5abdaff5-c2f3-40f9-af07-154ba66eecb1_20230429T15_07_UTC.wav', '01c81113-4cf4-4892-a080-ebe8f26c767a_20230410T21_24_UTC.wav', '31ee3f17-4608-4fa2-8ea2-b3c9dfeb0930_20230513T13_54_UTC.wav', '2ad5de2a-875d-4aff-a907-ebe3a2d8851d_20230429T13_55_UTC.wav', '680cf6f0-10d7-44f5-9d52-b6e8d2f0cb1e_20230513T14_24_UTC.wav', '7549f180-369b-4390-8705-822dea512a7f_20230422T14_31_UTC.wav', 'c5cf1a3b-f155-4aa3-af0a-4271b7f5dda4_20230506T13_26_UTC.wav', '98b69638-22ee-455b-8e17-2421d0881ee3_20230520T16_45_UTC.wav', '8d44f7e1-c49b-457b-ba12-a1a9e21ed13e_20230520T13_45_UTC.wav', '874741a0-5edd-4e59-ba2a-5962d77c5c0a_20230520T15_33_UTC.wav', 'b22bfe99-a51b-4f3b-81ca-5b3f71552483_20230520T16_01_UTC.wav', '471aff11-5d0a-4b41-824f-b20e4e3ee321_20230429T16_02_UTC.wav', '683e1909-6888-4638-8623-df81d7720006_20230411T23_17_UTC.wav', '4821b13c-ee4a-4a30-acb4-93ece09b18ca_20230422T13_40_UTC.wav', '27e1e0c6-4e7f-455e-a545-4cd45cb37578_20230603T15_17_UTC.wav', '653112db-b1be-4926-9c3a-a45c5575522d_20230410T19_26_UTC.wav', '9e0129cb-42cb-4219-9eb5-fa468f0a2140_20230520T14_47_UTC.wav', '1cf46f04-222d-4bae-a1e9-8c0b0c22ac1f_20230415T16_06_UTC.wav', '7724a495-b32b-42af-aaf7-3127a3c9adf8_20230603T16_34_UTC.wav', '4e77be57-8d61-4382-9f1a-3625ce750cfb_20230415T15_42_UTC.wav', 'ca046302-8054-4cbf-8b9b-ee6854a2f681_20230610T14_13_UTC.wav', '9056361e-e5d0-4f4d-ac85-4a699978e1b3_20230603T14_27_UTC.wav', 'aa220622-e434-46a7-b5bc-ac9b1c0a52db_20230429T16_35_UTC.wav', '4c9c3500-961f-49d0-b7ef-1d02df193979_20230429T16_00_UTC.wav', '3a6e48f1-725e-4676-85f6-153a5e7ff8d8_20230401T16_29_UTC.wav', '8454ed90-16f9-45d2-a693-88b7eb73eaae_20230415T15_16_UTC.wav', '37705508-eb41-4fa8-9205-8caa2f631afc_20230422T14_46_UTC.wav', '5e09558c-2874-4736-b8a5-23cde3366875_20230415T16_33_UTC.wav', 'fa4f25d0-e8c9-45d2-8bc1-9f63cc236a15_20230603T16_03_UTC.wav', '640807ed-f3f7-4283-a729-5a888a93aaf7_20230610T16_54_UTC.wav', '01e7ca7c-d7f3-4a98-93f9-4978401b44a5_20230411T20_49_UTC.wav', 'bdfc7cce-1b0a-47db-b400-941ed1f8567d_20230411T21_44_UTC.wav', 'b67a535a-4d32-4704-9df0-d1c8c4a09af7_20230513T14_41_UTC.wav', '8cfc0ae1-b03f-43f0-85a9-2aea543eafc0_20230603T16_31_UTC.wav', 'c0151935-2b8d-4a4d-9cd6-a51e0a28f979_20230506T13_34_UTC.wav', 'fca9d9cd-4dbc-4a65-bcbc-a954c9141c82_20230520T13_46_UTC.wav', 'd0d8509a-4c84-43a8-beed-608d24063e1a_20230422T14_07_UTC.wav', '05d553d3-15e6-4018-bfa6-e3ea120e29c8_20230422T14_54_UTC.wav', '1d59b651-30bc-480d-b4ba-14288e039b92_20230506T16_13_UTC.wav', 'ed011e99-f19e-4257-b0cc-08f003decd8c_20230610T16_21_UTC.wav', '30a6921c-5a56-4778-a792-0a3cad953451_20230513T13_58_UTC.wav', '0bff31ee-dee1-4eaf-92e1-54b458eb9eea_20230603T14_47_UTC.wav', 'f399f796-40f9-4bfe-bba1-323714013e12_20230610T16_49_UTC.wav', '5bec9db8-77e2-46ef-b641-413bde26a88e_20230410T16_29_UTC.wav', '1e65294f-b396-467a-b52e-dc67ded0a78c_20230603T16_43_UTC.wav', 'bedc2a7f-c9e3-4112-93e8-acb3f966a2a7_20230410T20_11_UTC.wav', 'c03add8d-e73d-4714-a4c6-ed1e19f569c5_20230401T14_17_UTC.wav', '5557af49-3fad-4404-a7db-26b48a4f2669_20230520T16_42_UTC.wav', '4faccbbf-1aa6-41b9-a8b0-40f81e2c3611_20230415T15_36_UTC.wav', 'bd08a1f1-1e58-47de-9cf8-3d8a76b382d5_20230603T15_51_UTC.wav', '9e24c2bf-6827-4204-8e27-d07442904de4_20230411T17_38_UTC.wav', '5b12d1ce-c48e-43c3-bae2-001ac0df1ec6_20230520T16_34_UTC.wav', '66b31a20-9b33-4ccd-af79-7da328c1cda3_20230603T16_02_UTC.wav', 'efe98a6a-5455-4e15-aeee-48eaab0cce45_20230401T15_07_UTC.wav', '7e787287-71d8-49bf-9744-551fcaf30d67_20230415T16_37_UTC.wav', '07cf976a-52ae-4952-af85-4b458d45feab_20230506T15_54_UTC.wav', '33bc57d9-ee91-4429-86e6-00e1fa3462c4_20230603T16_51_UTC.wav', '417afa74-f872-481d-a126-866e7f7c5e68_20230410T14_57_UTC.wav', 'c74b1762-62f2-4f21-be20-afd4337ed749_20230506T14_10_UTC.wav', 'a71322ec-da87-4346-baed-f605a9f8b5b2_20230415T15_57_UTC.wav', 'b3067024-c98b-4888-8d1b-93992535ae9a_20230610T14_15_UTC.wav', 'ecdee297-77ac-444c-84b2-a95afeda5e47_20230415T14_41_UTC.wav', '214a0b05-e17c-4781-8e90-f9723a214d4a_20230506T13_21_UTC.wav', '404e7931-5fb3-4802-b4dc-719a3f5cb20f_20230422T16_22_UTC.wav', 'ad0946be-1ed5-43ac-bf3c-a01df5fc6b25_20230610T14_38_UTC.wav', '2dbd5c4e-0ae5-41b4-aa2f-5cc4976cc7ee_20230513T14_08_UTC.wav', '089454f4-614f-4e7a-8c75-f3ff84c577f2_20230422T13_27_UTC.wav', 'f189dbfe-6981-4140-87b0-500db982a3e7_20230610T13_45_UTC.wav', '5eb45b6b-b1fb-4d2c-abbe-b97177e0c6a5_20230429T13_48_UTC.wav', '6662d820-5b90-458c-8966-0cba5a3b45a5_20230603T15_38_UTC.wav', 'b34756c4-246a-4b40-bdcd-7998ee4942d1_20230603T16_09_UTC.wav', '9ba113e3-c4ac-4616-acdc-9d7935a3fe6d_20230411T15_45_UTC.wav', '9324d491-5152-4cf3-a5fb-99e9aad6f069_20230603T14_49_UTC.wav', 'd1941715-e821-42c8-a6e3-997b15a121b6_20230603T15_52_UTC.wav', '42f325bf-875f-4cb1-bf6d-e2f5cebddccc_20230506T15_28_UTC.wav', '141dd6fc-6ad1-4564-8eeb-603c4f0b4430_20230411T22_23_UTC.wav', '8096aa48-196f-4231-aabd-00fd9f1459e0_20230603T14_31_UTC.wav', '83cf39d6-502d-41ca-82ba-861912177d90_20230506T13_43_UTC.wav', 'f9af26cb-4904-486a-8068-835c1171b7cc_20230410T14_49_UTC.wav', '3235182a-8a63-4107-ae5e-6286910234c1_20230603T15_27_UTC.wav', '18b2b93c-2953-487c-97c8-b73ce36135fb_20230610T15_48_UTC.wav', 'c15c3250-1598-476a-a1a3-78f84e4db0e0_20230422T15_42_UTC.wav', '7e8087d6-6ea5-44b1-ad47-6f542beadd9e_20230422T14_22_UTC.wav', '84b62d0e-c3ed-4b07-8211-34806d42d49c_20230603T13_56_UTC.wav', 'fd3a31f0-339b-4dd3-81de-508b1311f3fd_20230422T14_53_UTC.wav', '3030567b-3ee0-42bb-8a83-8d1c76b6b916_20230610T14_01_UTC.wav', 'f855e0cc-0eb5-4e7d-85c4-c75afc91d583_20230422T16_51_UTC.wav', '463b83b0-280e-4835-89f2-d330b05114bd_20230506T15_12_UTC.wav', '889fb9e7-e19a-451d-98cd-be4503145d3a_20230520T16_13_UTC.wav', '463aea85-483f-442f-a152-796bbe6412f0_20230610T13_52_UTC.wav', 'f5738c9f-909d-4f56-a5b1-c22b5c2f28b3_20230422T15_28_UTC.wav', 'ef27f14f-919e-46e3-aa21-efd9a2a37933_20230410T14_06_UTC.wav', 'f14e8612-72f4-4a5e-b90e-5318fa6acab1_20230603T14_52_UTC.wav', '85307c7a-a409-40c0-b4a3-e580a097e987_20230520T16_07_UTC.wav', 'd2ce1aa4-558a-4dc4-a1d8-72c451a3e4b6_20230411T16_07_UTC.wav', 'e7f1e07f-eecf-4a62-912c-b93fec7f6a5e_20230506T15_11_UTC.wav', '025d7914-af83-481c-928e-9d9135c9da81_20230410T20_06_UTC.wav', '89c69762-4422-4168-ae51-925898eeac00_20230513T14_02_UTC.wav', '88407632-6a00-4107-8e1f-7433727d1292_20230603T16_29_UTC.wav', '342db425-864c-4c5f-928d-b6f33831727e_20230513T14_15_UTC.wav', '5ed44792-4a6c-411d-b789-d982ced86f87_20230513T15_49_UTC.wav', 'd32ed68f-0070-43a4-a4eb-582c82015c33_20230610T14_59_UTC.wav', '537c6e4a-05b4-44cd-8664-798bc78bcfe6_20230401T14_55_UTC.wav', 'f5348871-fa96-4cde-8493-03e500d7cdaf_20230411T14_53_UTC.wav', '62eb0ae8-3aab-4888-b037-da7c8beba1cb_20230513T15_07_UTC.wav', '1f948c34-3dac-4d09-9d6c-bb9a648403ff_20230610T16_57_UTC.wav', '07b7cdd2-8e90-4671-9493-43335ea1a6a9_20230513T15_49_UTC.wav', '590bfa9f-77f3-460e-b4b2-a18cebdb2820_20230422T14_47_UTC.wav', '43ae5242-9b5d-4abb-bf63-d04a3bf44b85_20230410T21_25_UTC.wav', '3bea674a-7225-41e7-b592-0cabc9fc4ea5_20230520T14_14_UTC.wav', '7762a28d-d9e8-42f8-818b-73eef5c82835_20230415T14_08_UTC.wav', '3af6a602-4a42-4071-b809-da314b31c322_20230422T14_42_UTC.wav', '5c90ed07-cdd9-4982-a974-bfa25eb4db21_20230506T13_24_UTC.wav', '7df47aa3-d6a6-471f-9570-efe419f06c56_20230513T14_38_UTC.wav', '9ea3de2c-6662-46a5-bdbe-a4f48299ef89_20230603T16_34_UTC.wav', '483dd9e8-7fd9-4420-b2f3-14b777fbbf34_20230415T16_00_UTC.wav', '546f8e2a-a3f6-4e43-8134-539c3191d81b_20230513T15_25_UTC.wav', '1137b552-8c30-430a-8465-71839e5153dd_20230513T14_30_UTC.wav', '954e1ba4-97d9-4c87-89f7-7118f1c8a9f2_20230411T17_24_UTC.wav', 'da99b69a-c23b-480d-83c1-532c242496de_20230411T23_50_UTC.wav', 'bb6f98e6-3dd7-4fe5-8be1-6d664de19a6c_20230520T14_50_UTC.wav', '30342e5c-598f-4975-8b8f-f9fa68ca4051_20230513T14_19_UTC.wav', 'e8107a5e-3a6a-4d6b-8166-7fdc910daa03_20230411T19_43_UTC.wav', '80d32ca2-8417-46f8-bb2a-70d9f6ecc384_20230603T16_04_UTC.wav', '010878ce-af75-4f0e-bf59-33735a1076b9_20230506T13_51_UTC.wav', '6599635f-a9ac-403b-868d-d67d044d24e4_20230513T14_15_UTC.wav', 'd1145cef-1e3d-45b8-9bdd-9ecf04cbbe7e_20230506T14_38_UTC.wav', '5f962505-9986-4a5b-a3b2-db50d252214f_20230422T15_46_UTC.wav', '1dcbb12a-3984-4aba-a69f-478967aa0a56_20230422T16_20_UTC.wav', '9adc6041-04c3-41d9-adc9-2db9665fb992_20230610T15_10_UTC.wav', 'ba310203-2f9d-4b2d-84c6-4ca97d0243c8_20230513T13_52_UTC.wav', '0cfb9ebb-032b-4262-9e6c-0df0d5e60183_20230506T15_42_UTC.wav', '7f58f35e-e971-4150-b256-57e191b33e11_20230422T13_25_UTC.wav', '6984ce3d-53b0-45a0-8a86-b6da750f9679_20230410T15_46_UTC.wav', 'ee3b2f1f-0c5d-4354-bb33-c66fd149c3b2_20230415T15_24_UTC.wav', '6c91167c-9941-47e4-b140-6a25f8f568cc_20230411T21_11_UTC.wav', '8d4ce095-04ec-4340-95cd-825becb7454d_20230429T15_12_UTC.wav', '9d05069f-957e-4cac-b044-6d17d23b5302_20230410T22_43_UTC.wav', 'bc992585-07a8-47c1-8c46-c5f2ff8bb9fb_20230520T15_19_UTC.wav', '1585f02a-c1f8-4ac3-b42c-e76dad3acb50_20230520T14_45_UTC.wav', '116f8022-60ad-4da9-bedf-98014338a17d_20230415T16_34_UTC.wav', '453753b9-95c1-4dd8-a518-47f63ad7bf11_20230506T14_07_UTC.wav', 'e27591c2-a9c8-48f2-8713-4e8b3b8a2376_20230603T15_30_UTC.wav', '274e2b3f-248b-49b9-88a9-b897dc5af11c_20230429T16_14_UTC.wav', '7c127994-b8c6-409c-935b-aabfe0332228_20230513T15_45_UTC.wav', '18710ae2-ed98-42aa-bdb6-37eae2a858c1_20230610T16_04_UTC.wav', '197676bd-2fde-4ac8-9cd5-4cd79b406d79_20230513T15_08_UTC.wav', 'be3488db-9594-4920-93be-5d722f0c6cbc_20230513T13_31_UTC.wav', '009045a0-a038-4250-a503-eb34607c670c_20230520T15_58_UTC.wav', 'cdce752e-a81d-4ea6-bff5-3558efcfd063_20230506T16_00_UTC.wav', '7c4537fc-c024-49c3-bdee-049bfd84d149_20230513T15_14_UTC.wav', '707aa055-42fc-4df6-ac78-1d565f9c3178_20230411T15_15_UTC.wav', '113147e1-fd1c-47e4-b717-f146e7583d39_20230513T16_35_UTC.wav', '34958b78-223b-4497-82e4-4c3afd0d0fd7_20230610T14_27_UTC.wav', '72912896-1c77-4991-a8df-43e764c5ea76_20230429T14_28_UTC.wav', 'a9b8fe53-e277-4010-b4bf-201460b5bef6_20230410T15_14_UTC.wav', '3da4629f-2607-476d-bbd8-1559a80126fa_20230506T15_16_UTC.wav', 'ad51905d-c317-49d6-ad45-f95d2e86ff3d_20230520T13_29_UTC.wav', 'c2ec4893-2b7a-41e1-9bf7-463c60ed5443_20230411T14_27_UTC.wav', '55368935-9795-4c0a-94e8-08aa5b357f3c_20230506T14_38_UTC.wav', '7ca5403c-0582-4b4f-ba05-4abed3603f4f_20230401T15_39_UTC.wav', 'e9ff83fe-dd0a-482e-be48-487187c7e13f_20230520T15_50_UTC.wav', '8ee859a8-6038-429c-8050-3b5299a48964_20230603T16_44_UTC.wav', '1744a2ad-d2ed-4a74-ad6f-bee4deccbebe_20230415T15_06_UTC.wav', 'f2cac06a-ec34-4eab-9fa4-a4f6d6046c3a_20230506T15_01_UTC.wav', '5fab44f2-12e3-402d-9963-8a5dc9d97701_20230610T14_26_UTC.wav', '4ea88716-3da8-42b0-ac05-b3d2521a64c7_20230513T15_42_UTC.wav', '57f1755a-b61c-44fd-afe3-b473d3df08ed_20230411T19_16_UTC.wav', '1cc50562-b323-469e-9713-471c3d7b3482_20230411T15_57_UTC.wav', 'fad8f691-ea46-4972-9aa1-16f37373c4bf_20230415T13_33_UTC.wav', '23f5eeaf-2e7c-4bfa-a680-4dbec95bfe89_20230422T13_31_UTC.wav', 'd679a03a-de47-49f1-87c9-31ca157cd6db_20230411T17_48_UTC.wav', '552decaf-5f19-4408-b28c-ca8fa30a8b4a_20230410T23_00_UTC.wav', 'c75ed6e9-7d38-496d-b7cd-c7c685c19e4d_20230506T15_44_UTC.wav', '8f7c8609-7ae1-4297-ad57-81f8d608277e_20230506T15_08_UTC.wav', '1f3a500f-16e8-46d5-af80-ac8719349efe_20230520T16_35_UTC.wav', 'bc593734-c3e0-422d-a39e-8f1683500169_20230411T16_51_UTC.wav', '73413f99-1767-446f-ae4d-8a1c2e9a4753_20230411T14_29_UTC.wav', '6f109ce1-626d-4c7b-9dc0-bf48688c90d3_20230506T16_28_UTC.wav', 'c19cec1d-7905-499b-b3df-c587d1ee0f2c_20230520T14_12_UTC.wav', '031b9bad-639f-454a-9c14-8576bf68d6bb_20230506T15_35_UTC.wav', '6ebdee5c-7276-4d21-af23-e7115404bc99_20230506T15_47_UTC.wav', '5cd6165d-de27-473a-bf19-d423564c00cf_20230513T14_00_UTC.wav', 'c19a6c90-36d2-4a7d-9b15-297271c9787b_20230422T16_28_UTC.wav', 'edd315cc-7d02-42ea-a610-20316561ad1a_20230520T14_46_UTC.wav', 'edad47b0-b587-4725-9078-eea28e991b35_20230401T13_24_UTC.wav', '13ee3fa8-5e4d-4d7a-a856-0e0053f04a0d_20230422T16_31_UTC.wav', 'c3b47bdc-a055-4353-8f20-0cf8f2a4a65f_20230603T16_10_UTC.wav', 'cc9d1ce4-fdb4-4330-b89b-4536f4f116a8_20230401T13_55_UTC.wav', 'f9c77f5f-aeb0-4d3e-b6c2-c0f9d1f79e38_20230603T16_18_UTC.wav', '2fef37bb-f438-4819-bb85-0d2f8cb52934_20230401T16_38_UTC.wav', '08cc34dd-337a-4a71-8e37-7d9076946030_20230520T16_38_UTC.wav', 'aa782ac5-00a1-40a7-ab0f-9d0ee55820b7_20230506T14_13_UTC.wav', '822671d3-fd8d-4b46-8ca3-fe67162b0e18_20230610T15_03_UTC.wav', '4e048062-59ce-4679-ab3b-057c1507b9f8_20230603T15_29_UTC.wav', '713f4625-a49c-4f8e-8bc3-1c34fe8eba21_20230411T16_54_UTC.wav', 'e572da42-0c0b-44b5-8d4e-a1c8896d5af7_20230520T15_24_UTC.wav', '6637e4aa-a7fe-446c-9bbc-3e96aab42123_20230411T16_13_UTC.wav', '5f59a3bc-7916-43d0-827f-a011e0703cdc_20230415T16_10_UTC.wav', '338898fa-9d15-440e-a191-0a1d23950a70_20230506T14_42_UTC.wav', '4dcdddfb-6fc1-4bfc-b078-6b7dcc9b9393_20230513T13_55_UTC.wav', 'c7f6749f-b15b-4e10-8745-66bb61b7e8ee_20230422T15_08_UTC.wav', 'e2b52690-f454-4076-ab12-fa60d178d6a5_20230429T13_35_UTC.wav', '1b89b931-86e9-476c-ab9a-286d960634f1_20230506T15_34_UTC.wav', '6e252fef-eb44-4526-b3ec-c3de6eaca9d8_20230429T16_59_UTC.wav', '635e4862-decc-4299-a0fa-4a16cc6c031e_20230401T14_46_UTC.wav', '4b0b8ebd-9749-44db-8d99-4bb66e3ac109_20230410T14_13_UTC.wav', 'c69e3cc5-d9de-448a-a966-e7820dfc0648_20230401T14_54_UTC.wav', '72007eb6-57d7-41bd-9961-eab9eb262c07_20230513T16_02_UTC.wav', 'da764e39-82b6-44b2-8245-c1b5dc96f648_20230429T15_31_UTC.wav', 'f94e8c9f-4fd3-4c27-ba1e-0d3af3c69d97_20230513T14_04_UTC.wav', 'db08ee33-52eb-45ba-a69b-920590773df7_20230415T13_46_UTC.wav', '3d4e250a-6503-4a49-bda5-c8e32d76a92c_20230520T16_48_UTC.wav', 'e5ffd63b-f1f6-424e-8dbf-33d7868c88a3_20230422T15_17_UTC.wav', 'eb564703-9c2b-4e91-af9e-438a908ef4fc_20230520T16_04_UTC.wav', '116518b0-a71d-42a3-baf4-f2b033d470f5_20230520T14_33_UTC.wav', '44de0213-a511-4255-8cb6-93411019f156_20230422T15_11_UTC.wav', '0728d6c4-4d61-44fb-9311-3005890db8c6_20230422T14_54_UTC.wav', '58c51add-f9e4-4d26-ad0b-f0031c087a77_20230411T21_10_UTC.wav', 'a8de54e7-217b-43bf-9222-236fe3a35143_20230610T15_59_UTC.wav', 'd2be3314-363b-40f0-9a2f-683c8bc4ff84_20230415T13_55_UTC.wav', '1f323c9a-ec1b-48be-8463-35ec9bb8cd95_20230520T14_44_UTC.wav', 'f63de629-ca41-4538-a549-1f0fcfc2fb0a_20230520T14_54_UTC.wav', '488a8a21-1e89-456a-a5cb-49db6c95c97e_20230415T15_51_UTC.wav', '4d0fddaf-bf72-43f4-828f-2fa5478d57c7_20230520T14_53_UTC.wav', '52217898-a6d8-4b0f-9022-c9d33b2f273f_20230610T13_28_UTC.wav', '42ee0c1f-e929-4347-88d9-79716a5c8ea0_20230506T13_46_UTC.wav', '94ec97b5-8435-4596-8ebc-41349eaa75e1_20230513T14_19_UTC.wav', '794fb86a-b60d-4b4a-ad67-afdd63b620f9_20230415T16_19_UTC.wav', 'e05cdde7-ba44-4286-8a8a-663ba1634581_20230513T15_23_UTC.wav', '78cab8b9-6d3f-41f4-a26c-0033cbacc3d4_20230415T15_21_UTC.wav', 'b06c1e98-5435-423e-b476-f94e89b923a9_20230411T16_27_UTC.wav', '680af949-29c3-4de5-84fb-901fb52b419b_20230411T15_32_UTC.wav', '8a6fbb54-5999-4708-b1f4-00bfb4e8fe37_20230411T21_14_UTC.wav', 'ee79615b-5cd8-40a3-8dce-b7c4a77b3192_20230415T16_30_UTC.wav', 'a7c7f3ff-0a2f-4178-92de-e58b75687c66_20230411T21_16_UTC.wav', '81fdd597-ac20-48ad-ab5c-fe2b0b2f10c7_20230411T16_46_UTC.wav', '033864c8-7c5f-4a4f-ab44-a201563fd968_20230610T15_05_UTC.wav', '575ac139-6e3a-4883-87ff-4f2c5fd2e549_20230506T15_44_UTC.wav', '4fb1c693-e7ac-4af5-8e5e-be54d3f959ef_20230410T18_05_UTC.wav', '8cfbb958-413a-4751-a454-49e53ef14af9_20230415T13_59_UTC.wav', '1e89ae9d-25dc-42ec-9bdd-f53417053f2e_20230513T14_28_UTC.wav', 'b0ff1db2-2b23-407f-95ec-b7bcfeb93e4d_20230410T21_03_UTC.wav', 'bd541769-2d57-4967-823c-88fa36288e20_20230422T16_26_UTC.wav', '603597da-801f-4cf5-b9e9-d9a7e6344c12_20230520T16_36_UTC.wav', '985de04e-417c-4d67-91ce-bb4d4f20d7a2_20230520T14_09_UTC.wav', '2cf97530-4798-41a5-b3df-8c975c328d49_20230401T14_10_UTC.wav', 'd554a73b-18c8-4f35-866c-98565d703d21_20230610T16_41_UTC.wav', '50ab3124-681d-4200-b15a-b449cd1d77b9_20230422T16_37_UTC.wav', 'e40f06ea-7922-4414-8399-c9014e2dcf48_20230415T15_48_UTC.wav', '1e9de5fe-556c-45b1-8f7a-fa01bd8e5792_20230513T14_26_UTC.wav', 'ef88ac27-ad7a-4816-9f49-c0165e6c9dc6_20230410T15_31_UTC.wav', '507d162a-9e91-468a-a0bb-5d464bcf8306_20230410T20_52_UTC.wav', '9470924f-5b98-4bb7-811e-a87fc55bdcc0_20230520T15_45_UTC.wav', '355e09f1-c236-4385-acb6-ab063e06b92c_20230429T16_00_UTC.wav', 'd7b144ef-8763-46bd-ad6a-635c184333d8_20230411T16_49_UTC.wav', '196163b6-dc4b-42a9-9768-9c3b51ba04d3_20230520T14_23_UTC.wav', '6fd33ccf-e55c-42f4-9f91-51e69c46ccfe_20230603T15_34_UTC.wav', 'a9879b6f-9d0a-4341-9727-be8763c8143d_20230506T16_49_UTC.wav', '47ae6f69-8eec-4ac0-9b04-fda2cee9a84d_20230603T16_55_UTC.wav', 'd8ca88e2-884a-4bd4-a09c-a9a05fe469d4_20230411T16_19_UTC.wav', 'ec698549-12ce-4d93-9559-f26cbef6a4cd_20230410T16_36_UTC.wav', 'd09d3944-097d-47c3-a4a5-0ba96a2e30c5_20230513T16_58_UTC.wav', '8bd84b15-a391-441c-b79f-1e3da9fba381_20230520T14_29_UTC.wav', 'dadc3b91-813e-4f68-8857-c0dbebdcacd5_20230411T19_31_UTC.wav', '4cf5489d-9c06-4df4-a630-5fd2435879bc_20230411T19_32_UTC.wav', '026ae835-07af-4cd1-a746-26de91ccfb84_20230401T14_48_UTC.wav', '38b31381-1206-4735-8cbc-1cdb6be4fc93_20230506T14_40_UTC.wav', 'baf41d37-2231-4f11-8aa1-f9efa35e2e83_20230506T16_28_UTC.wav', 'f5428781-188d-4778-a2c0-e8dad5d32e3f_20230429T13_30_UTC.wav', 'd54d4dd0-22f2-43d5-b129-b4aeadf8d949_20230411T21_42_UTC.wav', '6c68bb72-6f40-40e5-b428-43678b1b6c14_20230411T16_30_UTC.wav', '939ad70f-482e-4a44-a5ad-041d4a08cf9d_20230520T13_41_UTC.wav', 'c50bf2e9-fc1a-498f-b5fb-1d4c3fed0ef1_20230411T15_12_UTC.wav', 'a1dd5230-a14a-4ceb-8b8a-4125c4983d6c_20230411T20_43_UTC.wav', '951906d3-efa4-42ff-b582-643ad5f98f25_20230506T16_28_UTC.wav', 'f6e1997e-b931-4094-a10a-6529f51648f3_20230429T13_54_UTC.wav', 'ea0be619-7976-4652-a634-613e83bfdfd9_20230422T15_34_UTC.wav', '1ccb941c-c487-4df1-87d3-a9be911b6087_20230429T14_29_UTC.wav', '77fe6103-4f89-4fe0-bd09-da0b15c42ed5_20230513T13_39_UTC.wav', '41a31167-97e0-4c41-b6d8-fd97821f9e4a_20230520T15_42_UTC.wav', '0a79fec0-47de-48db-a1f7-d96d1e43bfd3_20230411T20_29_UTC.wav', '5a0baf31-3073-48af-8873-0a7c14ee748e_20230410T15_21_UTC.wav', 'c245f34a-a05a-4ae1-9b3b-8187bdfbc52b_20230422T14_34_UTC.wav', '42df394a-0d74-4909-b694-f4139d4b8c09_20230610T15_37_UTC.wav', 'd32cce30-da68-4fa0-93e8-b2f9bf5b7ca8_20230415T15_49_UTC.wav', 'ea1ee2c1-2f3e-4c35-ba06-1fbaaf0ae084_20230603T16_55_UTC.wav', 'ab0eef6a-40f6-4b60-ac18-c92cb70a7b87_20230506T16_14_UTC.wav', '37143e2b-996c-4292-8641-e1bc094a2821_20230422T14_21_UTC.wav', '9e4d53b7-64df-4ef3-bb5b-67473d765d7d_20230422T16_40_UTC.wav', '378a6ab1-f1e9-4921-bd04-4905cfd5fd15_20230506T14_23_UTC.wav', '9a69066f-af1c-480a-b766-270d6930f207_20230429T15_27_UTC.wav', '28a2f83d-d4c8-49e3-a877-80d66daba141_20230520T14_24_UTC.wav', '3b578a25-c465-43fc-955b-0554a3c4bac2_20230603T16_36_UTC.wav', '7561a59a-1cc2-4d3f-9dcb-726bda6b777e_20230610T14_18_UTC.wav', 'a02d3ac4-f86d-4db8-9fe9-12abf5c4be9f_20230520T14_22_UTC.wav', '9fbc4011-3322-4602-9ec1-9b6af0060898_20230401T14_32_UTC.wav', '8bc7b6d6-df6a-41c0-ae5d-17e3ea7ff538_20230603T16_43_UTC.wav', '15407ae0-a923-46ee-adb2-f5410cefe223_20230401T15_29_UTC.wav', '460de0ef-c099-4ddb-bd68-82fcb84e149f_20230513T14_37_UTC.wav', '10d53bee-c598-4c15-8fbc-ab952c29f840_20230411T22_04_UTC.wav', '7a997a6e-7315-4fde-9805-46cb004b1a79_20230506T14_24_UTC.wav', '14c5c3d1-526f-4376-96dc-da365a2b6ec0_20230506T13_34_UTC.wav', '910be2cc-d794-4876-8700-917f769ce28c_20230520T14_28_UTC.wav', '565d84e1-e2f5-42aa-83b9-c4efb62a9d44_20230415T15_30_UTC.wav', '3155a333-3252-4318-935a-f4a3a7420475_20230506T14_26_UTC.wav', '8565e892-9ffb-437e-9096-e06a12af4d2a_20230410T15_22_UTC.wav', '3e389aa8-8397-48e7-8e57-f6eb8ce0812a_20230610T13_55_UTC.wav', '6eb352d2-7580-49f0-9c96-19ac9df008e5_20230610T14_29_UTC.wav', 'bab93478-e737-4a7d-a7ca-383c9090a498_20230610T16_15_UTC.wav', '4d1237f2-3114-4ff7-ab3b-0915ce55a261_20230513T15_48_UTC.wav', '218faaf3-9a27-4cae-91f8-350e760cd256_20230520T15_50_UTC.wav', 'a7b3a1c2-f26c-464d-97db-ec49d46b75f1_20230610T14_25_UTC.wav', 'bbbe1178-e3c3-4589-81f6-856f9853a8be_20230401T15_02_UTC.wav', 'e091c455-9605-4f6e-a5fa-c6b7388e115c_20230610T15_13_UTC.wav', '40616391-4881-4ab6-b1c9-b3140e0c8410_20230422T13_34_UTC.wav', 'c6d769d1-3c17-4550-9a8b-907d0436a157_20230415T16_38_UTC.wav', '37acf025-7513-4cbf-8c84-44808b4d76bb_20230411T16_35_UTC.wav', '917712eb-518b-4a30-b33f-4542c11e23bc_20230506T14_27_UTC.wav', '94524d10-36c3-46f1-ba46-32d8dba9c1a0_20230520T15_34_UTC.wav', '83565bfe-3d89-4d56-aeab-17c3e5d4d287_20230410T19_05_UTC.wav', '2756db88-e992-4eb7-b04d-8e997015a691_20230506T15_33_UTC.wav', '680147b0-0049-4098-854c-4344f4b0dc17_20230411T15_02_UTC.wav', 'e86106ea-e7b4-4bba-b73d-cc28fe74640a_20230429T14_51_UTC.wav', '79b85f0e-973f-4395-94c9-9afa75c61c8a_20230411T13_57_UTC.wav', 'e8a52d4b-45b4-4af5-be7b-1cc7a4fe9a67_20230429T14_49_UTC.wav', '532981b7-adc4-49c4-9ecd-ee362b6e2c4a_20230422T16_10_UTC.wav', 'f5075ec3-b695-4718-87eb-5bd617aa45ef_20230513T13_59_UTC.wav', 'af176031-f007-4816-b87c-1a2d36c64bb1_20230429T13_19_UTC.wav', '642edfeb-8a31-4fd2-8bc6-d888ab314a9a_20230603T15_34_UTC.wav', '909110ef-29df-4140-bcbf-34068a4facd7_20230410T19_35_UTC.wav', '349349d7-b0a6-4b3c-81b9-73a1bbc000ae_20230411T23_07_UTC.wav', '2a66fed0-4e20-41a5-9bcc-3ac6d68949ea_20230411T15_37_UTC.wav', 'acc9f0ba-ebea-4f0b-b603-ff54c45928a4_20230422T15_51_UTC.wav', '3c1a5ac7-632a-450e-a13d-7acbb6a02587_20230422T16_43_UTC.wav', '84286b42-52f8-4873-bea3-fd670b42a67b_20230520T15_11_UTC.wav', '7955c3c1-0559-4cc5-af77-d8372f84c30d_20230401T15_35_UTC.wav', '03e03c17-a4db-480d-9398-98a2a187ec05_20230506T13_35_UTC.wav', 'f189e556-91f0-4a0c-bca7-11f6ee0bac4a_20230610T13_18_UTC.wav', '601fa041-941b-47b5-a5b6-799c9b4bb52c_20230520T15_20_UTC.wav', 'f7f10ec8-adba-4ac0-86fe-19ac6dd3d24e_20230401T15_38_UTC.wav', '384a9e38-83d1-4d61-8d60-0aa2b582db70_20230603T15_33_UTC.wav', '29a70da7-b6b4-483d-85fd-483e814378b1_20230610T14_41_UTC.wav', '7f77a99f-ac1b-4dab-bcce-2f408995b9bf_20230610T13_04_UTC.wav', '40fd7c79-a2c2-45da-bae3-756a22ce065d_20230415T15_22_UTC.wav', 'e3a5c2c5-727b-4bd5-98f0-6c8f7e88f528_20230415T15_19_UTC.wav', '10a78230-8120-40ff-967f-f9474b8681de_20230513T14_52_UTC.wav', '2a60bc82-8e70-4276-aee6-5cc329bd7e0e_20230429T16_20_UTC.wav', 'c740fd6e-bfb8-4775-84b2-fac186cc6096_20230603T16_27_UTC.wav', '32098918-3a62-4711-b515-c4f73b78ca9c_20230520T14_30_UTC.wav', '905f342b-a579-4efd-b4cd-6d04cadce2dc_20230520T15_17_UTC.wav', '18eff36f-759c-4d73-965c-2a229beecfee_20230610T16_24_UTC.wav', 'a307b6fb-84a7-4880-a1ea-00809410d22c_20230415T13_29_UTC.wav', 'c46c4466-bca2-4173-adb5-c473b38fcf34_20230603T14_05_UTC.wav', '81657259-ed99-4269-952a-0969bc168879_20230520T14_42_UTC.wav', '56106688-b198-4ef7-81dd-6e235ba46d60_20230429T16_40_UTC.wav', '2b4d1446-039b-4964-a1b6-f0d45ccd6add_20230513T16_20_UTC.wav', '1fbc0a40-a2e9-4f86-8885-251cffbf0e48_20230415T15_52_UTC.wav', '94387e77-2343-4f96-821b-3b4eaec26f8e_20230411T23_06_UTC.wav', '733244c0-66e8-4b26-81c5-005033abdf6b_20230422T16_24_UTC.wav', '1fa73898-4ad1-417a-9447-4e54f2838011_20230410T15_53_UTC.wav', 'aa8ee420-41ad-49ab-a7d1-f69a88f07278_20230506T16_16_UTC.wav', '9a72fb9a-366e-4065-8c31-b8efc56d0a5a_20230401T16_18_UTC.wav', '031d90bd-2c04-438a-96aa-41ae06c154ad_20230603T14_18_UTC.wav', '2bdfdb05-6789-46ca-a883-0afdb2520c61_20230520T14_54_UTC.wav', '54357403-9ec1-4340-8f7e-1f686441e918_20230401T13_56_UTC.wav', 'a8aa7718-dc4f-4e32-97b4-aa12514425b9_20230603T15_09_UTC.wav', 'f5115b4d-cbe0-4337-a924-25b1341f62f4_20230422T14_31_UTC.wav', 'a7b2c245-f1ec-4336-8e70-d417e3ed25d1_20230513T13_47_UTC.wav', '29406a02-deba-4efe-99df-7f05467d41bf_20230422T15_03_UTC.wav', 'f3da8705-2d92-4da0-ae1c-b240ff710501_20230411T21_36_UTC.wav', 'aefbfc0d-79e4-4b1c-a2a6-55587f83ce08_20230506T16_14_UTC.wav', 'c62380ce-6e02-4728-a083-6e24459f0c1d_20230603T16_09_UTC.wav', '139f333f-8a01-4e37-a64b-91a6170c4523_20230401T14_25_UTC.wav', 'f9dce104-9b6e-4c9e-aaa1-6a86eb274768_20230411T21_09_UTC.wav', '934de517-7dd9-4afd-8f8a-198b2226c2e5_20230610T15_00_UTC.wav', 'eda25ef8-2d7c-42c1-a29c-b68045744c97_20230429T14_03_UTC.wav', '788eeae0-18b9-40c3-97cb-b42b95b4475e_20230411T19_05_UTC.wav', 'adecfa2a-9f3d-4fac-8224-e3e70557a4c9_20230603T14_03_UTC.wav', '0164a21e-deb5-4a48-9477-5e8b0b1ae8c3_20230429T13_40_UTC.wav', 'c08123cc-5b6e-4eff-8c34-dae414f80cbb_20230422T16_16_UTC.wav', '606bc04d-e20f-4869-8438-972a3c5d73c5_20230513T13_50_UTC.wav', '042458ab-1635-4753-a745-fa3aa2342932_20230513T14_43_UTC.wav', 'eff5112c-a663-4def-9597-5e956bbc2b04_20230506T16_50_UTC.wav', 'adeae93e-5de9-4bf3-8475-f2be1e33b246_20230603T15_17_UTC.wav', 'ce4b3f92-a387-4a43-89f7-b43579e929af_20230513T15_04_UTC.wav', 'e2bceef8-3606-433f-8e34-0041afe802fd_20230603T14_40_UTC.wav', '273735e2-6073-4f47-92c5-44342af36cd1_20230410T16_41_UTC.wav', 'fb9b79ae-c05e-4539-b00a-e25228b9f76f_20230415T13_52_UTC.wav', '644425d8-eca2-4295-bc15-dc678aacde59_20230415T16_15_UTC.wav', '208ac2af-40b7-4858-a9d2-0f853707e985_20230401T15_27_UTC.wav', '45de056a-1fe1-4222-9786-deee12dd410a_20230603T15_24_UTC.wav', '1e934f7a-3425-41fb-87a6-2033161e7d35_20230506T14_31_UTC.wav', '697bf7da-22d2-466e-8a1c-8e3b3902773f_20230603T15_48_UTC.wav', '2e89b588-c9c0-4e96-a1b5-a67f7a2b9aa8_20230411T19_13_UTC.wav', 'a7472e18-88d0-43b5-a642-eefc26781945_20230506T15_35_UTC.wav', 'ddbd78cc-d5d3-4a1b-a800-3b74721bbafa_20230506T16_36_UTC.wav', 'a84a6476-af20-46ba-8915-6b5d649248ff_20230520T15_01_UTC.wav', '1807b779-dcf0-41f8-9c80-70561aebbf4a_20230429T13_39_UTC.wav', '911afd33-fd7a-4131-a8c5-af48cde00ea7_20230411T15_46_UTC.wav', 'dc5113b6-f941-4dd3-b47c-18fa3fd4a2b5_20230520T13_43_UTC.wav', '970163d6-af85-4c5b-bcdc-20683c0718b3_20230429T16_32_UTC.wav', 'ef719c3f-93c5-4a92-bcc2-d78687ed6916_20230422T15_06_UTC.wav', 'd9553adb-ba9c-45be-ad6e-1a2bded61ad8_20230610T16_33_UTC.wav', '856cd9fe-4c7d-4a7a-880c-eb480ca78834_20230429T15_41_UTC.wav', '07abdc9d-f0c4-471f-9752-6056b92ebaf5_20230506T16_20_UTC.wav', '5868843b-8fcb-4d67-bdd9-f510acba77e0_20230401T16_22_UTC.wav', '5fc07564-55ff-4dbf-9a79-b8d315ff7de7_20230429T16_22_UTC.wav', '80b7d887-017d-40f1-b547-b35df3a8288d_20230520T14_27_UTC.wav', '157cbbb1-cc70-4a8a-9273-69c8af1e553d_20230603T16_22_UTC.wav', '439fd9e6-845e-4430-be5a-623deb841e22_20230506T16_38_UTC.wav', '6eb42d94-dfb3-406f-af29-0fe85feffbfe_20230610T16_55_UTC.wav', '9750b201-23fa-4c0c-997c-e692e36c6bd5_20230422T16_03_UTC.wav', '4876cd90-1980-44df-909d-77e8a3adfc28_20230415T16_49_UTC.wav', '97d98e1b-95bb-4789-b89c-c2a5ee0d3a0b_20230415T13_41_UTC.wav', '850ce407-0de1-4b7b-81b8-aae833bf83b5_20230429T14_23_UTC.wav', 'aa29be68-0ad0-47ea-9af0-5d2e3292d6e2_20230410T14_18_UTC.wav', '150eae31-2596-4624-be31-244bc2edfdb9_20230513T15_11_UTC.wav', '3fde7eca-0a2f-4b18-8a3f-d81fce9a9d09_20230610T14_48_UTC.wav', '97854074-06dc-4fb0-8176-55b4c82a2175_20230415T16_14_UTC.wav', '0232759a-e225-4b65-967f-d5692f2289bb_20230603T16_18_UTC.wav', 'a7cb174e-124a-4b49-8a76-43d24733066c_20230520T14_20_UTC.wav', '48042829-f387-4955-b61a-ddf3c5dd66fa_20230422T13_35_UTC.wav', '9c3c50ee-ade3-41df-8da3-0221a49f876c_20230513T14_35_UTC.wav', '2554ef94-fd63-4f53-80f1-3b1da70a4a5c_20230603T15_29_UTC.wav', 'f639ffe4-a675-4f6e-ae94-e592bacffeab_20230506T14_56_UTC.wav', '34093c6f-8784-4662-9522-fd815d240e6a_20230411T22_08_UTC.wav', 'c9e75cee-d79e-4ca9-a7c4-20ed40a2486c_20230422T15_57_UTC.wav', 'd5d431e4-eb50-4346-9d46-a6403a3fae35_20230410T22_46_UTC.wav', '14ac803d-4650-43b5-8d52-b4f8f8221463_20230520T14_37_UTC.wav', 'd0318e67-a523-488d-ac8f-978525acaed1_20230603T13_18_UTC.wav', 'd84bc7ab-bb48-4692-b1f2-2501205cb790_20230603T16_25_UTC.wav', '0475a9f6-8cfd-46cc-9811-a2c0bd254cba_20230410T20_19_UTC.wav', '0f7f9700-3c8b-4ca6-a469-4c90ffbc7a08_20230429T14_08_UTC.wav', 'bd219ad4-a971-4249-81cf-7eaabe47847f_20230415T15_55_UTC.wav', 'e3ddf033-9d7d-497a-b707-e5b972eea599_20230411T21_19_UTC.wav', '2f4d3ac2-e3ee-4d28-bce7-9c6d0b9948da_20230506T13_36_UTC.wav', '39efe428-b750-46ff-9d09-7b38fee1f9c3_20230429T13_18_UTC.wav', 'e009a5e5-f188-4142-a5e9-3b99490f9725_20230411T22_03_UTC.wav', '433c0e26-0ddb-4067-8dec-8182793d3124_20230422T16_33_UTC.wav', '64ae7828-3bcc-45ba-82db-806c021a44e7_20230415T14_13_UTC.wav', 'f46a8cad-1ac6-4aeb-b7ba-63abe6e1079d_20230513T15_10_UTC.wav', '0bfe45d7-cdf6-4e65-8365-967bb0ed5d4f_20230411T16_25_UTC.wav', '0030e177-fd39-4ca1-ab11-a54d45d504ec_20230603T13_48_UTC.wav', 'e3166252-a484-4812-a71d-c7e5127e1853_20230603T16_53_UTC.wav', '87cee38a-8a48-4c62-890a-2b8a04881c3c_20230410T21_11_UTC.wav', '9a0f8517-b225-4f3d-939a-bde8c09100f6_20230422T15_41_UTC.wav', 'a4108b71-6c63-4935-931e-67e290ebf5ed_20230415T15_27_UTC.wav', 'f332b332-6cb3-4bdd-b098-9e865a5831e4_20230610T14_13_UTC.wav', 'de226de0-f8c9-4183-b0fc-1b26c2a7a637_20230610T16_49_UTC.wav', 'e00886da-3b1c-4d40-aef6-acf1c2495cca_20230520T15_47_UTC.wav', '97d7be85-0c18-450d-bead-cc8ab66b6589_20230401T15_02_UTC.wav', '2e360e5d-8411-410c-af65-ac52f7ebb612_20230520T15_36_UTC.wav', 'c1f6bb25-19c5-43fc-ae4a-84ab5027729a_20230415T16_23_UTC.wav', 'bdc1679b-294f-4d60-844c-566fef78c4c8_20230610T16_16_UTC.wav', '9dc3465f-9c9b-41c8-83a3-7328a913a912_20230520T15_58_UTC.wav', '3fe9459f-7ea4-41a8-b7fe-099281c6933e_20230410T19_57_UTC.wav', '047db9ca-b2af-4229-b2aa-d38f22eb3652_20230401T14_09_UTC.wav', 'd8de1f28-7ee1-44e2-873c-ab0b784b1fc6_20230415T15_11_UTC.wav', '180fad9a-a3b4-4fdd-9620-2951dcad860e_20230411T15_57_UTC.wav', '4e014158-da2d-4143-9310-ef4dc1d90cd2_20230410T15_56_UTC.wav', '3f533089-1ea6-4492-a38c-2ccfe3f7b538_20230506T15_43_UTC.wav', '68d84c60-35fb-46cf-ac27-b6730f690e18_20230422T13_39_UTC.wav', '345d8040-eb37-45e6-a050-f5400158c74c_20230401T14_38_UTC.wav', '9d9ad8e2-eec0-4d22-9b01-1b08caac2399_20230513T14_46_UTC.wav', '59c281a8-bc44-4807-9cd5-badae33507ee_20230401T14_27_UTC.wav', 'eda880c7-ca6f-4e40-835a-a372d01627c0_20230610T14_59_UTC.wav', '1e798210-746b-4b36-9a8f-e460af2cf9f9_20230401T16_35_UTC.wav', '45adf080-f3e2-4793-9006-99ada4592d63_20230610T15_47_UTC.wav', '52b9e772-098b-4da1-9446-7b56ebbc60df_20230603T14_12_UTC.wav', 'd3f9da97-0a55-4615-9f10-fba0283c6bc6_20230411T22_38_UTC.wav', '395e4860-4bba-4174-9658-ea56370ee664_20230415T15_31_UTC.wav', '5dca1c61-c2bd-40c9-9eae-cf6db205d40b_20230422T16_54_UTC.wav', '8596a04a-c2af-4a5c-95bc-a1f8bcab3a3a_20230506T15_44_UTC.wav', '993dc711-9890-4a2c-ba47-09afaa81f7f6_20230401T14_23_UTC.wav', '8546519f-c98f-4d6d-9d4c-7bb2ef2ca057_20230410T19_35_UTC.wav', '21717b84-966c-41c0-984d-9e9347c5f9bb_20230513T13_56_UTC.wav', 'c7e11bdf-ad06-4aae-944c-4ce1a11dc2d7_20230610T14_02_UTC.wav', '41663fe9-9f68-481d-85a1-1fc4f18287a1_20230415T14_36_UTC.wav', 'cae8a78e-89bb-43de-ad56-b392e63980fe_20230513T14_51_UTC.wav', '3a3b2973-f7f0-41d0-937b-b5dfb7544b5e_20230422T16_43_UTC.wav', '3cd94688-360b-4765-9f4c-1cb9ca941d37_20230415T13_42_UTC.wav', '95b943b4-ff29-443f-90fd-597d734364aa_20230506T14_47_UTC.wav', '9cc88c03-7736-49f3-96ec-c088dbdcfaa5_20230506T15_00_UTC.wav', 'bc0e1c0b-4e19-4b13-8c38-c17813f495aa_20230603T14_34_UTC.wav', '6ba1c276-36e2-42aa-9b2b-f4e47614f435_20230422T14_28_UTC.wav', '3588f501-74e8-4eb4-80a7-d3d055031399_20230513T16_00_UTC.wav', '6ce2f828-120e-4c0c-aa2b-04f92bd3bf7b_20230411T21_49_UTC.wav', '5784d80e-51e8-4d3f-9fef-b30c957f8e91_20230415T13_27_UTC.wav', '9c2ec049-1910-46b1-818d-938a15ea0635_20230513T13_49_UTC.wav', '9c3f1b9b-fe9e-4c23-b661-8aa1b9f4d86a_20230513T16_20_UTC.wav', '39668e94-ebc7-43e9-bf34-252b07cf0c64_20230422T14_35_UTC.wav', 'd3ca53f1-b931-4eca-8fc2-39b8df6b583a_20230603T14_56_UTC.wav', '8a9e90a7-378e-44c8-b12e-c65ac422ee79_20230415T13_57_UTC.wav', '40b6d572-3c0f-40cf-91e3-812ad4c150fe_20230520T15_21_UTC.wav', 'd301988f-d745-4837-a22f-8f523ece089e_20230415T16_02_UTC.wav', 'c24e02ed-87a4-4265-a8ee-01dc29750c46_20230429T16_23_UTC.wav', '02647261-da12-429f-9cfa-9c4cc663c180_20230520T16_21_UTC.wav', 'ca814175-95ad-4bf1-87df-b74afbdfa0b4_20230520T16_40_UTC.wav', '541547d2-ee68-4fbb-8b63-a2eefacbbfe0_20230429T16_27_UTC.wav', '74c933f5-ec4f-425e-b7b5-16a9159c9aa1_20230410T16_45_UTC.wav', '90a28742-5d43-4699-9b35-2c86841da0f3_20230410T20_35_UTC.wav', 'b5177be4-cb56-4c91-9b6f-d7beb39e58de_20230429T15_01_UTC.wav', '343630a2-898c-49dd-8554-e9f982b32f51_20230415T13_51_UTC.wav', 'b31710b0-cebf-47db-a2db-6cbe9b474328_20230411T15_12_UTC.wav', '6da6e049-c8e7-4afc-8a14-2919df0b7d8c_20230415T14_33_UTC.wav', '685804b7-76ff-4deb-ae85-0348cd2e662c_20230429T14_32_UTC.wav', '8b8eacfb-94eb-4229-a8b9-c4366158ae38_20230429T16_09_UTC.wav', '3d4d837b-8d47-42f3-9c16-09f641fe5b7c_20230401T15_56_UTC.wav', '83d09db2-bedb-4dac-9c83-17dd005a306f_20230415T15_20_UTC.wav', 'fa2e02f1-94b6-47a7-9ec9-ce31f0965d8a_20230415T14_07_UTC.wav', 'b5aebd97-3c9e-4460-be36-e17f510224c5_20230513T15_18_UTC.wav', 'b06a666a-a870-4c85-b9ad-85d28d469327_20230410T15_46_UTC.wav', '6f5a73d9-c565-485c-b0a2-a59e77f82a20_20230422T16_15_UTC.wav', '67c4c529-9787-4c1b-af66-7d39294be888_20230513T15_01_UTC.wav', '22958174-4ef8-410d-a1eb-2d87a18e4fe0_20230513T15_55_UTC.wav', 'b93c3651-43db-424a-8f48-439ab7544abf_20230520T16_49_UTC.wav', '0d42bfce-1235-41bf-b682-5be893bc3daf_20230520T16_46_UTC.wav', '72204d99-e654-4ca0-bfff-b27f861cf709_20230429T13_28_UTC.wav', 'f16fa42c-e348-4c51-9646-3f79bfe72e9e_20230520T15_04_UTC.wav', '3012004a-5626-4572-b89f-1e1c98e11b24_20230415T15_59_UTC.wav', '85783ad3-d6a6-4f32-9e97-fad6929351e6_20230401T14_41_UTC.wav', '69c059eb-d32e-4ca5-879e-36a1c16fc9d6_20230506T15_20_UTC.wav', '82f7ae74-f625-4f15-a69c-b0e912be4061_20230506T16_46_UTC.wav', 'facd0eac-6562-4ea0-bade-57735201a291_20230410T20_34_UTC.wav', '5a12c09f-6299-4346-bd43-e6e707085aab_20230411T19_17_UTC.wav', '0f9f909b-b478-4bd1-ae7a-8656ebc39e50_20230401T14_08_UTC.wav', 'c6014cba-959d-4325-8124-b12de2397096_20230603T16_39_UTC.wav', 'e24a2db7-255e-4480-a02f-3ae1a5dcab3c_20230410T20_36_UTC.wav', '9015f350-f893-439c-9672-fe39bf92dd3c_20230410T15_06_UTC.wav', 'f071b457-53b7-40c2-8641-4b1963948676_20230506T15_03_UTC.wav', '29ae3f88-3339-4f12-9f97-677bfd5d7c40_20230415T15_06_UTC.wav', '28e46110-5622-4461-9170-90034dfa735a_20230520T16_39_UTC.wav', '19016e9b-b660-4da2-8f29-7afcae807e0c_20230603T14_27_UTC.wav', '47539959-b2a1-4f07-959d-0677316ae87c_20230513T16_22_UTC.wav', 'dafe5e3b-0c33-42a7-aaea-2e46eb5974ff_20230520T15_41_UTC.wav', '6f7e9034-fa45-482a-a3ac-42da48afec9d_20230415T15_13_UTC.wav', '408f03ac-6dc9-496c-96e0-6a8cf71a2698_20230513T16_23_UTC.wav', 'f77ace08-7c5e-46d1-90f6-416c244b045f_20230429T15_14_UTC.wav', '9a1dcdae-bafd-4701-b03d-1edd8d0cfcf2_20230415T13_31_UTC.wav', 'b60cc994-4773-4907-8422-53935fb1858b_20230422T14_30_UTC.wav', '2debb732-8d99-4ecd-b89a-0a7afd03cb2e_20230610T16_57_UTC.wav', '88ff8661-57f7-42b3-87b0-6bfefa404e9a_20230506T15_09_UTC.wav', 'dbe5300f-d957-4b76-9977-d0c9fbb24837_20230410T22_21_UTC.wav', '10f5693d-beb2-4875-aeea-5bba87a40809_20230415T13_13_UTC.wav', '3b00844f-5a19-4bd7-81f8-d3c336512fdb_20230603T15_45_UTC.wav', '866cc7d6-6f0e-4ec2-bcb5-8e00408d0526_20230410T20_37_UTC.wav', '3790e2a1-6369-4202-95cd-1456849101ac_20230610T16_51_UTC.wav', '5db4b150-a2a7-46f1-88fc-d719951375cd_20230513T16_31_UTC.wav', 'ac1bd4f1-2ad6-40e9-a644-a1df7e25d803_20230411T17_35_UTC.wav', '62966d4f-44e2-4f34-a4a8-37905c429b36_20230603T14_36_UTC.wav', '79edf837-ebfa-4f86-a72c-851eff781f38_20230422T14_19_UTC.wav', 'e0383201-78fa-4d93-bb28-06019e66c2aa_20230603T15_53_UTC.wav', '3e9fa1a1-a9b5-440b-bf34-ba111196096f_20230411T22_12_UTC.wav', '016f20e5-737c-4ef7-b4c7-e6aa293c759a_20230513T14_34_UTC.wav', '8e43586f-7306-452f-aee1-29f7ae574bf3_20230520T14_05_UTC.wav', '82309327-c2e7-4eb3-ba78-6d53fad93d26_20230422T14_27_UTC.wav', '78bbdb79-570f-467e-82c9-423f0d2af116_20230520T15_18_UTC.wav', '0ec71968-2bfa-4c46-a72a-690e0a23f780_20230506T16_31_UTC.wav', 'd50b8632-1fd7-49a1-a28f-3381f4171d8f_20230506T15_06_UTC.wav', '6dc3e5d9-bcfe-4a48-85ca-d5da026f18e4_20230506T14_20_UTC.wav', '95402853-7f24-47b1-bc3f-e1423e5dc91e_20230429T16_46_UTC.wav', 'bc70753c-fc01-45c7-97cc-d0eb680b0a09_20230411T14_43_UTC.wav', '0c027942-655e-4f11-8361-4bb47a282aea_20230610T13_32_UTC.wav', '2909f47c-f7dd-4e11-997c-c00f32dfa69d_20230520T16_54_UTC.wav', '1744acda-8b4b-4e94-8c9f-891a34c5171c_20230411T13_59_UTC.wav', '21a477a7-b958-4a67-9938-f78f2c2a51b4_20230415T14_20_UTC.wav', '33b9ce2f-992b-43db-b9e6-4ddb24fc5538_20230411T15_02_UTC.wav', 'a4badea9-f688-48fc-8d1c-d8c42b174caf_20230506T14_18_UTC.wav', '71c3a935-7b26-437e-921e-0578d6591052_20230422T16_17_UTC.wav', 'b7a54ede-d9a2-4f87-99e6-294f474bed1b_20230513T16_01_UTC.wav', '60e1b8f0-7eb8-44c8-b701-4251b86ecea1_20230610T13_35_UTC.wav', '6fddad58-12fe-447a-afcf-0ea1b69384fa_20230401T13_40_UTC.wav', '93075abf-1134-4da8-b90e-475d8039ff9c_20230422T15_06_UTC.wav', 'e1b74cc1-1132-4138-860c-f1f1fbfbeb01_20230513T15_35_UTC.wav', 'dd76a4a1-cb3c-41e3-ae20-0ffb737b53ee_20230401T15_06_UTC.wav', '68e3b1a5-4440-4ec4-93fe-aa01bce316c8_20230506T14_10_UTC.wav', 'bfef4005-062b-4e6c-8b94-8c79b028cc5b_20230410T19_53_UTC.wav', '9a4b8c11-1fca-486c-83d9-df02daf7092f_20230401T16_47_UTC.wav', '89b759d9-b6d0-4fe5-bf09-e35d1a18e38f_20230422T15_02_UTC.wav', '9a0e078a-a4ae-44ab-8bfd-8d7ff2af562a_20230415T13_53_UTC.wav', '0fc06e0f-ec72-4ceb-a662-f2652746bd6b_20230513T15_14_UTC.wav', 'e0e2f6bf-3859-4a22-9738-c1b769773f0c_20230429T16_03_UTC.wav', '3285427c-df83-400b-9ea7-3b1ae349b5bd_20230415T16_09_UTC.wav', '16d944ae-54bb-461a-81bd-e1bedc5aa4c9_20230401T16_24_UTC.wav', '39c7e1af-a983-423d-9560-8be3325f39cd_20230422T15_49_UTC.wav', 'd8363b1b-bb1f-4657-9cb6-6073a1423ad3_20230610T15_06_UTC.wav', 'bf27a5fd-cb22-45f4-97d5-cc6710f2f3d6_20230506T16_11_UTC.wav', '8676f58f-7b37-46cc-9ab1-5edf6f986e87_20230520T14_03_UTC.wav', 'fa73e42b-2e7f-4c6e-ad58-4c72fd1a5906_20230411T19_35_UTC.wav', '62348a51-79a1-4b19-ae53-fc0831afa258_20230513T14_22_UTC.wav', 'e0bbb40a-e54c-4b27-b2a9-eb5a4581aab4_20230603T13_18_UTC.wav', '8273dce4-65a5-4e99-a47d-92da2d1af7ad_20230610T14_54_UTC.wav', '75281220-b17f-42fe-8d46-16ba933670d1_20230422T15_54_UTC.wav', 'f116526e-e701-4bae-9f44-b21e0a6cacf8_20230603T16_41_UTC.wav', 'e3fee5db-a1de-4c43-b746-c6785b4acbcd_20230506T16_36_UTC.wav', 'c77901b0-dc0e-44b3-9fba-cf6dfc4e8a64_20230410T14_19_UTC.wav', '269d7a90-3160-4216-9c14-e767e8b4ec18_20230610T15_41_UTC.wav', '9795bc43-7cda-4049-a0b0-6f3b1ca4caff_20230603T15_29_UTC.wav', 'a90d4f65-7153-494f-92d2-7fee434d7993_20230520T16_35_UTC.wav', '82fbace9-dadc-4abd-9d7d-c3ec3f6f4991_20230520T15_24_UTC.wav', 'e56abe4f-b3ae-4c0c-bc1b-1cdfc8d80cb3_20230610T15_15_UTC.wav', '9eda7f11-0ff3-4ae4-a961-c25b10d45f69_20230410T23_26_UTC.wav', '4143a33a-2278-4375-8dbf-07e067633a0b_20230415T16_05_UTC.wav', 'a8a8e3bc-c5e6-4920-8145-fa5d8671d7ed_20230422T14_36_UTC.wav', 'a465d7e7-ba15-4aeb-b223-0890e0b11665_20230520T15_55_UTC.wav', 'e929ad77-684a-4192-8f49-6ef18c539200_20230506T15_48_UTC.wav', '2b4c0b5a-e3c2-4b72-a2f2-f6f051af932c_20230520T15_28_UTC.wav', 'f869ac5b-d424-4ca0-b9bf-2dfb10ac77d3_20230415T16_20_UTC.wav', '816ecbb4-7ba9-4593-81b5-a5957de2bc8c_20230411T16_42_UTC.wav', '26746b7e-69e1-40b3-b3a1-1b973330ce96_20230610T14_35_UTC.wav', 'b7fd0389-8ab6-406b-a5f4-27f21f174a4c_20230520T15_10_UTC.wav', '38028477-df8a-428d-84bf-9b9db5bf7114_20230401T16_42_UTC.wav', 'c6ab69e7-4faa-45ac-a103-c4c9ee8e105b_20230506T15_20_UTC.wav', '34bdce35-71ee-491a-b7fb-cba5a4888b46_20230520T13_25_UTC.wav', '7fbe1f18-5411-4413-a555-cd409e52317a_20230506T15_47_UTC.wav', '154104a0-af4b-43c4-ac53-7dcfb0b1fd5a_20230422T15_55_UTC.wav', '8f543285-15e9-4d3d-9d6a-5d48d0921fd2_20230506T15_13_UTC.wav', 'cfcdff7d-41cb-48ef-b794-88eecab62e6b_20230411T15_17_UTC.wav', '712a3952-0222-44de-9bb8-d9d3c04fa8b4_20230520T16_34_UTC.wav', '5b686c92-3b3b-4511-9dd0-ce4dd4e97313_20230401T16_06_UTC.wav', 'df30d5c8-1852-436d-9135-e9b2edadce14_20230506T14_44_UTC.wav', '699779ac-ada3-46a4-a762-897b3e50fc32_20230422T13_45_UTC.wav', '3f7bb9e0-1952-4ca3-862f-cbb15517889d_20230506T16_27_UTC.wav', 'e3e047f6-195c-4b32-a05f-8de775ba50e5_20230429T15_32_UTC.wav', '421c076a-2162-455b-8846-667a238f2380_20230603T13_37_UTC.wav', 'bb6c44d1-8ae8-4b23-b86f-5e7e6a6f7153_20230411T14_14_UTC.wav', '7446bb26-0ffd-47da-ad9c-67c6e55e1e18_20230410T22_06_UTC.wav', '47f93aa8-5f71-4379-8e0b-8b2082986edd_20230603T15_59_UTC.wav', '4614a9e8-1fc4-48c9-92dd-0963e237e3da_20230401T15_45_UTC.wav', 'bf657c87-2370-453a-a757-7e731996bac5_20230513T15_55_UTC.wav', '2b7e6051-5192-41d8-a468-8cdf6f7b19e4_20230506T15_07_UTC.wav', 'a8a2f8cd-78f1-45a9-a57e-5e25dea5f56a_20230603T14_21_UTC.wav', '6341e565-756d-4d36-a3c0-b1b8002f3c34_20230401T15_16_UTC.wav', '1d5de6a4-1d82-4665-93d6-e193d04448c4_20230429T14_43_UTC.wav', '336c7446-4dd0-46bd-a99e-69fa46f3a1d2_20230506T14_56_UTC.wav', '536cbdf0-d4e8-47c5-8384-7bcedf902be6_20230429T13_45_UTC.wav', '54d5ffa7-c570-4c7d-9673-c01c4eec60c6_20230603T13_41_UTC.wav', 'd7fa92da-8e27-4569-94d5-881474e770e1_20230410T23_48_UTC.wav', 'cbd20465-103d-4583-9679-422dccedf813_20230422T15_16_UTC.wav', '5d9a33ca-81b8-4da1-a6b4-c27e48478d9a_20230429T16_35_UTC.wav', '59efa8c8-167b-424c-8cac-bb3f76df94cb_20230415T15_56_UTC.wav', '9d49804f-1ab2-4051-9764-ed9be3ed3dd9_20230520T13_55_UTC.wav', '975df311-5269-4860-98f5-22a3eb856dfd_20230610T15_05_UTC.wav', 'c5fe1b95-9057-4174-ab7a-99191aac144a_20230411T19_51_UTC.wav', '353e9acf-054d-411c-9a3c-4a2ce197bae9_20230520T16_21_UTC.wav', '813de320-0552-473d-b261-651605877886_20230429T14_30_UTC.wav', 'cb63cab9-a129-4bb0-b436-32c54755422d_20230415T14_59_UTC.wav', '71a40f9b-026e-4537-9ba0-704991f8e8dc_20230513T16_16_UTC.wav', 'cea4655f-25bd-4999-aa9c-13ea4dd42084_20230603T14_13_UTC.wav', '9f4431c7-a778-4c87-8a5b-1dd22387313d_20230429T16_45_UTC.wav', 'a7aa46cd-f8bc-4181-a539-73f847ed660b_20230506T15_48_UTC.wav', '70430579-661e-41e2-b384-06960f3dd126_20230429T16_34_UTC.wav', '7071d053-4612-4ad6-a546-d8b06d519f19_20230401T14_29_UTC.wav', '3bc7f3e6-dbe0-419f-a30e-acb2504c3a9b_20230411T23_02_UTC.wav', '9ccebd0d-f96e-4dc9-916f-f7e5aeccaeff_20230506T13_55_UTC.wav', '6d760d07-29d2-49db-800b-cb85a320587f_20230506T13_41_UTC.wav', 'd176a9c4-1cef-4641-b121-c64651060ce4_20230411T20_41_UTC.wav', '7ac4470c-fd3b-4a64-9293-dfcd7dae8b85_20230506T15_18_UTC.wav', '49ea1e07-2f7b-4ea0-9737-f1263d29e300_20230603T16_38_UTC.wav', '35294179-632a-40ae-899b-8bf4d103e54e_20230410T14_04_UTC.wav', '0c1dacc2-0d21-474f-9f30-0b2bc3069d1a_20230401T16_11_UTC.wav', '021a52a7-0fdf-4b70-aae9-30fea38d8b2d_20230401T15_41_UTC.wav', '4678f55d-f951-4a69-aa84-1da1849fc74a_20230429T14_55_UTC.wav', '8de21dcb-f085-4c02-ab84-0f3a31bcb975_20230401T15_20_UTC.wav', '93e3d9a9-444e-45fd-bf02-43ede80387a9_20230429T15_14_UTC.wav', '2ee89ca6-b151-452d-80fa-fc0031248b5c_20230610T15_18_UTC.wav', 'e85c6614-72f9-4fd0-b186-9d87266c0121_20230429T14_16_UTC.wav', 'f25b557d-c8cb-447b-a5e8-5ebe7d8215e8_20230603T16_52_UTC.wav', 'a4e0358a-e54f-48d8-92ab-9996190c590b_20230410T16_30_UTC.wav', '2bf1748f-6df2-4d44-94ad-8a137f33ed77_20230610T15_22_UTC.wav', 'c36d9fac-7165-4581-8cf8-5996d3de4c13_20230415T16_25_UTC.wav', '25c6705e-b182-45c5-bdc8-f3c815d5fe05_20230401T14_01_UTC.wav', '43d00212-3477-4b82-aee1-cf256b486038_20230415T14_26_UTC.wav', '7b39ef06-3ca8-4c01-8e35-0c7cc7b4e07a_20230415T13_53_UTC.wav', '67fe5a14-63cc-4787-8cec-50e1ee7bf025_20230422T15_47_UTC.wav', '60929ed1-4f16-4194-a18a-e7a4ff310624_20230513T13_22_UTC.wav', '5d6b0bcd-9801-457b-b627-33de21e565f2_20230610T15_44_UTC.wav', 'dd1c87d3-da3e-4f3d-bcbc-a74eb8bf9bba_20230513T13_58_UTC.wav', '71538ce5-216c-401d-858a-2aa36e84ba52_20230513T14_23_UTC.wav', '7e280061-9ea5-495d-9bfe-1e3cc534f152_20230513T14_50_UTC.wav', 'e0634185-f435-4c04-8991-26946e3a6543_20230422T15_04_UTC.wav', 'aba6a590-6098-44ec-b6a8-c105e2a6d040_20230603T14_32_UTC.wav', '68165b26-a21c-4684-972e-d52b95781b6a_20230603T14_29_UTC.wav', 'a3aafac6-9173-467b-bad4-b3aa605d1d09_20230410T17_17_UTC.wav', 'c7ac6af1-8f0b-4463-b059-7d6d36774b2c_20230410T19_37_UTC.wav', '16d72dae-a5cf-4e5b-b8f2-aa1ecbd74954_20230506T15_06_UTC.wav', 'f1e80f37-6a02-4fac-8912-df9b9df04df0_20230610T13_44_UTC.wav', '8c2b84f5-69fd-4eef-a57d-dc7353cd5f4d_20230520T14_49_UTC.wav', '719fdfe4-c307-4062-a6c1-d9d3f6717e64_20230429T14_51_UTC.wav', '04cce189-8ff0-4de9-86ff-978ceed8b3c9_20230410T21_47_UTC.wav', 'df3afc85-861d-4dea-9f6f-60c50ca2f336_20230410T13_52_UTC.wav', '3db3a6db-bac4-403a-8919-7db8d5370109_20230410T19_51_UTC.wav', '64b02580-0d90-40f1-ae48-0187f9d244ac_20230411T23_33_UTC.wav', '196ddb59-bd1c-49f0-a7cd-31adcbfa52ea_20230411T20_36_UTC.wav', '0d68e227-32fd-4e23-b613-139fb0931786_20230410T15_31_UTC.wav', '1d3fb2e9-3a05-451e-9eb6-c0d915472694_20230401T14_16_UTC.wav', '10aeffbd-fdfb-441f-a9bd-9d3453b8542d_20230506T14_38_UTC.wav', '4a7e7dce-1e1a-4ef9-86de-022834da0890_20230603T16_22_UTC.wav', 'eb790c32-7abb-4ae4-b341-9de02f428c7b_20230415T14_52_UTC.wav', 'a05fa8fe-7f26-4491-8279-7521fc00f807_20230429T14_05_UTC.wav', 'd4e6e812-7ba0-4aef-99a1-0db847bf1147_20230513T15_45_UTC.wav', '766af491-c347-4362-be9a-171ed1ba520b_20230401T16_43_UTC.wav', 'daaefcc0-bfc5-4c1b-8a73-2e7ca8ed766e_20230506T15_16_UTC.wav', '8b1e2596-a7e2-47e2-acca-554449d9a65a_20230422T15_19_UTC.wav', 'e85dd4d4-86a3-4330-bf87-c02e6236d9a2_20230411T15_29_UTC.wav', '0823295c-ed47-4573-9556-43ed879414cf_20230415T16_11_UTC.wav', '54a5d966-04a6-4a91-92ce-4a0fdbb9c7c8_20230415T13_45_UTC.wav', '9a4c9180-a4d5-4322-85e3-eca7ba89214a_20230506T15_47_UTC.wav', 'c460ce04-06de-4452-9c8e-181b72b60aea_20230410T14_28_UTC.wav', '15806e5f-145c-4377-bdbd-6f1b30578278_20230506T14_53_UTC.wav', '2729d9a3-0307-4258-b822-bb548ab24c09_20230506T14_22_UTC.wav', '4648b334-55fd-4029-8a6b-56ae900bc728_20230401T15_01_UTC.wav', '0f64591b-bbe6-470d-976c-a9b6b8c326ca_20230506T14_40_UTC.wav', '981fad81-113d-4ee3-9d19-00d0f58d176d_20230520T16_46_UTC.wav', '26b82182-dbc1-454d-9cc6-cc114d159316_20230506T16_30_UTC.wav', '26cec85e-84dc-48ed-a11d-b96e84033cae_20230410T13_55_UTC.wav', '851fbf7a-f5c0-4555-9c9d-afbd38fbc6d4_20230429T15_04_UTC.wav', 'de4d233e-6161-4b1a-abcc-e65ca771d84d_20230401T13_38_UTC.wav', 'd1989662-afb9-4e7d-b4a9-5db8ef92dc48_20230513T13_35_UTC.wav', 'f0ce8351-89d2-4f94-9637-98b0c767da18_20230422T15_08_UTC.wav', '90fbb18e-a9a0-4bf9-ab27-60969446d826_20230429T14_09_UTC.wav', '716391e8-d102-4a68-b76e-9c8beae2d630_20230513T15_02_UTC.wav', '7d1e9c1d-3d09-4eeb-b4cd-ddee26941734_20230513T16_55_UTC.wav', 'c5857a4b-d1ca-4c18-9119-d66de0193106_20230603T16_15_UTC.wav', '62d7f94f-b3ef-45aa-8d42-5335e9dfdb6f_20230410T17_15_UTC.wav', '25f12ead-3aa0-4a3b-b795-66087b8db321_20230513T15_31_UTC.wav', 'a1b3a2b4-557e-4e18-85e4-ef633d330cef_20230415T16_22_UTC.wav', 'a0f86d90-9555-4c4c-b753-07e16a16e99f_20230415T13_58_UTC.wav', '78b2705d-5c2c-4f63-a30f-466b61e80dc3_20230401T14_50_UTC.wav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def rename_file(filepath):\n",
        "filepath = \"00bcae99-9c09-402c-b74a-20549a188040_20230429T15_03_UTC.wav\"\n",
        "\n",
        "filepath = filepath.replace('-','')\n",
        "suffix = Path(filepath).suffix\n",
        "\n",
        "# if str(Path(filepath).parent) != \".\":\n",
        "#     new_filepath = str(Path(filepath).parent) + cleanString(filepath.replace(suffix, \"\")) + suffix\n",
        "# else:\n",
        "#     new_filepath = cleanString(filepath.replace(suffix, \"\")) + suffix\n",
        "# os.rename(filepath, new_filepath)\n",
        "# return new_filepath\n",
        "\n",
        "# print(rename_file(\"00bcae99-9c09-402c-b74a-20549a188040_20230429T15_03_UTC.wav\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuRXHeVLWM0b",
        "outputId": "dd983913-d7d9-43f2-a227-595c8d36dd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def isolate_string(audio_path):\n",
        "  if enable_stemming:\n",
        "      # Isolate vocals from the rest of the audio\n",
        "\n",
        "      return_code = os.system(\n",
        "          f'python3 -m demucs.separate -n htdemucs --two-stems=vocals \"{audio_path}\" -o \"temp_outputs\"'\n",
        "      )\n",
        "\n",
        "      if return_code != 0:\n",
        "          logging.warning(\"Source splitting failed, using original audio file.\")\n",
        "          vocal_target = audio_path\n",
        "      else:\n",
        "          vocal_target = os.path.join(\n",
        "              \"temp_outputs\",\n",
        "              \"htdemucs\",\n",
        "              os.path.splitext(os.path.basename(audio_path))[0],\n",
        "              \"vocals.wav\",\n",
        "          )\n",
        "  else:\n",
        "      vocal_target = audio_path\n",
        "      return vocal_target"
      ],
      "metadata": {
        "id": "htDdriuwSvlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EJECUCION MUESTRA"
      ],
      "metadata": {
        "id": "HdtUEI1XLWbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "vocal_target = audio_path\n",
        "language = None\n",
        "whisper_model_name = \"large-v3\"\n",
        "# replaces numerical digits with their pronounciation, increases diarization accuracy\n",
        "suppress_numerals = True\n",
        "batch_size = 8\n",
        "\n",
        "if device == \"cuda\": compute_type = \"float16\"\n",
        "# or run on GPU with INT8\n",
        "# compute_type = \"int8_float16\"\n",
        "# or run on CPU with INT8\n",
        "else: compute_type = \"int8\"\n",
        "\n",
        "\n",
        "whisper_results, language = transcribe_batched(\n",
        "    vocal_target,\n",
        "    language,\n",
        "    batch_size,\n",
        "    whisper_model_name,\n",
        "    compute_type,\n",
        "    suppress_numerals,\n",
        "    device,\n",
        ")"
      ],
      "metadata": {
        "id": "Jb8XcDGNTbbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "7920268bb17e4e439f744deeab57ac3d",
            "2d76b4e2020c4032a79e9f0629691e74",
            "668120239829440da2f0863d564e221e",
            "3a73f7cfc0f9471d93a3ef93fc712d80",
            "4716eda28a4e40508ca05f1e6d25e25f",
            "afa66ee52ebc419985e0d64f92f83ef3",
            "394c109011764391996453cb55d76740",
            "74943f0c603c47db836dab716bc72947",
            "608c5af1b34f4d4dba18ef38b1a5f1cb",
            "abf464d9128d49b79ae4569e9eb516e3",
            "453778a8c3234e52bc9572ea4ae69f4d",
            "5462145b917949979d5c5a4ac2eaaf54",
            "dc4a91cc35244cf59327dacea1e32fbe",
            "c5bcf01e5cb04973b4ac7b5c57034517",
            "4cf873db3db044bd986b811ca2568673",
            "3b0f8876ee054d68914763be73910284",
            "79797638ba364a1c9f32f7f23be6d767",
            "791fc496bd7f46408b392de5171c2c92",
            "838c150755034f7da1d47ac72a47c473",
            "8c356bdd6ea646fda453d543c3527c5b",
            "a4a90ba4e5254f419babdcd280f96d26",
            "4f9de3e2aa9e40c88a86974324d1f15e",
            "b8f7b41eecc34c58ab0e20b04d367a74",
            "a8ea5b82b8d5489dad6498144f277910",
            "4f05a9322f1b4139991fc596513d387a",
            "cc7f7e4bc80645879c64ef2b81764f4c",
            "80d75918bed04847ae607e752111f49d",
            "58316d0d1ad246e59c328d7a197dada2",
            "fd8e91964bbd4d118601f2c4204d1a4f",
            "cc77f9333077442bba1c6807d6a38f8e",
            "332c6170b74c45a79778da0ff95bed16",
            "61d45f8442604f259361aab962db0ebb",
            "658dc48718e74dde94f2845839aee494",
            "00686bdb7f2f4b859d6f3b75a4d52189",
            "374175c659f9467bbe277863b961e7d2",
            "7adb45bdb2644e48ae97ad19c34c72e6",
            "08133c800ddc4f8b942bc2fc30341339",
            "6330b002abd84c95b118d7f711760937",
            "6caec3a0322946429c7b00f5ae0e366e",
            "afc9ca91a5984bafa33a177babea95a0",
            "76d435ded4114b0393ee482323deb7cd",
            "c9b0b900c9a34dd894ff96f4147f77f9",
            "17bfc1853fc643cebdbc5ec19c92a684",
            "ee0cb84e7f264fbab793a07b3a6f476d",
            "7abab0a5240e43cd97837ee2cb846f4f",
            "8ab75dadc4ee4e98ae25023c5ae073aa",
            "f39c482566d54a47b7c10ffff0485105",
            "3d9ca7192a1248cf8a70f6fa22d73f7f",
            "117e4e10fd2f47d2983226e47c840aa3",
            "78bdf215bf064c3ba963bf830c4102ca",
            "1b5964f616b14c5a83c57baa798abe55",
            "e84d5a69ece54549a8925f993a90761c",
            "4aee9d493a444b16a86d5c66be62be59",
            "c7d0dec0ba40486fa2954ff401c84bff",
            "8e02f050833b4c63961df97e7ef9ab5f"
          ]
        },
        "outputId": "a100cb10-1b92-41e4-c520-c75f6c258ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7920268bb17e4e439f744deeab57ac3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.39k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5462145b917949979d5c5a4ac2eaaf54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8f7b41eecc34c58ab0e20b04d367a74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00686bdb7f2f4b859d6f3b75a4d52189"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocabulary.json:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7abab0a5240e43cd97837ee2cb846f4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 16.9M/16.9M [00:02<00:00, 8.07MiB/s]\n",
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Detected language: es (0.99) in first 30s of audio...\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RESULTADO WHISPER"
      ],
      "metadata": {
        "id": "P_afvf7KQEo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(whisper_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqdwc2oqPbL2",
        "outputId": "a8c1ff7f-b0d0-4a0a-c303-dc0d027bb023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': ' Aló. Buenos días, me comunico con Rafael Dávalo. ¿Y con él? Le habla Angie Valente, de la Universidad Javeriana de Cali. ¿Cómo se encuentra? Muy bien, gracias a Dios, usted. Muy bien, gracias a Dios. Nos estamos comunicando, señor Rafael, por su interés en el seminario en Business Analysis con Power BI. Ajá, sí, señora. Bueno, usted se encuentra en la ciudad de Cali.', 'start': 0.623, 'end': 29.599}, {'text': ' Sí, señora. Este seminario se dictará de manera presencial en el campus universitario. Iniciaría el veintidós de junio y finalizaría el treinta y uno de julio. ¿Qué tenés a la pregunta? ¿Este es el curso de Python? No, señor. Seminario en Business y análisis de Big Data con Power BI. Ah, ok, ok. Sí, sí, ya recordé. Este seminario es gratuito, ¿cierto?', 'start': 30.503, 'end': 58.729}, {'text': ' Se estaba, digamos que se estaba ofertando de esa manera, pero pues con un convenio que tenía el ICT con el Ministerio de las TIC, pero esa convocatoria ya finalizó. Ahorita se está pues manejando ya directamente con la universidad y sí tienen valor. Ok, ¿y qué va el ICT? Se encuentra en ochocientos cinco mil pesos. Ok, pero yo no he pagado todavía matrícula ni nada, ¿no?', 'start': 60.674, 'end': 85.947}, {'text': ' No, no, señor. Precisamente pues me comunico es para brindarle información. Usted dejó los datos para que le brindaran información. Sí, sí, entiendo. Sí, sino que como me decías que ya empezaba a tal fecha, yo quería decir ya estaba como inscrito o algo así. Por eso preguntaba. No, no, señor. Este iniciaría el veintidós de junio. Ok. Ajá.', 'start': 86.425, 'end': 109.241}, {'text': ' Las clases presenciales serían los días lunes y jueves de seis y media, nueve y media de la noche. ¿Tendría de pronto algún inconveniente con ese horario? Sí, no, eso sí. Por el trabajo. La verdad yo creí que era iba a ser virtual. Es online, bueno, se maneja un online, pero ya sería para el mes de julio. El mes de julio, ok.', 'start': 111.169, 'end': 135.282}, {'text': ' Pues por ahora sí, recibiré la información y creo que estaré pendiente para confirmarlo. Bueno, sí, señor. Entonces le compartiré información vía WhatsApp, si está bien. Y pues por ese medio podríamos continuar en contacto. Bueno. Listo, muchísimas gracias. Bueno, señor, con gusto. Que esté muy bien. Hasta luego. Hasta luego, mamá.', 'start': 136.186, 'end': 159.275}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ALINEACION DE AUDIO CON WAV2VEC2"
      ],
      "metadata": {
        "id": "Xv9FxZYcQSr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if language in wav2vec2_langs:\n",
        "    device = \"cuda\"\n",
        "    alignment_model, metadata = whisperx.load_align_model(\n",
        "        language_code=language, device=device\n",
        "    )\n",
        "    result_aligned = whisperx.align(\n",
        "        whisper_results, alignment_model, metadata, vocal_target, device\n",
        "    )\n",
        "    word_timestamps = filter_missing_timestamps(result_aligned[\"word_segments\"])\n",
        "\n",
        "    # clear gpu vram\n",
        "    del alignment_model\n",
        "    torch.cuda.empty_cache()\n",
        "else:\n",
        "    assert batch_size == 0, (  # TODO: add a better check for word timestamps existence\n",
        "        f\"Unsupported language: {language}, use --batch_size to 0\"\n",
        "        \" to generate word timestamps using whisper directly and fix this error.\"\n",
        "    )\n",
        "    word_timestamps = []\n",
        "    for segment in whisper_results:\n",
        "        for word in segment[\"words\"]:\n",
        "            word_timestamps.append({\"word\": word[2], \"start\": word[0], \"end\": word[1]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL01NEw9OXfM",
        "outputId": "1e4670e1-8f9d-4a04-c743-e25c4544e70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_voxpopuli_base_10k_asr_es.pt\" to /root/.cache/torch/hub/checkpoints/wav2vec2_voxpopuli_base_10k_asr_es.pt\n",
            "100%|██████████| 360M/360M [00:05<00:00, 66.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.36 s, sys: 1.35 s, total: 6.71 s\n",
            "Wall time: 12.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_timestamps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvpRJK0wRFyl",
        "outputId": "7d7a163f-e6ee-4796-b345-83d37612f634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'word': 'Aló.', 'start': 0.663, 'end': 0.803, 'score': 0.035}, {'word': 'Buenos', 'start': 0.823, 'end': 3.324, 'score': 0.496}, {'word': 'días,', 'start': 3.385, 'end': 3.725, 'score': 0.698}, {'word': 'me', 'start': 3.745, 'end': 3.825, 'score': 0.544}, {'word': 'comunico', 'start': 3.865, 'end': 4.265, 'score': 0.692}, {'word': 'con', 'start': 4.305, 'end': 4.425, 'score': 0.661}, {'word': 'Rafael', 'start': 4.485, 'end': 4.905, 'score': 0.702}, {'word': 'Dávalo.', 'start': 4.965, 'end': 5.326, 'score': 0.774}, {'word': '¿Y', 'start': 6.486, 'end': 6.546, 'score': 0.568}, {'word': 'con', 'start': 6.586, 'end': 6.686, 'score': 0.436}, {'word': 'él?', 'start': 6.766, 'end': 6.906, 'score': 0.495}, {'word': 'Le', 'start': 7.827, 'end': 7.927, 'score': 0.788}, {'word': 'habla', 'start': 7.987, 'end': 8.147, 'score': 0.447}, {'word': 'Angie', 'start': 8.187, 'end': 8.467, 'score': 0.749}, {'word': 'Valente,', 'start': 8.487, 'end': 8.868, 'score': 0.566}, {'word': 'de', 'start': 8.888, 'end': 8.928, 'score': 0.004}, {'word': 'la', 'start': 8.948, 'end': 9.028, 'score': 0.658}, {'word': 'Universidad', 'start': 9.068, 'end': 9.568, 'score': 0.867}, {'word': 'Javeriana', 'start': 9.588, 'end': 10.068, 'score': 0.609}, {'word': 'de', 'start': 10.088, 'end': 10.188, 'score': 0.736}, {'word': 'Cali.', 'start': 10.228, 'end': 10.508, 'score': 0.74}, {'word': '¿Cómo', 'start': 10.548, 'end': 10.689, 'score': 0.865}, {'word': 'se', 'start': 10.709, 'end': 10.749, 'score': 0.018}, {'word': 'encuentra?', 'start': 10.869, 'end': 11.369, 'score': 0.791}, {'word': 'Muy', 'start': 12.41, 'end': 12.57, 'score': 0.468}, {'word': 'bien,', 'start': 12.59, 'end': 12.73, 'score': 0.613}, {'word': 'gracias', 'start': 12.79, 'end': 13.01, 'score': 0.151}, {'word': 'a', 'start': 13.03, 'end': 13.05, 'score': 0.018}, {'word': 'Dios,', 'start': 13.07, 'end': 13.15, 'score': 0.139}, {'word': 'usted.', 'start': 13.27, 'end': 13.67, 'score': 0.476}, {'word': 'Muy', 'start': 14.911, 'end': 15.071, 'score': 0.683}, {'word': 'bien,', 'start': 15.131, 'end': 15.311, 'score': 0.712}, {'word': 'gracias', 'start': 15.331, 'end': 15.651, 'score': 0.473}, {'word': 'a', 'start': 15.691, 'end': 15.751, 'score': 0.715}, {'word': 'Dios.', 'start': 15.771, 'end': 16.052, 'score': 0.746}, {'word': 'Nos', 'start': 16.932, 'end': 17.072, 'score': 0.758}, {'word': 'estamos', 'start': 17.132, 'end': 17.432, 'score': 0.703}, {'word': 'comunicando,', 'start': 17.472, 'end': 18.013, 'score': 0.808}, {'word': 'señor', 'start': 18.093, 'end': 18.313, 'score': 0.893}, {'word': 'Rafael,', 'start': 18.693, 'end': 19.133, 'score': 0.753}, {'word': 'por', 'start': 19.193, 'end': 19.293, 'score': 0.975}, {'word': 'su', 'start': 19.333, 'end': 19.413, 'score': 0.946}, {'word': 'interés', 'start': 19.493, 'end': 19.894, 'score': 0.858}, {'word': 'en', 'start': 20.094, 'end': 20.254, 'score': 0.965}, {'word': 'el', 'start': 20.334, 'end': 20.414, 'score': 0.919}, {'word': 'seminario', 'start': 20.494, 'end': 20.974, 'score': 0.843}, {'word': 'en', 'start': 21.014, 'end': 21.114, 'score': 0.582}, {'word': 'Business', 'start': 21.174, 'end': 21.575, 'score': 0.56}, {'word': 'Analysis', 'start': 21.635, 'end': 22.295, 'score': 0.624}, {'word': 'con', 'start': 22.655, 'end': 22.795, 'score': 0.589}, {'word': 'Power', 'start': 22.815, 'end': 23.035, 'score': 0.54}, {'word': 'BI.', 'start': 23.095, 'end': 23.336, 'score': 0.616}, {'word': 'Ajá,', 'start': 24.796, 'end': 25.097, 'score': 0.606}, {'word': 'sí,', 'start': 25.117, 'end': 25.237, 'score': 0.519}, {'word': 'señora.', 'start': 25.257, 'end': 25.657, 'score': 0.572}, {'word': 'Bueno,', 'start': 27.318, 'end': 28.058, 'score': 0.777}, {'word': 'usted', 'start': 28.098, 'end': 28.258, 'score': 0.893}, {'word': 'se', 'start': 28.278, 'end': 28.318, 'score': 0.022}, {'word': 'encuentra', 'start': 28.438, 'end': 28.719, 'score': 0.721}, {'word': 'en', 'start': 28.739, 'end': 28.779, 'score': 0.273}, {'word': 'la', 'start': 28.819, 'end': 28.899, 'score': 0.726}, {'word': 'ciudad', 'start': 28.919, 'end': 29.099, 'score': 0.401}, {'word': 'de', 'start': 29.119, 'end': 29.219, 'score': 0.591}, {'word': 'Cali.', 'start': 29.259, 'end': 29.479, 'score': 0.711}, {'word': 'Sí,', 'start': 30.503, 'end': 30.543, 'score': 0.264}, {'word': 'señora.', 'start': 30.563, 'end': 30.723, 'score': 0.398}, {'word': 'Este', 'start': 30.803, 'end': 31.103, 'score': 0.684}, {'word': 'seminario', 'start': 32.263, 'end': 32.944, 'score': 0.857}, {'word': 'se', 'start': 33.004, 'end': 33.104, 'score': 0.644}, {'word': 'dictará', 'start': 33.164, 'end': 33.544, 'score': 0.822}, {'word': 'de', 'start': 33.584, 'end': 33.664, 'score': 0.677}, {'word': 'manera', 'start': 33.704, 'end': 33.984, 'score': 0.88}, {'word': 'presencial', 'start': 34.084, 'end': 34.844, 'score': 0.778}, {'word': 'en', 'start': 34.864, 'end': 34.904, 'score': 0.0}, {'word': 'el', 'start': 35.204, 'end': 35.284, 'score': 0.782}, {'word': 'campus', 'start': 35.364, 'end': 35.704, 'score': 0.889}, {'word': 'universitario.', 'start': 35.724, 'end': 36.564, 'score': 0.778}, {'word': 'Iniciaría', 'start': 37.164, 'end': 37.805, 'score': 0.905}, {'word': 'el', 'start': 37.845, 'end': 37.925, 'score': 0.68}, {'word': 'veintidós', 'start': 37.985, 'end': 38.525, 'score': 0.783}, {'word': 'de', 'start': 38.585, 'end': 38.685, 'score': 0.768}, {'word': 'junio', 'start': 38.825, 'end': 39.225, 'score': 0.488}, {'word': 'y', 'start': 39.245, 'end': 39.265, 'score': 0.002}, {'word': 'finalizaría', 'start': 39.945, 'end': 40.825, 'score': 0.975}, {'word': 'el', 'start': 41.285, 'end': 41.545, 'score': 0.924}, {'word': 'treinta', 'start': 42.526, 'end': 42.806, 'score': 0.744}, {'word': 'y', 'start': 42.826, 'end': 42.866, 'score': 0.498}, {'word': 'uno', 'start': 42.906, 'end': 43.026, 'score': 0.823}, {'word': 'de', 'start': 43.066, 'end': 43.146, 'score': 0.781}, {'word': 'julio.', 'start': 43.246, 'end': 43.606, 'score': 0.911}, {'word': '¿Qué', 'start': 44.606, 'end': 44.686, 'score': 0.512}, {'word': 'tenés', 'start': 44.726, 'end': 44.846, 'score': 0.237}, {'word': 'a', 'start': 44.866, 'end': 44.926, 'score': 0.547}, {'word': 'la', 'start': 44.946, 'end': 45.006, 'score': 0.633}, {'word': 'pregunta?', 'start': 45.026, 'end': 45.286, 'score': 0.835}, {'word': '¿Este', 'start': 45.306, 'end': 45.446, 'score': 0.376}, {'word': 'es', 'start': 45.486, 'end': 45.546, 'score': 0.43}, {'word': 'el', 'start': 45.626, 'end': 45.686, 'score': 0.886}, {'word': 'curso', 'start': 45.726, 'end': 45.926, 'score': 0.627}, {'word': 'de', 'start': 45.946, 'end': 46.026, 'score': 0.59}, {'word': 'Python?', 'start': 46.066, 'end': 46.386, 'score': 0.448}, {'word': 'No,', 'start': 48.667, 'end': 48.747, 'score': 0.5}, {'word': 'señor.', 'start': 48.827, 'end': 49.147, 'score': 0.949}, {'word': 'Seminario', 'start': 49.867, 'end': 50.327, 'score': 0.781}, {'word': 'en', 'start': 50.347, 'end': 50.387, 'score': 0.07}, {'word': 'Business', 'start': 50.447, 'end': 51.027, 'score': 0.609}, {'word': 'y', 'start': 51.147, 'end': 51.227, 'score': 0.504}, {'word': 'análisis', 'start': 51.287, 'end': 51.647, 'score': 0.745}, {'word': 'de', 'start': 51.667, 'end': 51.728, 'score': 0.712}, {'word': 'Big', 'start': 51.788, 'end': 51.908, 'score': 0.657}, {'word': 'Data', 'start': 51.948, 'end': 52.168, 'score': 0.75}, {'word': 'con', 'start': 52.208, 'end': 52.328, 'score': 0.859}, {'word': 'Power', 'start': 52.368, 'end': 52.628, 'score': 0.81}, {'word': 'BI.', 'start': 52.668, 'end': 52.988, 'score': 0.802}, {'word': 'Ah,', 'start': 54.208, 'end': 54.388, 'score': 0.472}, {'word': 'ok,', 'start': 54.468, 'end': 54.628, 'score': 0.506}, {'word': 'ok.', 'start': 54.708, 'end': 54.748, 'score': 0.08}, {'word': 'Sí,', 'start': 54.928, 'end': 55.068, 'score': 0.524}, {'word': 'sí,', 'start': 55.108, 'end': 55.528, 'score': 0.675}, {'word': 'ya', 'start': 55.568, 'end': 55.688, 'score': 0.455}, {'word': 'recordé.', 'start': 55.728, 'end': 56.128, 'score': 0.908}, {'word': 'Este', 'start': 56.729, 'end': 57.329, 'score': 0.607}, {'word': 'seminario', 'start': 57.369, 'end': 57.769, 'score': 0.317}, {'word': 'es', 'start': 57.829, 'end': 57.889, 'score': 0.306}, {'word': 'gratuito,', 'start': 57.929, 'end': 58.349, 'score': 0.529}, {'word': '¿cierto?', 'start': 58.389, 'end': 58.589, 'score': 0.42}, {'word': 'Se', 'start': 60.674, 'end': 60.774, 'score': 0.396}, {'word': 'estaba,', 'start': 60.974, 'end': 61.374, 'score': 0.83}, {'word': 'digamos', 'start': 61.614, 'end': 61.935, 'score': 0.83}, {'word': 'que', 'start': 61.975, 'end': 62.055, 'score': 0.825}, {'word': 'se', 'start': 62.095, 'end': 62.175, 'score': 0.746}, {'word': 'estaba', 'start': 62.195, 'end': 62.475, 'score': 0.682}, {'word': 'ofertando', 'start': 62.495, 'end': 62.935, 'score': 0.818}, {'word': 'de', 'start': 62.975, 'end': 63.075, 'score': 0.631}, {'word': 'esa', 'start': 63.115, 'end': 63.275, 'score': 0.824}, {'word': 'manera,', 'start': 63.335, 'end': 63.676, 'score': 0.893}, {'word': 'pero', 'start': 63.816, 'end': 63.956, 'score': 0.965}, {'word': 'pues', 'start': 64.036, 'end': 64.176, 'score': 0.427}, {'word': 'con', 'start': 64.216, 'end': 64.336, 'score': 0.83}, {'word': 'un', 'start': 64.376, 'end': 64.456, 'score': 0.742}, {'word': 'convenio', 'start': 64.496, 'end': 64.776, 'score': 0.837}, {'word': 'que', 'start': 64.816, 'end': 64.916, 'score': 0.677}, {'word': 'tenía', 'start': 64.976, 'end': 65.376, 'score': 0.868}, {'word': 'el', 'start': 65.396, 'end': 65.436, 'score': 0.0}, {'word': 'ICT', 'start': 65.917, 'end': 66.397, 'score': 0.834}, {'word': 'con', 'start': 66.517, 'end': 66.797, 'score': 0.79}, {'word': 'el', 'start': 66.977, 'end': 67.257, 'score': 0.828}, {'word': 'Ministerio', 'start': 67.337, 'end': 67.698, 'score': 0.89}, {'word': 'de', 'start': 67.738, 'end': 67.798, 'score': 0.879}, {'word': 'las', 'start': 67.838, 'end': 67.958, 'score': 0.79}, {'word': 'TIC,', 'start': 68.018, 'end': 68.258, 'score': 0.84}, {'word': 'pero', 'start': 68.838, 'end': 68.958, 'score': 0.961}, {'word': 'esa', 'start': 68.978, 'end': 69.098, 'score': 0.694}, {'word': 'convocatoria', 'start': 69.138, 'end': 69.619, 'score': 0.986}, {'word': 'ya', 'start': 69.719, 'end': 69.799, 'score': 0.211}, {'word': 'finalizó.', 'start': 69.859, 'end': 70.379, 'score': 0.924}, {'word': 'Ahorita', 'start': 70.399, 'end': 70.999, 'score': 0.803}, {'word': 'se', 'start': 71.099, 'end': 71.139, 'score': 0.166}, {'word': 'está', 'start': 71.159, 'end': 71.64, 'score': 0.851}, {'word': 'pues', 'start': 71.82, 'end': 71.94, 'score': 0.531}, {'word': 'manejando', 'start': 71.98, 'end': 72.4, 'score': 0.955}, {'word': 'ya', 'start': 72.46, 'end': 72.64, 'score': 0.373}, {'word': 'directamente', 'start': 72.72, 'end': 73.26, 'score': 0.929}, {'word': 'con', 'start': 73.321, 'end': 73.421, 'score': 0.969}, {'word': 'la', 'start': 73.461, 'end': 73.521, 'score': 0.761}, {'word': 'universidad', 'start': 73.561, 'end': 74.101, 'score': 0.898}, {'word': 'y', 'start': 74.161, 'end': 74.201, 'score': 0.649}, {'word': 'sí', 'start': 74.241, 'end': 74.321, 'score': 0.66}, {'word': 'tienen', 'start': 74.381, 'end': 74.641, 'score': 0.788}, {'word': 'valor.', 'start': 74.681, 'end': 74.981, 'score': 0.924}, {'word': 'Ok,', 'start': 76.662, 'end': 76.722, 'score': 0.352}, {'word': '¿y', 'start': 77.062, 'end': 77.102, 'score': 0.475}, {'word': 'qué', 'start': 77.162, 'end': 77.263, 'score': 0.246}, {'word': 'va', 'start': 77.283, 'end': 77.383, 'score': 0.53}, {'word': 'el', 'start': 77.423, 'end': 77.483, 'score': 0.306}, {'word': 'ICT?', 'start': 77.543, 'end': 77.943, 'score': 0.628}, {'word': 'Se', 'start': 78.783, 'end': 78.863, 'score': 0.743}, {'word': 'encuentra', 'start': 78.883, 'end': 79.344, 'score': 0.832}, {'word': 'en', 'start': 79.524, 'end': 79.624, 'score': 0.486}, {'word': 'ochocientos', 'start': 79.684, 'end': 80.164, 'score': 0.829}, {'word': 'cinco', 'start': 80.244, 'end': 80.484, 'score': 0.769}, {'word': 'mil', 'start': 80.564, 'end': 80.724, 'score': 0.617}, {'word': 'pesos.', 'start': 80.824, 'end': 81.145, 'score': 0.919}, {'word': 'Ok,', 'start': 81.165, 'end': 83.005, 'score': 0.702}, {'word': 'pero', 'start': 83.526, 'end': 83.806, 'score': 0.488}, {'word': 'yo', 'start': 83.846, 'end': 83.966, 'score': 0.546}, {'word': 'no', 'start': 84.006, 'end': 84.086, 'score': 0.382}, {'word': 'he', 'start': 84.126, 'end': 84.326, 'score': 0.378}, {'word': 'pagado', 'start': 84.346, 'end': 84.626, 'score': 0.469}, {'word': 'todavía', 'start': 84.646, 'end': 84.926, 'score': 0.373}, {'word': 'matrícula', 'start': 84.966, 'end': 85.387, 'score': 0.414}, {'word': 'ni', 'start': 85.427, 'end': 85.507, 'score': 0.43}, {'word': 'nada,', 'start': 85.527, 'end': 85.707, 'score': 0.362}, {'word': '¿no?', 'start': 85.727, 'end': 85.807, 'score': 0.551}, {'word': 'No,', 'start': 86.485, 'end': 86.565, 'score': 0.267}, {'word': 'no,', 'start': 86.765, 'end': 86.985, 'score': 0.46}, {'word': 'señor.', 'start': 87.025, 'end': 87.326, 'score': 0.671}, {'word': 'Precisamente', 'start': 87.466, 'end': 87.986, 'score': 0.759}, {'word': 'pues', 'start': 88.006, 'end': 88.266, 'score': 0.381}, {'word': 'me', 'start': 88.286, 'end': 88.366, 'score': 0.684}, {'word': 'comunico', 'start': 88.426, 'end': 88.787, 'score': 0.884}, {'word': 'es', 'start': 88.847, 'end': 88.907, 'score': 0.77}, {'word': 'para', 'start': 88.927, 'end': 89.047, 'score': 0.792}, {'word': 'brindarle', 'start': 89.087, 'end': 89.467, 'score': 0.626}, {'word': 'información.', 'start': 89.507, 'end': 90.188, 'score': 0.815}, {'word': 'Usted', 'start': 90.208, 'end': 90.468, 'score': 0.497}, {'word': 'dejó', 'start': 90.508, 'end': 90.628, 'score': 0.694}, {'word': 'los', 'start': 90.708, 'end': 90.788, 'score': 0.647}, {'word': 'datos', 'start': 90.828, 'end': 91.128, 'score': 0.818}, {'word': 'para', 'start': 91.268, 'end': 91.408, 'score': 0.9}, {'word': 'que', 'start': 91.509, 'end': 91.589, 'score': 0.326}, {'word': 'le', 'start': 91.609, 'end': 91.649, 'score': 0.782}, {'word': 'brindaran', 'start': 91.669, 'end': 92.109, 'score': 0.684}, {'word': 'información.', 'start': 92.169, 'end': 92.709, 'score': 0.839}, {'word': 'Sí,', 'start': 93.85, 'end': 93.99, 'score': 0.658}, {'word': 'sí,', 'start': 94.01, 'end': 94.491, 'score': 0.669}, {'word': 'entiendo.', 'start': 94.631, 'end': 95.011, 'score': 0.516}, {'word': 'Sí,', 'start': 95.651, 'end': 95.691, 'score': 0.064}, {'word': 'sino', 'start': 95.712, 'end': 95.852, 'score': 0.256}, {'word': 'que', 'start': 95.892, 'end': 95.992, 'score': 0.491}, {'word': 'como', 'start': 96.012, 'end': 96.152, 'score': 0.826}, {'word': 'me', 'start': 96.192, 'end': 96.272, 'score': 0.52}, {'word': 'decías', 'start': 96.292, 'end': 96.572, 'score': 0.46}, {'word': 'que', 'start': 96.592, 'end': 96.692, 'score': 0.393}, {'word': 'ya', 'start': 96.752, 'end': 97.133, 'score': 0.544}, {'word': 'empezaba', 'start': 97.173, 'end': 97.473, 'score': 0.397}, {'word': 'a', 'start': 97.513, 'end': 97.553, 'score': 0.488}, {'word': 'tal', 'start': 97.593, 'end': 97.733, 'score': 0.709}, {'word': 'fecha,', 'start': 97.753, 'end': 97.973, 'score': 0.394}, {'word': 'yo', 'start': 97.993, 'end': 98.073, 'score': 0.395}, {'word': 'quería', 'start': 98.133, 'end': 98.273, 'score': 0.157}, {'word': 'decir', 'start': 98.293, 'end': 98.513, 'score': 0.369}, {'word': 'ya', 'start': 98.554, 'end': 98.614, 'score': 0.2}, {'word': 'estaba', 'start': 98.634, 'end': 98.794, 'score': 0.329}, {'word': 'como', 'start': 98.814, 'end': 98.934, 'score': 0.348}, {'word': 'inscrito', 'start': 98.974, 'end': 99.414, 'score': 0.413}, {'word': 'o', 'start': 99.434, 'end': 99.454, 'score': 0.021}, {'word': 'algo', 'start': 99.474, 'end': 99.734, 'score': 0.557}, {'word': 'así.', 'start': 99.814, 'end': 99.894, 'score': 0.162}, {'word': 'Por', 'start': 99.995, 'end': 100.075, 'score': 0.189}, {'word': 'eso', 'start': 100.135, 'end': 100.295, 'score': 0.613}, {'word': 'preguntaba.', 'start': 100.335, 'end': 100.775, 'score': 0.426}, {'word': 'No,', 'start': 101.516, 'end': 101.636, 'score': 0.645}, {'word': 'no,', 'start': 101.816, 'end': 101.996, 'score': 0.552}, {'word': 'señor.', 'start': 102.036, 'end': 102.276, 'score': 0.806}, {'word': 'Este', 'start': 102.336, 'end': 102.476, 'score': 0.445}, {'word': 'iniciaría', 'start': 102.496, 'end': 102.917, 'score': 0.635}, {'word': 'el', 'start': 102.957, 'end': 103.037, 'score': 0.698}, {'word': 'veintidós', 'start': 103.077, 'end': 103.537, 'score': 0.859}, {'word': 'de', 'start': 103.577, 'end': 103.657, 'score': 0.77}, {'word': 'junio.', 'start': 103.777, 'end': 104.137, 'score': 0.962}, {'word': 'Ok.', 'start': 104.378, 'end': 105.378, 'score': 0.648}, {'word': 'Ajá.', 'start': 108.681, 'end': 108.821, 'score': 0.409}, {'word': 'Las', 'start': 111.289, 'end': 111.429, 'score': 0.812}, {'word': 'clases', 'start': 111.469, 'end': 111.769, 'score': 0.786}, {'word': 'presenciales', 'start': 111.829, 'end': 112.35, 'score': 0.855}, {'word': 'serían', 'start': 112.39, 'end': 112.67, 'score': 0.856}, {'word': 'los', 'start': 112.73, 'end': 112.85, 'score': 0.821}, {'word': 'días', 'start': 112.93, 'end': 113.33, 'score': 0.862}, {'word': 'lunes', 'start': 113.67, 'end': 113.991, 'score': 0.875}, {'word': 'y', 'start': 114.111, 'end': 114.131, 'score': 0.003}, {'word': 'jueves', 'start': 114.211, 'end': 114.511, 'score': 0.896}, {'word': 'de', 'start': 114.591, 'end': 114.671, 'score': 0.792}, {'word': 'seis', 'start': 114.711, 'end': 114.911, 'score': 0.665}, {'word': 'y', 'start': 114.951, 'end': 114.991, 'score': 0.663}, {'word': 'media,', 'start': 115.031, 'end': 115.251, 'score': 0.955}, {'word': 'nueve', 'start': 115.271, 'end': 115.431, 'score': 0.305}, {'word': 'y', 'start': 115.491, 'end': 115.531, 'score': 0.59}, {'word': 'media', 'start': 115.591, 'end': 115.852, 'score': 0.872}, {'word': 'de', 'start': 115.872, 'end': 115.952, 'score': 0.394}, {'word': 'la', 'start': 115.992, 'end': 116.072, 'score': 0.834}, {'word': 'noche.', 'start': 116.132, 'end': 116.392, 'score': 0.443}, {'word': '¿Tendría', 'start': 116.872, 'end': 117.192, 'score': 0.59}, {'word': 'de', 'start': 117.212, 'end': 117.252, 'score': 0.007}, {'word': 'pronto', 'start': 117.272, 'end': 117.472, 'score': 0.745}, {'word': 'algún', 'start': 117.512, 'end': 117.693, 'score': 0.783}, {'word': 'inconveniente', 'start': 117.733, 'end': 118.193, 'score': 0.86}, {'word': 'con', 'start': 118.233, 'end': 118.353, 'score': 0.965}, {'word': 'ese', 'start': 118.393, 'end': 118.633, 'score': 0.895}, {'word': 'horario?', 'start': 118.753, 'end': 119.093, 'score': 0.929}, {'word': 'Sí,', 'start': 119.614, 'end': 119.694, 'score': 0.44}, {'word': 'no,', 'start': 119.734, 'end': 119.794, 'score': 0.268}, {'word': 'eso', 'start': 119.834, 'end': 119.894, 'score': 0.041}, {'word': 'sí.', 'start': 119.914, 'end': 119.974, 'score': 0.196}, {'word': 'Por', 'start': 119.994, 'end': 120.054, 'score': 0.075}, {'word': 'el', 'start': 120.094, 'end': 120.214, 'score': 0.539}, {'word': 'trabajo.', 'start': 120.234, 'end': 120.494, 'score': 0.359}, {'word': 'La', 'start': 120.514, 'end': 120.594, 'score': 0.314}, {'word': 'verdad', 'start': 120.614, 'end': 121.174, 'score': 0.57}, {'word': 'yo', 'start': 121.755, 'end': 121.995, 'score': 0.784}, {'word': 'creí', 'start': 122.035, 'end': 122.355, 'score': 0.416}, {'word': 'que', 'start': 123.616, 'end': 123.696, 'score': 0.173}, {'word': 'era', 'start': 123.776, 'end': 125.297, 'score': 0.63}, {'word': 'iba', 'start': 126.437, 'end': 126.557, 'score': 0.493}, {'word': 'a', 'start': 126.797, 'end': 126.837, 'score': 0.495}, {'word': 'ser', 'start': 126.917, 'end': 127.038, 'score': 0.49}, {'word': 'virtual.', 'start': 127.118, 'end': 128.518, 'score': 0.417}, {'word': 'Es', 'start': 128.578, 'end': 128.638, 'score': 0.884}, {'word': 'online,', 'start': 128.698, 'end': 129.099, 'score': 0.608}, {'word': 'bueno,', 'start': 129.299, 'end': 129.519, 'score': 0.653}, {'word': 'se', 'start': 129.539, 'end': 129.639, 'score': 0.728}, {'word': 'maneja', 'start': 129.659, 'end': 129.939, 'score': 0.743}, {'word': 'un', 'start': 129.959, 'end': 130.039, 'score': 0.819}, {'word': 'online,', 'start': 130.079, 'end': 130.539, 'score': 0.535}, {'word': 'pero', 'start': 130.579, 'end': 130.72, 'score': 0.857}, {'word': 'ya', 'start': 130.76, 'end': 130.84, 'score': 0.936}, {'word': 'sería', 'start': 130.94, 'end': 131.18, 'score': 0.883}, {'word': 'para', 'start': 131.26, 'end': 131.38, 'score': 0.948}, {'word': 'el', 'start': 131.42, 'end': 131.48, 'score': 0.934}, {'word': 'mes', 'start': 131.52, 'end': 131.68, 'score': 0.842}, {'word': 'de', 'start': 131.72, 'end': 131.8, 'score': 0.882}, {'word': 'julio.', 'start': 131.9, 'end': 132.26, 'score': 0.953}, {'word': 'El', 'start': 133.841, 'end': 133.881, 'score': 0.01}, {'word': 'mes', 'start': 133.901, 'end': 134.021, 'score': 0.394}, {'word': 'de', 'start': 134.061, 'end': 134.181, 'score': 0.39}, {'word': 'julio,', 'start': 134.221, 'end': 134.722, 'score': 0.605}, {'word': 'ok.', 'start': 134.842, 'end': 134.902, 'score': 0.25}, {'word': 'Pues', 'start': 136.686, 'end': 136.926, 'score': 0.329}, {'word': 'por', 'start': 136.986, 'end': 137.086, 'score': 0.941}, {'word': 'ahora', 'start': 137.126, 'end': 137.587, 'score': 0.98}, {'word': 'sí,', 'start': 137.607, 'end': 137.847, 'score': 0.606}, {'word': 'recibiré', 'start': 137.987, 'end': 139.007, 'score': 0.629}, {'word': 'la', 'start': 139.027, 'end': 139.067, 'score': 0.46}, {'word': 'información', 'start': 139.087, 'end': 139.567, 'score': 0.844}, {'word': 'y', 'start': 140.268, 'end': 140.388, 'score': 0.794}, {'word': 'creo', 'start': 140.548, 'end': 140.748, 'score': 0.396}, {'word': 'que', 'start': 140.848, 'end': 141.168, 'score': 0.697}, {'word': 'estaré', 'start': 141.528, 'end': 141.768, 'score': 0.438}, {'word': 'pendiente', 'start': 141.828, 'end': 142.088, 'score': 0.732}, {'word': 'para', 'start': 142.148, 'end': 142.268, 'score': 0.879}, {'word': 'confirmarlo.', 'start': 142.348, 'end': 142.849, 'score': 0.816}, {'word': 'Bueno,', 'start': 143.989, 'end': 144.269, 'score': 0.695}, {'word': 'sí,', 'start': 144.389, 'end': 144.489, 'score': 0.642}, {'word': 'señor.', 'start': 144.509, 'end': 144.829, 'score': 0.625}, {'word': 'Entonces', 'start': 144.849, 'end': 145.27, 'score': 0.769}, {'word': 'le', 'start': 145.31, 'end': 145.37, 'score': 0.912}, {'word': 'compartiré', 'start': 145.45, 'end': 146.01, 'score': 0.936}, {'word': 'información', 'start': 146.15, 'end': 146.63, 'score': 0.862}, {'word': 'vía', 'start': 146.69, 'end': 146.81, 'score': 0.622}, {'word': 'WhatsApp,', 'start': 146.85, 'end': 147.39, 'score': 0.62}, {'word': 'si', 'start': 147.41, 'end': 147.45, 'score': 0.046}, {'word': 'está', 'start': 147.51, 'end': 147.71, 'score': 0.831}, {'word': 'bien.', 'start': 147.751, 'end': 147.951, 'score': 0.786}, {'word': 'Y', 'start': 150.011, 'end': 150.051, 'score': 0.664}, {'word': 'pues', 'start': 150.111, 'end': 150.251, 'score': 0.938}, {'word': 'por', 'start': 150.291, 'end': 150.412, 'score': 0.736}, {'word': 'ese', 'start': 150.432, 'end': 150.552, 'score': 0.761}, {'word': 'medio', 'start': 150.612, 'end': 150.832, 'score': 0.919}, {'word': 'podríamos', 'start': 150.912, 'end': 151.312, 'score': 0.814}, {'word': 'continuar', 'start': 151.392, 'end': 151.732, 'score': 0.866}, {'word': 'en', 'start': 151.772, 'end': 151.852, 'score': 0.726}, {'word': 'contacto.', 'start': 151.892, 'end': 152.332, 'score': 0.968}, {'word': 'Bueno.', 'start': 152.372, 'end': 152.592, 'score': 0.599}, {'word': 'Listo,', 'start': 153.673, 'end': 153.993, 'score': 0.435}, {'word': 'muchísimas', 'start': 154.013, 'end': 154.453, 'score': 0.423}, {'word': 'gracias.', 'start': 154.473, 'end': 155.173, 'score': 0.521}, {'word': 'Bueno,', 'start': 155.213, 'end': 155.413, 'score': 0.641}, {'word': 'señor,', 'start': 155.474, 'end': 155.794, 'score': 0.821}, {'word': 'con', 'start': 155.854, 'end': 155.994, 'score': 0.971}, {'word': 'gusto.', 'start': 156.034, 'end': 156.294, 'score': 0.855}, {'word': 'Que', 'start': 156.314, 'end': 156.374, 'score': 0.002}, {'word': 'esté', 'start': 156.434, 'end': 156.634, 'score': 0.32}, {'word': 'muy', 'start': 156.674, 'end': 156.774, 'score': 0.701}, {'word': 'bien.', 'start': 156.814, 'end': 156.934, 'score': 0.853}, {'word': 'Hasta', 'start': 156.974, 'end': 157.154, 'score': 0.672}, {'word': 'luego.', 'start': 157.194, 'end': 157.434, 'score': 0.598}, {'word': 'Hasta', 'start': 157.474, 'end': 157.814, 'score': 0.509}, {'word': 'luego,', 'start': 158.215, 'end': 158.755, 'score': 0.587}, {'word': 'mamá.', 'start': 158.795, 'end': 158.995, 'score': 0.54}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONVERSION A MONO"
      ],
      "metadata": {
        "id": "NPxb96ZjWm4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "sound = AudioSegment.from_file(vocal_target).set_channels(1)\n",
        "ROOT = os.getcwd()\n",
        "temp_path = os.path.join(ROOT, \"temp_outputs\")\n",
        "os.makedirs(temp_path, exist_ok=True)\n",
        "sound.export(os.path.join(temp_path, \"mono_file.wav\"), format=\"wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS_e9xMbWq7q",
        "outputId": "08535763-8989-4fa2-ca17-e903f4de073e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.98 ms, sys: 5.04 ms, total: 15 ms\n",
            "Wall time: 15.2 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/temp_outputs/mono_file.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DIARIZACION AUDIO"
      ],
      "metadata": {
        "id": "ehZT-TcOXMSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Initialize NeMo MSDD diarization model\n",
        "# DOMAIN_TYPE: can be meeting, telephonic, or general based on domain type of the audio file\n",
        "msdd_model = NeuralDiarizer(cfg=create_config(temp_path, DOMAIN_TYPE=\"telephonic\")).to(\"cuda\")\n",
        "msdd_model.diarize()\n",
        "\n",
        "del msdd_model\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-7yZ2mPXOmW",
        "outputId": "7083b5e9-7478-423a-aa69-d02ebd7d606f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:42:44 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-18 02:42:44 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/diar_msdd_telephonic/versions/1.0.1/files/diar_msdd_telephonic.nemo to /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-18 02:42:46 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-18 02:42:47 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-18 02:42:47 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-18 02:42:47 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:42:47 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-18 02:42:47 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-18 02:42:48 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-18 02:42:48 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-18 02:42:49 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-18 02:42:49 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/vad_multilingual_marblenet/versions/1.10.0/files/vad_multilingual_marblenet.nemo to /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-18 02:42:49 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-18 02:42:49 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-18 02:42:49 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-18 02:42:49 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:42:49 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-18 02:42:49 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-18 02:42:50 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-18 02:42:50 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n",
            "[NeMo I 2024-08-18 02:42:50 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-18 02:42:50 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:14<00:00, 14.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:04 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-18 02:43:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-18 02:43:04 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n",
            "[NeMo I 2024-08-18 02:43:04 collections:304] # 4 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 4/4 [00:00<00:00,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:05 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:06 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-18 02:43:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-18 02:43:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-18 02:43:07 collections:302] Dataset loaded with 145 items, total duration of  0.05 hours.\n",
            "[NeMo I 2024-08-18 02:43:07 collections:304] # 145 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-18 02:43:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-18 02:43:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-18 02:43:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-18 02:43:07 collections:302] Dataset loaded with 174 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-18 02:43:07 collections:304] # 174 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:08 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-18 02:43:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-18 02:43:08 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-18 02:43:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-18 02:43:08 collections:302] Dataset loaded with 222 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-18 02:43:08 collections:304] # 222 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:09 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-18 02:43:09 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-18 02:43:09 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-18 02:43:09 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-18 02:43:09 collections:302] Dataset loaded with 297 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-18 02:43:09 collections:304] # 297 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:09 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-18 02:43:09 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-18 02:43:09 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-18 02:43:09 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-18 02:43:09 collections:302] Dataset loaded with 456 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-18 02:43:09 collections:304] # 456 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 8/8 [00:01<00:00,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:11 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:13 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-18 02:43:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:13 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-18 02:43:13 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-18 02:43:13 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-18 02:43:13 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-18 02:43:13 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-18 02:43:13 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-18 02:43:13 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-18 02:43:13 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 22.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:13 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-18 02:43:13 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-18 02:43:13 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-18 02:43:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:13 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-18 02:43:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:13 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-18 02:43:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-18 02:43:13 msdd_models:1431]   \n",
            "    \n",
            "CPU times: user 22.8 s, sys: 930 ms, total: 23.8 s\n",
            "Wall time: 28.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAPEO HABLANTES POR TIEMPO"
      ],
      "metadata": {
        "id": "JiwE05-CXrZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Reading timestamps <> Speaker Labels mapping\n",
        "\n",
        "speaker_ts = []\n",
        "with open(os.path.join(temp_path, \"pred_rttms\", \"mono_file.rttm\"), \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        line_list = line.split(\" \")\n",
        "        s = int(float(line_list[5]) * 1000)\n",
        "        e = s + int(float(line_list[8]) * 1000)\n",
        "        speaker_ts.append([s, e, int(line_list[11].split(\"_\")[-1])])\n",
        "\n",
        "wsm = get_words_speaker_mapping(word_timestamps, speaker_ts, \"start\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0HunlKQXtVM",
        "outputId": "5309f7c0-d640-489f-df50-0d2c1f8e62a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.47 ms, sys: 0 ns, total: 2.47 ms\n",
            "Wall time: 2.29 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wsm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mmJZY70YDDk",
        "outputId": "8b9835e6-b85e-47d1-e9e6-1cb4f754704c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'word': 'Aló.', 'start_time': 663, 'end_time': 803, 'speaker': 0}, {'word': 'Buenos', 'start_time': 823, 'end_time': 3324, 'speaker': 0}, {'word': 'días,', 'start_time': 3385, 'end_time': 3725, 'speaker': 1}, {'word': 'me', 'start_time': 3745, 'end_time': 3825, 'speaker': 1}, {'word': 'comunico', 'start_time': 3865, 'end_time': 4265, 'speaker': 1}, {'word': 'con', 'start_time': 4305, 'end_time': 4425, 'speaker': 1}, {'word': 'Rafael', 'start_time': 4485, 'end_time': 4905, 'speaker': 1}, {'word': 'Dávalo.', 'start_time': 4965, 'end_time': 5326, 'speaker': 1}, {'word': '¿Y', 'start_time': 6486, 'end_time': 6546, 'speaker': 0}, {'word': 'con', 'start_time': 6586, 'end_time': 6686, 'speaker': 0}, {'word': 'él?', 'start_time': 6766, 'end_time': 6906, 'speaker': 0}, {'word': 'Le', 'start_time': 7827, 'end_time': 7927, 'speaker': 1}, {'word': 'habla', 'start_time': 7987, 'end_time': 8147, 'speaker': 1}, {'word': 'Angie', 'start_time': 8186, 'end_time': 8467, 'speaker': 1}, {'word': 'Valente,', 'start_time': 8487, 'end_time': 8868, 'speaker': 1}, {'word': 'de', 'start_time': 8888, 'end_time': 8928, 'speaker': 1}, {'word': 'la', 'start_time': 8948, 'end_time': 9028, 'speaker': 1}, {'word': 'Universidad', 'start_time': 9068, 'end_time': 9568, 'speaker': 1}, {'word': 'Javeriana', 'start_time': 9588, 'end_time': 10068, 'speaker': 1}, {'word': 'de', 'start_time': 10088, 'end_time': 10188, 'speaker': 1}, {'word': 'Cali.', 'start_time': 10228, 'end_time': 10508, 'speaker': 1}, {'word': '¿Cómo', 'start_time': 10548, 'end_time': 10689, 'speaker': 1}, {'word': 'se', 'start_time': 10709, 'end_time': 10749, 'speaker': 1}, {'word': 'encuentra?', 'start_time': 10869, 'end_time': 11369, 'speaker': 1}, {'word': 'Muy', 'start_time': 12410, 'end_time': 12570, 'speaker': 0}, {'word': 'bien,', 'start_time': 12590, 'end_time': 12730, 'speaker': 0}, {'word': 'gracias', 'start_time': 12790, 'end_time': 13010, 'speaker': 0}, {'word': 'a', 'start_time': 13030, 'end_time': 13050, 'speaker': 0}, {'word': 'Dios,', 'start_time': 13070, 'end_time': 13150, 'speaker': 0}, {'word': 'usted.', 'start_time': 13270, 'end_time': 13670, 'speaker': 0}, {'word': 'Muy', 'start_time': 14911, 'end_time': 15071, 'speaker': 1}, {'word': 'bien,', 'start_time': 15131, 'end_time': 15311, 'speaker': 1}, {'word': 'gracias', 'start_time': 15331, 'end_time': 15651, 'speaker': 1}, {'word': 'a', 'start_time': 15691, 'end_time': 15751, 'speaker': 1}, {'word': 'Dios.', 'start_time': 15771, 'end_time': 16052, 'speaker': 1}, {'word': 'Nos', 'start_time': 16932, 'end_time': 17072, 'speaker': 1}, {'word': 'estamos', 'start_time': 17132, 'end_time': 17432, 'speaker': 1}, {'word': 'comunicando,', 'start_time': 17472, 'end_time': 18013, 'speaker': 1}, {'word': 'señor', 'start_time': 18093, 'end_time': 18313, 'speaker': 1}, {'word': 'Rafael,', 'start_time': 18693, 'end_time': 19133, 'speaker': 1}, {'word': 'por', 'start_time': 19193, 'end_time': 19293, 'speaker': 1}, {'word': 'su', 'start_time': 19333, 'end_time': 19413, 'speaker': 1}, {'word': 'interés', 'start_time': 19493, 'end_time': 19894, 'speaker': 1}, {'word': 'en', 'start_time': 20094, 'end_time': 20254, 'speaker': 1}, {'word': 'el', 'start_time': 20334, 'end_time': 20414, 'speaker': 1}, {'word': 'seminario', 'start_time': 20494, 'end_time': 20974, 'speaker': 1}, {'word': 'en', 'start_time': 21014, 'end_time': 21114, 'speaker': 1}, {'word': 'Business', 'start_time': 21174, 'end_time': 21575, 'speaker': 1}, {'word': 'Analysis', 'start_time': 21635, 'end_time': 22295, 'speaker': 1}, {'word': 'con', 'start_time': 22655, 'end_time': 22795, 'speaker': 1}, {'word': 'Power', 'start_time': 22815, 'end_time': 23035, 'speaker': 1}, {'word': 'BI.', 'start_time': 23095, 'end_time': 23336, 'speaker': 1}, {'word': 'Ajá,', 'start_time': 24796, 'end_time': 25097, 'speaker': 0}, {'word': 'sí,', 'start_time': 25117, 'end_time': 25237, 'speaker': 0}, {'word': 'señora.', 'start_time': 25257, 'end_time': 25657, 'speaker': 0}, {'word': 'Bueno,', 'start_time': 27318, 'end_time': 28058, 'speaker': 1}, {'word': 'usted', 'start_time': 28098, 'end_time': 28258, 'speaker': 1}, {'word': 'se', 'start_time': 28278, 'end_time': 28318, 'speaker': 1}, {'word': 'encuentra', 'start_time': 28438, 'end_time': 28719, 'speaker': 1}, {'word': 'en', 'start_time': 28739, 'end_time': 28779, 'speaker': 1}, {'word': 'la', 'start_time': 28819, 'end_time': 28899, 'speaker': 1}, {'word': 'ciudad', 'start_time': 28919, 'end_time': 29099, 'speaker': 1}, {'word': 'de', 'start_time': 29119, 'end_time': 29219, 'speaker': 1}, {'word': 'Cali.', 'start_time': 29259, 'end_time': 29479, 'speaker': 1}, {'word': 'Sí,', 'start_time': 30503, 'end_time': 30543, 'speaker': 0}, {'word': 'señora.', 'start_time': 30563, 'end_time': 30723, 'speaker': 0}, {'word': 'Este', 'start_time': 30803, 'end_time': 31103, 'speaker': 0}, {'word': 'seminario', 'start_time': 32262, 'end_time': 32944, 'speaker': 1}, {'word': 'se', 'start_time': 33004, 'end_time': 33104, 'speaker': 1}, {'word': 'dictará', 'start_time': 33164, 'end_time': 33544, 'speaker': 1}, {'word': 'de', 'start_time': 33584, 'end_time': 33664, 'speaker': 1}, {'word': 'manera', 'start_time': 33704, 'end_time': 33984, 'speaker': 1}, {'word': 'presencial', 'start_time': 34084, 'end_time': 34844, 'speaker': 1}, {'word': 'en', 'start_time': 34864, 'end_time': 34904, 'speaker': 1}, {'word': 'el', 'start_time': 35204, 'end_time': 35284, 'speaker': 1}, {'word': 'campus', 'start_time': 35364, 'end_time': 35704, 'speaker': 1}, {'word': 'universitario.', 'start_time': 35724, 'end_time': 36564, 'speaker': 1}, {'word': 'Iniciaría', 'start_time': 37164, 'end_time': 37805, 'speaker': 1}, {'word': 'el', 'start_time': 37845, 'end_time': 37925, 'speaker': 1}, {'word': 'veintidós', 'start_time': 37985, 'end_time': 38525, 'speaker': 1}, {'word': 'de', 'start_time': 38585, 'end_time': 38685, 'speaker': 1}, {'word': 'junio', 'start_time': 38825, 'end_time': 39225, 'speaker': 1}, {'word': 'y', 'start_time': 39245, 'end_time': 39265, 'speaker': 1}, {'word': 'finalizaría', 'start_time': 39945, 'end_time': 40825, 'speaker': 1}, {'word': 'el', 'start_time': 41285, 'end_time': 41545, 'speaker': 1}, {'word': 'treinta', 'start_time': 42526, 'end_time': 42806, 'speaker': 1}, {'word': 'y', 'start_time': 42826, 'end_time': 42866, 'speaker': 1}, {'word': 'uno', 'start_time': 42906, 'end_time': 43026, 'speaker': 1}, {'word': 'de', 'start_time': 43066, 'end_time': 43146, 'speaker': 1}, {'word': 'julio.', 'start_time': 43246, 'end_time': 43606, 'speaker': 1}, {'word': '¿Qué', 'start_time': 44606, 'end_time': 44686, 'speaker': 0}, {'word': 'tenés', 'start_time': 44726, 'end_time': 44846, 'speaker': 0}, {'word': 'a', 'start_time': 44866, 'end_time': 44926, 'speaker': 0}, {'word': 'la', 'start_time': 44946, 'end_time': 45006, 'speaker': 0}, {'word': 'pregunta?', 'start_time': 45026, 'end_time': 45286, 'speaker': 0}, {'word': '¿Este', 'start_time': 45306, 'end_time': 45446, 'speaker': 0}, {'word': 'es', 'start_time': 45486, 'end_time': 45546, 'speaker': 0}, {'word': 'el', 'start_time': 45626, 'end_time': 45686, 'speaker': 0}, {'word': 'curso', 'start_time': 45726, 'end_time': 45926, 'speaker': 0}, {'word': 'de', 'start_time': 45946, 'end_time': 46026, 'speaker': 0}, {'word': 'Python?', 'start_time': 46066, 'end_time': 46386, 'speaker': 0}, {'word': 'No,', 'start_time': 48667, 'end_time': 48747, 'speaker': 1}, {'word': 'señor.', 'start_time': 48827, 'end_time': 49147, 'speaker': 1}, {'word': 'Seminario', 'start_time': 49867, 'end_time': 50327, 'speaker': 1}, {'word': 'en', 'start_time': 50347, 'end_time': 50387, 'speaker': 1}, {'word': 'Business', 'start_time': 50447, 'end_time': 51027, 'speaker': 1}, {'word': 'y', 'start_time': 51147, 'end_time': 51227, 'speaker': 1}, {'word': 'análisis', 'start_time': 51287, 'end_time': 51647, 'speaker': 1}, {'word': 'de', 'start_time': 51667, 'end_time': 51728, 'speaker': 1}, {'word': 'Big', 'start_time': 51788, 'end_time': 51908, 'speaker': 1}, {'word': 'Data', 'start_time': 51948, 'end_time': 52168, 'speaker': 1}, {'word': 'con', 'start_time': 52208, 'end_time': 52328, 'speaker': 1}, {'word': 'Power', 'start_time': 52368, 'end_time': 52628, 'speaker': 1}, {'word': 'BI.', 'start_time': 52668, 'end_time': 52988, 'speaker': 1}, {'word': 'Ah,', 'start_time': 54208, 'end_time': 54388, 'speaker': 0}, {'word': 'ok,', 'start_time': 54468, 'end_time': 54628, 'speaker': 0}, {'word': 'ok.', 'start_time': 54708, 'end_time': 54748, 'speaker': 0}, {'word': 'Sí,', 'start_time': 54928, 'end_time': 55068, 'speaker': 0}, {'word': 'sí,', 'start_time': 55108, 'end_time': 55528, 'speaker': 0}, {'word': 'ya', 'start_time': 55568, 'end_time': 55688, 'speaker': 0}, {'word': 'recordé.', 'start_time': 55728, 'end_time': 56128, 'speaker': 0}, {'word': 'Este', 'start_time': 56729, 'end_time': 57329, 'speaker': 0}, {'word': 'seminario', 'start_time': 57369, 'end_time': 57769, 'speaker': 0}, {'word': 'es', 'start_time': 57829, 'end_time': 57889, 'speaker': 0}, {'word': 'gratuito,', 'start_time': 57929, 'end_time': 58349, 'speaker': 0}, {'word': '¿cierto?', 'start_time': 58389, 'end_time': 58589, 'speaker': 0}, {'word': 'Se', 'start_time': 60674, 'end_time': 60774, 'speaker': 1}, {'word': 'estaba,', 'start_time': 60974, 'end_time': 61374, 'speaker': 1}, {'word': 'digamos', 'start_time': 61614, 'end_time': 61935, 'speaker': 1}, {'word': 'que', 'start_time': 61975, 'end_time': 62055, 'speaker': 1}, {'word': 'se', 'start_time': 62095, 'end_time': 62175, 'speaker': 1}, {'word': 'estaba', 'start_time': 62195, 'end_time': 62475, 'speaker': 1}, {'word': 'ofertando', 'start_time': 62495, 'end_time': 62935, 'speaker': 1}, {'word': 'de', 'start_time': 62975, 'end_time': 63075, 'speaker': 1}, {'word': 'esa', 'start_time': 63115, 'end_time': 63275, 'speaker': 1}, {'word': 'manera,', 'start_time': 63335, 'end_time': 63676, 'speaker': 1}, {'word': 'pero', 'start_time': 63816, 'end_time': 63956, 'speaker': 1}, {'word': 'pues', 'start_time': 64036, 'end_time': 64176, 'speaker': 1}, {'word': 'con', 'start_time': 64215, 'end_time': 64336, 'speaker': 1}, {'word': 'un', 'start_time': 64376, 'end_time': 64456, 'speaker': 1}, {'word': 'convenio', 'start_time': 64495, 'end_time': 64775, 'speaker': 1}, {'word': 'que', 'start_time': 64816, 'end_time': 64916, 'speaker': 1}, {'word': 'tenía', 'start_time': 64976, 'end_time': 65376, 'speaker': 1}, {'word': 'el', 'start_time': 65396, 'end_time': 65436, 'speaker': 1}, {'word': 'ICT', 'start_time': 65917, 'end_time': 66397, 'speaker': 1}, {'word': 'con', 'start_time': 66517, 'end_time': 66797, 'speaker': 1}, {'word': 'el', 'start_time': 66977, 'end_time': 67257, 'speaker': 1}, {'word': 'Ministerio', 'start_time': 67337, 'end_time': 67698, 'speaker': 1}, {'word': 'de', 'start_time': 67738, 'end_time': 67798, 'speaker': 1}, {'word': 'las', 'start_time': 67838, 'end_time': 67958, 'speaker': 1}, {'word': 'TIC,', 'start_time': 68018, 'end_time': 68258, 'speaker': 1}, {'word': 'pero', 'start_time': 68838, 'end_time': 68958, 'speaker': 1}, {'word': 'esa', 'start_time': 68978, 'end_time': 69098, 'speaker': 1}, {'word': 'convocatoria', 'start_time': 69138, 'end_time': 69619, 'speaker': 1}, {'word': 'ya', 'start_time': 69719, 'end_time': 69799, 'speaker': 1}, {'word': 'finalizó.', 'start_time': 69859, 'end_time': 70379, 'speaker': 1}, {'word': 'Ahorita', 'start_time': 70399, 'end_time': 70999, 'speaker': 1}, {'word': 'se', 'start_time': 71099, 'end_time': 71139, 'speaker': 1}, {'word': 'está', 'start_time': 71159, 'end_time': 71640, 'speaker': 1}, {'word': 'pues', 'start_time': 71820, 'end_time': 71940, 'speaker': 1}, {'word': 'manejando', 'start_time': 71980, 'end_time': 72400, 'speaker': 1}, {'word': 'ya', 'start_time': 72460, 'end_time': 72640, 'speaker': 1}, {'word': 'directamente', 'start_time': 72720, 'end_time': 73260, 'speaker': 1}, {'word': 'con', 'start_time': 73321, 'end_time': 73421, 'speaker': 1}, {'word': 'la', 'start_time': 73461, 'end_time': 73521, 'speaker': 1}, {'word': 'universidad', 'start_time': 73561, 'end_time': 74101, 'speaker': 1}, {'word': 'y', 'start_time': 74161, 'end_time': 74201, 'speaker': 1}, {'word': 'sí', 'start_time': 74241, 'end_time': 74321, 'speaker': 1}, {'word': 'tienen', 'start_time': 74381, 'end_time': 74641, 'speaker': 1}, {'word': 'valor.', 'start_time': 74681, 'end_time': 74981, 'speaker': 1}, {'word': 'Ok,', 'start_time': 76662, 'end_time': 76722, 'speaker': 0}, {'word': '¿y', 'start_time': 77062, 'end_time': 77102, 'speaker': 0}, {'word': 'qué', 'start_time': 77162, 'end_time': 77263, 'speaker': 0}, {'word': 'va', 'start_time': 77283, 'end_time': 77383, 'speaker': 0}, {'word': 'el', 'start_time': 77423, 'end_time': 77483, 'speaker': 0}, {'word': 'ICT?', 'start_time': 77543, 'end_time': 77943, 'speaker': 0}, {'word': 'Se', 'start_time': 78783, 'end_time': 78863, 'speaker': 1}, {'word': 'encuentra', 'start_time': 78883, 'end_time': 79344, 'speaker': 1}, {'word': 'en', 'start_time': 79524, 'end_time': 79624, 'speaker': 1}, {'word': 'ochocientos', 'start_time': 79684, 'end_time': 80164, 'speaker': 1}, {'word': 'cinco', 'start_time': 80244, 'end_time': 80484, 'speaker': 1}, {'word': 'mil', 'start_time': 80564, 'end_time': 80724, 'speaker': 1}, {'word': 'pesos.', 'start_time': 80824, 'end_time': 81145, 'speaker': 1}, {'word': 'Ok,', 'start_time': 81165, 'end_time': 83005, 'speaker': 0}, {'word': 'pero', 'start_time': 83526, 'end_time': 83806, 'speaker': 0}, {'word': 'yo', 'start_time': 83846, 'end_time': 83966, 'speaker': 0}, {'word': 'no', 'start_time': 84006, 'end_time': 84086, 'speaker': 0}, {'word': 'he', 'start_time': 84126, 'end_time': 84326, 'speaker': 0}, {'word': 'pagado', 'start_time': 84346, 'end_time': 84626, 'speaker': 0}, {'word': 'todavía', 'start_time': 84646, 'end_time': 84926, 'speaker': 0}, {'word': 'matrícula', 'start_time': 84966, 'end_time': 85387, 'speaker': 0}, {'word': 'ni', 'start_time': 85427, 'end_time': 85507, 'speaker': 0}, {'word': 'nada,', 'start_time': 85527, 'end_time': 85707, 'speaker': 0}, {'word': '¿no?', 'start_time': 85727, 'end_time': 85807, 'speaker': 0}, {'word': 'No,', 'start_time': 86485, 'end_time': 86565, 'speaker': 1}, {'word': 'no,', 'start_time': 86765, 'end_time': 86985, 'speaker': 1}, {'word': 'señor.', 'start_time': 87025, 'end_time': 87326, 'speaker': 1}, {'word': 'Precisamente', 'start_time': 87466, 'end_time': 87986, 'speaker': 1}, {'word': 'pues', 'start_time': 88006, 'end_time': 88266, 'speaker': 1}, {'word': 'me', 'start_time': 88286, 'end_time': 88366, 'speaker': 1}, {'word': 'comunico', 'start_time': 88426, 'end_time': 88787, 'speaker': 1}, {'word': 'es', 'start_time': 88847, 'end_time': 88907, 'speaker': 1}, {'word': 'para', 'start_time': 88927, 'end_time': 89047, 'speaker': 1}, {'word': 'brindarle', 'start_time': 89087, 'end_time': 89467, 'speaker': 1}, {'word': 'información.', 'start_time': 89507, 'end_time': 90188, 'speaker': 1}, {'word': 'Usted', 'start_time': 90208, 'end_time': 90468, 'speaker': 1}, {'word': 'dejó', 'start_time': 90508, 'end_time': 90628, 'speaker': 1}, {'word': 'los', 'start_time': 90708, 'end_time': 90788, 'speaker': 1}, {'word': 'datos', 'start_time': 90828, 'end_time': 91128, 'speaker': 1}, {'word': 'para', 'start_time': 91268, 'end_time': 91408, 'speaker': 1}, {'word': 'que', 'start_time': 91509, 'end_time': 91589, 'speaker': 1}, {'word': 'le', 'start_time': 91609, 'end_time': 91649, 'speaker': 1}, {'word': 'brindaran', 'start_time': 91669, 'end_time': 92109, 'speaker': 1}, {'word': 'información.', 'start_time': 92169, 'end_time': 92709, 'speaker': 1}, {'word': 'Sí,', 'start_time': 93850, 'end_time': 93990, 'speaker': 0}, {'word': 'sí,', 'start_time': 94010, 'end_time': 94491, 'speaker': 0}, {'word': 'entiendo.', 'start_time': 94631, 'end_time': 95011, 'speaker': 0}, {'word': 'Sí,', 'start_time': 95651, 'end_time': 95691, 'speaker': 0}, {'word': 'sino', 'start_time': 95712, 'end_time': 95852, 'speaker': 0}, {'word': 'que', 'start_time': 95892, 'end_time': 95992, 'speaker': 0}, {'word': 'como', 'start_time': 96012, 'end_time': 96152, 'speaker': 0}, {'word': 'me', 'start_time': 96192, 'end_time': 96272, 'speaker': 0}, {'word': 'decías', 'start_time': 96292, 'end_time': 96572, 'speaker': 0}, {'word': 'que', 'start_time': 96592, 'end_time': 96692, 'speaker': 0}, {'word': 'ya', 'start_time': 96752, 'end_time': 97133, 'speaker': 0}, {'word': 'empezaba', 'start_time': 97173, 'end_time': 97473, 'speaker': 0}, {'word': 'a', 'start_time': 97513, 'end_time': 97553, 'speaker': 0}, {'word': 'tal', 'start_time': 97593, 'end_time': 97733, 'speaker': 0}, {'word': 'fecha,', 'start_time': 97753, 'end_time': 97973, 'speaker': 0}, {'word': 'yo', 'start_time': 97993, 'end_time': 98073, 'speaker': 0}, {'word': 'quería', 'start_time': 98133, 'end_time': 98273, 'speaker': 0}, {'word': 'decir', 'start_time': 98293, 'end_time': 98513, 'speaker': 0}, {'word': 'ya', 'start_time': 98554, 'end_time': 98614, 'speaker': 0}, {'word': 'estaba', 'start_time': 98634, 'end_time': 98794, 'speaker': 0}, {'word': 'como', 'start_time': 98814, 'end_time': 98934, 'speaker': 0}, {'word': 'inscrito', 'start_time': 98974, 'end_time': 99414, 'speaker': 0}, {'word': 'o', 'start_time': 99434, 'end_time': 99454, 'speaker': 0}, {'word': 'algo', 'start_time': 99474, 'end_time': 99734, 'speaker': 0}, {'word': 'así.', 'start_time': 99814, 'end_time': 99894, 'speaker': 0}, {'word': 'Por', 'start_time': 99995, 'end_time': 100075, 'speaker': 0}, {'word': 'eso', 'start_time': 100135, 'end_time': 100295, 'speaker': 0}, {'word': 'preguntaba.', 'start_time': 100335, 'end_time': 100775, 'speaker': 0}, {'word': 'No,', 'start_time': 101516, 'end_time': 101636, 'speaker': 1}, {'word': 'no,', 'start_time': 101816, 'end_time': 101996, 'speaker': 1}, {'word': 'señor.', 'start_time': 102036, 'end_time': 102276, 'speaker': 1}, {'word': 'Este', 'start_time': 102336, 'end_time': 102476, 'speaker': 1}, {'word': 'iniciaría', 'start_time': 102496, 'end_time': 102917, 'speaker': 1}, {'word': 'el', 'start_time': 102957, 'end_time': 103037, 'speaker': 1}, {'word': 'veintidós', 'start_time': 103077, 'end_time': 103537, 'speaker': 1}, {'word': 'de', 'start_time': 103577, 'end_time': 103657, 'speaker': 1}, {'word': 'junio.', 'start_time': 103777, 'end_time': 104137, 'speaker': 1}, {'word': 'Ok.', 'start_time': 104378, 'end_time': 105378, 'speaker': 1}, {'word': 'Ajá.', 'start_time': 108681, 'end_time': 108821, 'speaker': 0}, {'word': 'Las', 'start_time': 111289, 'end_time': 111429, 'speaker': 1}, {'word': 'clases', 'start_time': 111469, 'end_time': 111769, 'speaker': 1}, {'word': 'presenciales', 'start_time': 111829, 'end_time': 112350, 'speaker': 1}, {'word': 'serían', 'start_time': 112390, 'end_time': 112670, 'speaker': 1}, {'word': 'los', 'start_time': 112730, 'end_time': 112850, 'speaker': 1}, {'word': 'días', 'start_time': 112930, 'end_time': 113330, 'speaker': 1}, {'word': 'lunes', 'start_time': 113670, 'end_time': 113991, 'speaker': 1}, {'word': 'y', 'start_time': 114111, 'end_time': 114131, 'speaker': 1}, {'word': 'jueves', 'start_time': 114211, 'end_time': 114511, 'speaker': 1}, {'word': 'de', 'start_time': 114591, 'end_time': 114671, 'speaker': 1}, {'word': 'seis', 'start_time': 114711, 'end_time': 114911, 'speaker': 1}, {'word': 'y', 'start_time': 114951, 'end_time': 114991, 'speaker': 1}, {'word': 'media,', 'start_time': 115031, 'end_time': 115251, 'speaker': 1}, {'word': 'nueve', 'start_time': 115271, 'end_time': 115431, 'speaker': 1}, {'word': 'y', 'start_time': 115491, 'end_time': 115531, 'speaker': 1}, {'word': 'media', 'start_time': 115591, 'end_time': 115852, 'speaker': 1}, {'word': 'de', 'start_time': 115872, 'end_time': 115952, 'speaker': 1}, {'word': 'la', 'start_time': 115992, 'end_time': 116072, 'speaker': 1}, {'word': 'noche.', 'start_time': 116132, 'end_time': 116392, 'speaker': 1}, {'word': '¿Tendría', 'start_time': 116872, 'end_time': 117192, 'speaker': 1}, {'word': 'de', 'start_time': 117212, 'end_time': 117252, 'speaker': 1}, {'word': 'pronto', 'start_time': 117272, 'end_time': 117472, 'speaker': 1}, {'word': 'algún', 'start_time': 117512, 'end_time': 117693, 'speaker': 1}, {'word': 'inconveniente', 'start_time': 117733, 'end_time': 118193, 'speaker': 1}, {'word': 'con', 'start_time': 118233, 'end_time': 118353, 'speaker': 1}, {'word': 'ese', 'start_time': 118393, 'end_time': 118633, 'speaker': 1}, {'word': 'horario?', 'start_time': 118753, 'end_time': 119093, 'speaker': 1}, {'word': 'Sí,', 'start_time': 119614, 'end_time': 119694, 'speaker': 0}, {'word': 'no,', 'start_time': 119734, 'end_time': 119794, 'speaker': 0}, {'word': 'eso', 'start_time': 119834, 'end_time': 119894, 'speaker': 0}, {'word': 'sí.', 'start_time': 119914, 'end_time': 119974, 'speaker': 0}, {'word': 'Por', 'start_time': 119994, 'end_time': 120054, 'speaker': 0}, {'word': 'el', 'start_time': 120094, 'end_time': 120214, 'speaker': 0}, {'word': 'trabajo.', 'start_time': 120234, 'end_time': 120494, 'speaker': 0}, {'word': 'La', 'start_time': 120514, 'end_time': 120594, 'speaker': 0}, {'word': 'verdad', 'start_time': 120614, 'end_time': 121174, 'speaker': 0}, {'word': 'yo', 'start_time': 121755, 'end_time': 121995, 'speaker': 0}, {'word': 'creí', 'start_time': 122035, 'end_time': 122355, 'speaker': 0}, {'word': 'que', 'start_time': 123616, 'end_time': 123696, 'speaker': 0}, {'word': 'era', 'start_time': 123776, 'end_time': 125297, 'speaker': 0}, {'word': 'iba', 'start_time': 126437, 'end_time': 126557, 'speaker': 0}, {'word': 'a', 'start_time': 126797, 'end_time': 126837, 'speaker': 0}, {'word': 'ser', 'start_time': 126917, 'end_time': 127038, 'speaker': 0}, {'word': 'virtual.', 'start_time': 127118, 'end_time': 128518, 'speaker': 0}, {'word': 'Es', 'start_time': 128578, 'end_time': 128638, 'speaker': 1}, {'word': 'online,', 'start_time': 128698, 'end_time': 129098, 'speaker': 1}, {'word': 'bueno,', 'start_time': 129299, 'end_time': 129519, 'speaker': 1}, {'word': 'se', 'start_time': 129538, 'end_time': 129639, 'speaker': 1}, {'word': 'maneja', 'start_time': 129658, 'end_time': 129939, 'speaker': 1}, {'word': 'un', 'start_time': 129959, 'end_time': 130038, 'speaker': 1}, {'word': 'online,', 'start_time': 130079, 'end_time': 130538, 'speaker': 1}, {'word': 'pero', 'start_time': 130579, 'end_time': 130720, 'speaker': 1}, {'word': 'ya', 'start_time': 130759, 'end_time': 130840, 'speaker': 1}, {'word': 'sería', 'start_time': 130940, 'end_time': 131180, 'speaker': 1}, {'word': 'para', 'start_time': 131260, 'end_time': 131380, 'speaker': 1}, {'word': 'el', 'start_time': 131420, 'end_time': 131480, 'speaker': 1}, {'word': 'mes', 'start_time': 131520, 'end_time': 131680, 'speaker': 1}, {'word': 'de', 'start_time': 131720, 'end_time': 131800, 'speaker': 1}, {'word': 'julio.', 'start_time': 131900, 'end_time': 132260, 'speaker': 1}, {'word': 'El', 'start_time': 133841, 'end_time': 133881, 'speaker': 0}, {'word': 'mes', 'start_time': 133901, 'end_time': 134021, 'speaker': 0}, {'word': 'de', 'start_time': 134061, 'end_time': 134181, 'speaker': 0}, {'word': 'julio,', 'start_time': 134221, 'end_time': 134722, 'speaker': 0}, {'word': 'ok.', 'start_time': 134842, 'end_time': 134902, 'speaker': 0}, {'word': 'Pues', 'start_time': 136686, 'end_time': 136926, 'speaker': 0}, {'word': 'por', 'start_time': 136986, 'end_time': 137086, 'speaker': 0}, {'word': 'ahora', 'start_time': 137126, 'end_time': 137587, 'speaker': 0}, {'word': 'sí,', 'start_time': 137607, 'end_time': 137847, 'speaker': 0}, {'word': 'recibiré', 'start_time': 137987, 'end_time': 139007, 'speaker': 0}, {'word': 'la', 'start_time': 139027, 'end_time': 139067, 'speaker': 0}, {'word': 'información', 'start_time': 139087, 'end_time': 139567, 'speaker': 0}, {'word': 'y', 'start_time': 140268, 'end_time': 140388, 'speaker': 0}, {'word': 'creo', 'start_time': 140548, 'end_time': 140748, 'speaker': 0}, {'word': 'que', 'start_time': 140848, 'end_time': 141168, 'speaker': 0}, {'word': 'estaré', 'start_time': 141528, 'end_time': 141768, 'speaker': 0}, {'word': 'pendiente', 'start_time': 141828, 'end_time': 142088, 'speaker': 0}, {'word': 'para', 'start_time': 142148, 'end_time': 142268, 'speaker': 0}, {'word': 'confirmarlo.', 'start_time': 142348, 'end_time': 142849, 'speaker': 0}, {'word': 'Bueno,', 'start_time': 143989, 'end_time': 144269, 'speaker': 1}, {'word': 'sí,', 'start_time': 144389, 'end_time': 144489, 'speaker': 1}, {'word': 'señor.', 'start_time': 144509, 'end_time': 144829, 'speaker': 1}, {'word': 'Entonces', 'start_time': 144849, 'end_time': 145270, 'speaker': 1}, {'word': 'le', 'start_time': 145310, 'end_time': 145370, 'speaker': 1}, {'word': 'compartiré', 'start_time': 145450, 'end_time': 146010, 'speaker': 1}, {'word': 'información', 'start_time': 146150, 'end_time': 146630, 'speaker': 1}, {'word': 'vía', 'start_time': 146690, 'end_time': 146810, 'speaker': 1}, {'word': 'WhatsApp,', 'start_time': 146850, 'end_time': 147390, 'speaker': 1}, {'word': 'si', 'start_time': 147410, 'end_time': 147450, 'speaker': 1}, {'word': 'está', 'start_time': 147510, 'end_time': 147710, 'speaker': 1}, {'word': 'bien.', 'start_time': 147751, 'end_time': 147951, 'speaker': 1}, {'word': 'Y', 'start_time': 150011, 'end_time': 150051, 'speaker': 1}, {'word': 'pues', 'start_time': 150111, 'end_time': 150251, 'speaker': 1}, {'word': 'por', 'start_time': 150291, 'end_time': 150412, 'speaker': 1}, {'word': 'ese', 'start_time': 150432, 'end_time': 150552, 'speaker': 1}, {'word': 'medio', 'start_time': 150612, 'end_time': 150832, 'speaker': 1}, {'word': 'podríamos', 'start_time': 150912, 'end_time': 151312, 'speaker': 1}, {'word': 'continuar', 'start_time': 151392, 'end_time': 151732, 'speaker': 1}, {'word': 'en', 'start_time': 151772, 'end_time': 151852, 'speaker': 1}, {'word': 'contacto.', 'start_time': 151892, 'end_time': 152332, 'speaker': 1}, {'word': 'Bueno.', 'start_time': 152372, 'end_time': 152592, 'speaker': 1}, {'word': 'Listo,', 'start_time': 153673, 'end_time': 153993, 'speaker': 0}, {'word': 'muchísimas', 'start_time': 154013, 'end_time': 154453, 'speaker': 0}, {'word': 'gracias.', 'start_time': 154473, 'end_time': 155173, 'speaker': 0}, {'word': 'Bueno,', 'start_time': 155213, 'end_time': 155413, 'speaker': 1}, {'word': 'señor,', 'start_time': 155474, 'end_time': 155794, 'speaker': 1}, {'word': 'con', 'start_time': 155854, 'end_time': 155994, 'speaker': 1}, {'word': 'gusto.', 'start_time': 156034, 'end_time': 156294, 'speaker': 1}, {'word': 'Que', 'start_time': 156314, 'end_time': 156374, 'speaker': 1}, {'word': 'esté', 'start_time': 156434, 'end_time': 156634, 'speaker': 1}, {'word': 'muy', 'start_time': 156674, 'end_time': 156774, 'speaker': 1}, {'word': 'bien.', 'start_time': 156814, 'end_time': 156934, 'speaker': 1}, {'word': 'Hasta', 'start_time': 156974, 'end_time': 157154, 'speaker': 1}, {'word': 'luego.', 'start_time': 157194, 'end_time': 157434, 'speaker': 1}, {'word': 'Hasta', 'start_time': 157474, 'end_time': 157814, 'speaker': 1}, {'word': 'luego,', 'start_time': 158215, 'end_time': 158755, 'speaker': 0}, {'word': 'mamá.', 'start_time': 158795, 'end_time': 158995, 'speaker': 0}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ESTRUCTURA HABLANTES"
      ],
      "metadata": {
        "id": "IqJa-dDlYeL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "if language in punct_model_langs:\n",
        "    # restoring punctuation in the transcript to help realign the sentences\n",
        "    punct_model = PunctuationModel(model=\"kredor/punctuate-all\")\n",
        "\n",
        "    words_list = list(map(lambda x: x[\"word\"], wsm))\n",
        "\n",
        "    labled_words = punct_model.predict(words_list)\n",
        "\n",
        "    ending_puncts = \".?!\"\n",
        "    model_puncts = \".,;:!?\"\n",
        "\n",
        "    # We don't want to punctuate U.S.A. with a period. Right?\n",
        "    is_acronym = lambda x: re.fullmatch(r\"\\b(?:[a-zA-Z]\\.){2,}\", x)\n",
        "\n",
        "    for word_dict, labeled_tuple in zip(wsm, labled_words):\n",
        "        word = word_dict[\"word\"]\n",
        "        if (\n",
        "            word\n",
        "            and labeled_tuple[1] in ending_puncts\n",
        "            and (word[-1] not in model_puncts or is_acronym(word))\n",
        "        ):\n",
        "            word += labeled_tuple[1]\n",
        "            if word.endswith(\"..\"):\n",
        "                word = word.rstrip(\".\")\n",
        "            word_dict[\"word\"] = word\n",
        "\n",
        "else:\n",
        "    logging.warning(\n",
        "        f\"Punctuation restoration is not available for {language} language. Using the original punctuation.\"\n",
        "    )\n",
        "\n",
        "wsm = get_realigned_ws_mapping_with_punctuation(wsm)\n",
        "ssm = get_sentences_speaker_mapping(wsm, speaker_ts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "b3d98d94ee72407ebe570dbbd495b9ae",
            "1390a2b0f956434498d57f98790fa399",
            "7ecac59d0b934713a772712d0c3b5129",
            "6880ef28c23840be85315ed0c1a47cbf",
            "79132f46cf394bfe8d3e144c6a63fa9a",
            "5ccc3f18ad134783a8978263cc692d3d",
            "eccc61f20e204cc2810fef5102a1a077",
            "704dbfe9a5d941c0b4597c85a08d2d62",
            "a4cafeaf3b094a4ca7ada27cb9c98327",
            "e26ed8701857483a9e1992960c305db0",
            "c116d0f4cc68493486ccd380da608675",
            "7180bd96e91a4281b366c15291a371cb",
            "1a88b1f3ea5147d390d1031a890a54dc",
            "51a264e931d44c5db1d57b6351c5fd67",
            "4c2abf39e41c4bd5a9430fb85b29f46d",
            "f44fe46c258146349022f098057d31b2",
            "3a69cd19bed34612af2fd1d1581db520",
            "0905e35a537a44819bcbaef1131e2610",
            "a1b52ef0dd1e4538b3239b4af5f68a08",
            "578e15741dbd4637b751fd1bb80abfe3",
            "9616bc2c570f446cb7248e2e1869da8c",
            "c35924d6fbd74b778a042aa182fbb6c6",
            "379d6729a2de4a329f6dde411a986620",
            "3fe3a5a1e0f340eb9a0e11bf4b1dbac5",
            "809547a8d51649ea89825a1d9df09a4a",
            "b26a5ff87a2d4cc794060ccdfac9bf90",
            "71f57869685c485ca740c47920e318b6",
            "40d5c45643204d08805fe89ae7f2894d",
            "d624ba17fd5c4e59bed0e45e92416d8b",
            "6af5795fe68644c0b5f62994faef8655",
            "dd4b5b9282a54dff9e68b20cbefa3a95",
            "2696610f048048e5a560762874e64b43",
            "2081e91e173744278f397ae337e2ed28",
            "db204e6359b44ee78642239ba937907c",
            "027416c57ea4407ab9333f8097677d83",
            "42a10a6a84574a13b2aef562ddb59e3a",
            "06fdaa2461ca4ccc8b3d77eb15c34d34",
            "497e8eda188642f999c933ce8088aca1",
            "d2e9041aba554c0098ca149cdcaef9fe",
            "9b1916de0cbd4efebb93c6c877da88e3",
            "3b813ed98a5d49f5995345ded187b313",
            "23a0caa93574420f80d2bf09be09c5a5",
            "215ed2c72e3445a2a09092edd35fd4ea",
            "e72cf8b1d50b44eaacbd61cd8b6d2d8e",
            "31134006548540cc8c3aaf6b40d73234",
            "fb5630b1369547e2b6e4baa967002010",
            "2642168b4cba44e89c75a5acb06a25ad",
            "6d3d27c6ea7a4f0b85d659852c2d7d79",
            "4ad6c223e75449ddaf08ba62c6c940a8",
            "b6fb36156bfc4df990e4d410eccc748b",
            "7deca142ac6e4a10995b3631fd2779b0",
            "064f239408a3481b95a5a6c5cd43dd50",
            "506f335658734e949746b8e62206e426",
            "5a99d6c9b45b4cf69d553c6b11cbba75",
            "80a48693c1aa438c90fb7af83111d284"
          ]
        },
        "id": "QQ92T5pAYi4a",
        "outputId": "451e50e4-de65-45ee-9c55-499a38fd1d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/914 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3d98d94ee72407ebe570dbbd495b9ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7180bd96e91a4281b366c15291a371cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/447 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "379d6729a2de4a329f6dde411a986620"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db204e6359b44ee78642239ba937907c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31134006548540cc8c3aaf6b40d73234"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.44 s, sys: 3.8 s, total: 9.25 s\n",
            "Wall time: 32.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ssm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4OQjxelY16j",
        "outputId": "fc9eed2a-394e-43d0-cde4-7071dcd5491c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'speaker': 'Speaker 0', 'start_time': 0, 'end_time': 803, 'text': 'Aló. '}, {'speaker': 'Speaker 1', 'start_time': 823, 'end_time': 5326, 'text': 'Buenos días, me comunico con Rafael Dávalo. '}, {'speaker': 'Speaker 0', 'start_time': 6486, 'end_time': 6906, 'text': '¿Y con él? '}, {'speaker': 'Speaker 1', 'start_time': 7827, 'end_time': 10508, 'text': 'Le habla Angie Valente, de la Universidad Javeriana de Cali. '}, {'speaker': 'Speaker 1', 'start_time': 10548, 'end_time': 11369, 'text': '¿Cómo se encuentra? '}, {'speaker': 'Speaker 0', 'start_time': 12410, 'end_time': 13670, 'text': 'Muy bien, gracias a Dios, usted. '}, {'speaker': 'Speaker 1', 'start_time': 14911, 'end_time': 16052, 'text': 'Muy bien, gracias a Dios. '}, {'speaker': 'Speaker 1', 'start_time': 16932, 'end_time': 23336, 'text': 'Nos estamos comunicando, señor Rafael, por su interés en el seminario en Business Analysis con Power BI. '}, {'speaker': 'Speaker 0', 'start_time': 24796, 'end_time': 25657, 'text': 'Ajá, sí, señora. '}, {'speaker': 'Speaker 1', 'start_time': 27318, 'end_time': 29479, 'text': 'Bueno, usted se encuentra en la ciudad de Cali. '}, {'speaker': 'Speaker 0', 'start_time': 30503, 'end_time': 30723, 'text': 'Sí, señora. '}, {'speaker': 'Speaker 1', 'start_time': 30803, 'end_time': 36564, 'text': 'Este seminario se dictará de manera presencial en el campus universitario. '}, {'speaker': 'Speaker 1', 'start_time': 37164, 'end_time': 43606, 'text': 'Iniciaría el veintidós de junio y finalizaría el treinta y uno de julio. '}, {'speaker': 'Speaker 0', 'start_time': 44606, 'end_time': 45286, 'text': '¿Qué tenés a la pregunta? '}, {'speaker': 'Speaker 0', 'start_time': 45306, 'end_time': 46386, 'text': '¿Este es el curso de Python? '}, {'speaker': 'Speaker 1', 'start_time': 48667, 'end_time': 49147, 'text': 'No, señor. '}, {'speaker': 'Speaker 1', 'start_time': 49867, 'end_time': 52988, 'text': 'Seminario en Business y análisis de Big Data con Power BI. '}, {'speaker': 'Speaker 0', 'start_time': 54208, 'end_time': 54748, 'text': 'Ah, ok, ok. '}, {'speaker': 'Speaker 0', 'start_time': 54928, 'end_time': 56128, 'text': 'Sí, sí, ya recordé. '}, {'speaker': 'Speaker 0', 'start_time': 56729, 'end_time': 58589, 'text': 'Este seminario es gratuito, ¿cierto? '}, {'speaker': 'Speaker 1', 'start_time': 60674, 'end_time': 70379, 'text': 'Se estaba, digamos que se estaba ofertando de esa manera, pero pues con un convenio que tenía el ICT con el Ministerio de las TIC, pero esa convocatoria ya finalizó. '}, {'speaker': 'Speaker 1', 'start_time': 70399, 'end_time': 74981, 'text': 'Ahorita se está pues manejando ya directamente con la universidad y sí tienen valor. '}, {'speaker': 'Speaker 0', 'start_time': 76662, 'end_time': 77943, 'text': 'Ok, ¿y qué va el ICT? '}, {'speaker': 'Speaker 1', 'start_time': 78783, 'end_time': 81145, 'text': 'Se encuentra en ochocientos cinco mil pesos. '}, {'speaker': 'Speaker 0', 'start_time': 81165, 'end_time': 85807, 'text': 'Ok, pero yo no he pagado todavía matrícula ni nada, ¿no? '}, {'speaker': 'Speaker 1', 'start_time': 86485, 'end_time': 87326, 'text': 'No, no, señor. '}, {'speaker': 'Speaker 1', 'start_time': 87466, 'end_time': 90188, 'text': 'Precisamente pues me comunico es para brindarle información. '}, {'speaker': 'Speaker 1', 'start_time': 90208, 'end_time': 92709, 'text': 'Usted dejó los datos para que le brindaran información. '}, {'speaker': 'Speaker 0', 'start_time': 93850, 'end_time': 95011, 'text': 'Sí, sí, entiendo. '}, {'speaker': 'Speaker 0', 'start_time': 95651, 'end_time': 99894, 'text': 'Sí, sino que como me decías que ya empezaba a tal fecha, yo quería decir ya estaba como inscrito o algo así. '}, {'speaker': 'Speaker 0', 'start_time': 99995, 'end_time': 100775, 'text': 'Por eso preguntaba. '}, {'speaker': 'Speaker 1', 'start_time': 101516, 'end_time': 102276, 'text': 'No, no, señor. '}, {'speaker': 'Speaker 1', 'start_time': 102336, 'end_time': 104137, 'text': 'Este iniciaría el veintidós de junio. '}, {'speaker': 'Speaker 1', 'start_time': 104378, 'end_time': 105378, 'text': 'Ok. '}, {'speaker': 'Speaker 0', 'start_time': 108681, 'end_time': 108821, 'text': 'Ajá. '}, {'speaker': 'Speaker 1', 'start_time': 111289, 'end_time': 116392, 'text': 'Las clases presenciales serían los días lunes y jueves de seis y media, nueve y media de la noche. '}, {'speaker': 'Speaker 1', 'start_time': 116872, 'end_time': 119093, 'text': '¿Tendría de pronto algún inconveniente con ese horario? '}, {'speaker': 'Speaker 0', 'start_time': 119614, 'end_time': 119974, 'text': 'Sí, no, eso sí. '}, {'speaker': 'Speaker 0', 'start_time': 119994, 'end_time': 120494, 'text': 'Por el trabajo. '}, {'speaker': 'Speaker 0', 'start_time': 120514, 'end_time': 128518, 'text': 'La verdad yo creí que era iba a ser virtual. '}, {'speaker': 'Speaker 1', 'start_time': 128578, 'end_time': 132260, 'text': 'Es online, bueno, se maneja un online, pero ya sería para el mes de julio. '}, {'speaker': 'Speaker 0', 'start_time': 133841, 'end_time': 134902, 'text': 'El mes de julio, ok. '}, {'speaker': 'Speaker 0', 'start_time': 136686, 'end_time': 142849, 'text': 'Pues por ahora sí, recibiré la información y creo que estaré pendiente para confirmarlo. '}, {'speaker': 'Speaker 1', 'start_time': 143989, 'end_time': 144829, 'text': 'Bueno, sí, señor. '}, {'speaker': 'Speaker 1', 'start_time': 144849, 'end_time': 147951, 'text': 'Entonces le compartiré información vía WhatsApp, si está bien. '}, {'speaker': 'Speaker 1', 'start_time': 150011, 'end_time': 152332, 'text': 'Y pues por ese medio podríamos continuar en contacto. '}, {'speaker': 'Speaker 1', 'start_time': 152372, 'end_time': 152592, 'text': 'Bueno. '}, {'speaker': 'Speaker 0', 'start_time': 153673, 'end_time': 155173, 'text': 'Listo, muchísimas gracias. '}, {'speaker': 'Speaker 1', 'start_time': 155213, 'end_time': 156294, 'text': 'Bueno, señor, con gusto. '}, {'speaker': 'Speaker 1', 'start_time': 156314, 'end_time': 156934, 'text': 'Que esté muy bien. '}, {'speaker': 'Speaker 1', 'start_time': 156974, 'end_time': 157434, 'text': 'Hasta luego. '}, {'speaker': 'Speaker 0', 'start_time': 157474, 'end_time': 158995, 'text': 'Hasta luego, mamá. '}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXPORTACION DE RESULTADOS"
      ],
      "metadata": {
        "id": "fxixnoPmY9JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "path_textfile_with_speakers = f\"{os.path.splitext(audio_path)[0]}.txt\"\n",
        "path_srtfile_with_speakers = f\"{os.path.splitext(audio_path)[0]}.srt\"\n",
        "\n",
        "with open(path_textfile_with_speakers, \"w\", encoding=\"utf-8-sig\") as f:\n",
        "    get_speaker_aware_transcript(ssm, f)\n",
        "\n",
        "with open(path_srtfile_with_speakers, \"w\", encoding=\"utf-8-sig\") as srt:\n",
        "    write_srt(ssm, srt)\n",
        "\n",
        "cleanup(temp_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ViKbdrQY_Ym",
        "outputId": "ac82a203-072b-475b-9ec1-28ecbda3195e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.91 ms, sys: 1.03 ms, total: 4.94 ms\n",
            "Wall time: 10.8 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_text(audio_path):\n",
        "    # rename audio filename if necessary to get string without accent, space, in lower case\n",
        "    audio_path = rename_file(audio_path)\n",
        "    # vocal_target = isolate_string(audio_path)\n",
        "    # whisper_results, language = transcribe(vocal_target)\n",
        "    return audio_path"
      ],
      "metadata": {
        "id": "RAz2cxSlQTix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DESARROLLO FOLDER"
      ],
      "metadata": {
        "id": "labzy1knZ7kX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ESTANDARIZACION DE FILEPATH"
      ],
      "metadata": {
        "id": "Z3s4MEdLcjlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listar todos los archivos en una carpeta específica, por ejemplo, '/content'\n",
        "files = os.listdir('/content')\n",
        "# print(files)\n",
        "\n",
        "wav_files = [file for file in files if file.endswith('.wav')]\n",
        "# print(wav_files)\n",
        "\n",
        "for filepath in wav_files:\n",
        "  suffix = Path(filepath).suffix\n",
        "\n",
        "  if str(Path(filepath).parent) != \".\":\n",
        "      new_filepath = str(Path(filepath).parent) + cleanString(filepath.replace(suffix, \"\")) + suffix\n",
        "  else:\n",
        "      new_filepath = cleanString(filepath.replace(suffix, \"\")) + suffix\n",
        "  os.rename(filepath, new_filepath)\n"
      ],
      "metadata": {
        "id": "jKz-BgeGamA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir('/content')\n",
        "wav_files = [fl for fl in files if Path(fl).suffix == \".wav\"]\n",
        "print(wav_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlXU7rjkbiMG",
        "outputId": "76b00e23-c055-43f4-902e-96c049f648c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['b3067024c98b48888d1b93992535ae9a_20230610t14_15_utc.wav', '18b2b93c2953487c97c8b73ce36135fb_20230610t15_48_utc.wav', '033864c87c5f4a4fab44a201563fd968_20230610t15_05_utc.wav', '3030567b3ee042bb8a838d1c76b6b916_20230610t14_01_utc.wav', '7561a59a1cc24d3f9dcb726bda6b777e_20230610t14_18_utc.wav', '2423c4d401d1424ab3843e5ddda79e7a_20230610t16_50_utc.wav', '975df3115269486098f522a3eb856dfd_20230610t15_05_utc.wav', '34958b78223b449782e44c3afd0d0fd7_20230610t14_27_utc.wav', 'd32ed68f007043a4a4eb582c82015c33_20230610t14_59_utc.wav', '3fde7eca0a2f4b188a3fd81fce9a9d09_20230610t14_48_utc.wav', 'ca04630280544cbf8b9bee6854a2f681_20230610t14_13_utc.wav', '5fab44f212e3402d99638a5dc9d97701_20230610t14_26_utc.wav', 'e091c45596054f6ea5fac6b7388e115c_20230610t15_13_utc.wav', 'd9553adbba9c45bead6e1a2bded61ad8_20230610t16_33_utc.wav', '934de5177dd94afd8f8a198b2226c2e5_20230610t15_00_utc.wav', '45adf080f3e24793900699ada4592d63_20230610t15_47_utc.wav', 'eda880c7ca6f4e40835aa372d01627c0_20230610t14_59_utc.wav', 'c7e11bdfad064aae944c4ce1a11dc2d7_20230610t14_02_utc.wav', '6eb352d2758049f09c9619ac9df008e5_20230610t14_29_utc.wav', '6eb42d94dfb3406faf290fe85feffbfe_20230610t16_55_utc.wav', 'd15a221c5dce4a34ac2d8bda6ed71ebd_20230610t13_57_utc.wav', 'd554a73b18c84f35866c98565d703d21_20230610t16_41_utc.wav', '463aea85483f442fa152796bbe6412f0_20230610t13_52_utc.wav', 'ed011e99f19e4257b0cc08f003decd8c_20230610t16_21_utc.wav', '29a70da7b6b4483d85fd483e814378b1_20230610t14_41_utc.wav', '7f77a99fac1b4dabbcce2f408995b9bf_20230610t13_04_utc.wav', '3790e2a16369420295cd1456849101ac_20230610t16_51_utc.wav', '2ee89ca6b151452d80fafc0031248b5c_20230610t15_18_utc.wav', 'f189dbfe6981414087b0500db982a3e7_20230610t13_45_utc.wav', 'f1e80f376a024fac8912df9b9df04df0_20230610t13_44_utc.wav', '5d6b0bcd9801457bb62733de21e565f2_20230610t15_44_utc.wav', '9adc604104c341d9adc92db9665fb992_20230610t15_10_utc.wav', 'ad0946be1ed543acbf3ca01df5fc6b25_20230610t14_38_utc.wav', 'de226de0f8c94183b0fc1b26c2a7a637_20230610t16_49_utc.wav', '42df394a0d744909b694f4139d4b8c09_20230610t15_37_utc.wav', '8273dce465a54e99a47d92da2d1af7ad_20230610t14_54_utc.wav', 'a7b3a1c2f26c464d97dbec49d46b75f1_20230610t14_25_utc.wav', '26746b7e69e140b3b3a11b973330ce96_20230610t14_35_utc.wav', '269d7a90316042169c14e767e8b4ec18_20230610t15_41_utc.wav', '640807edf3f74283a7295a888a93aaf7_20230610t16_54_utc.wav', '52217898a6d84b0f9022c9d33b2f273f_20230610t13_28_utc.wav', 'f189e55691f04a0cbca711f6ee0bac4a_20230610t13_18_utc.wav', 'f399f79640f94bfebba1323714013e12_20230610t16_49_utc.wav', '1f948c343dac4d099d6cbb9a648403ff_20230610t16_57_utc.wav', '18eff36f759c4d73965c2a229beecfee_20230610t16_24_utc.wav', '0c027942655e4f1183614bb47a282aea_20230610t13_32_utc.wav', '822671d3fd8d4b468ca3fe67162b0e18_20230610t15_03_utc.wav', '18710ae2ed9842aabdb637eae2a858c1_20230610t16_04_utc.wav', 'e0913f30a77847f89585f9219bb14dd5_20230610t16_29_utc.wav', 'd8363b1bbb1f46579cb66073a1423ad3_20230610t15_06_utc.wav', 'a8de54e7217b43bf9222236fe3a35143_20230610t15_59_utc.wav', 'bab93478e7374a7da7ca383c9090a498_20230610t16_15_utc.wav', '3e389aa8839748e78e57f6eb8ce0812a_20230610t13_55_utc.wav', 'f332b3326cb34bddb0989e865a5831e4_20230610t14_13_utc.wav', 'e56abe4fb3ae4c0cbc1b1cdfc8d80cb3_20230610t15_15_utc.wav', 'bdc1679b294f4d60844c566fef78c4c8_20230610t16_16_utc.wav', '2bf1748f6df24d4494ad8a137f33ed77_20230610t15_22_utc.wav', '60e1b8f07eb844c8b7014251b86ecea1_20230610t13_35_utc.wav', '2debb7328d994ecdb89a0a7afd03cb2e_20230610t16_57_utc.wav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(wav_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e89EYpOrnr9",
        "outputId": "0f117551-45c6-4cae-e4f3-9733fed6bdf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "59"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Limpieza de storage\n",
        "files = os.listdir('/content')\n",
        "not_txt = [fl for fl in files if Path(fl).suffix != \".txt\"]\n",
        "elm = [fl for fl in files if Path(fl).suffix in (\".txt\", \".wav\")]\n",
        "# len(elm)\n",
        "for nt in elm:\n",
        "  mono_file_path = os.path.join('/content', nt)\n",
        "  # print(mono_file_path)\n",
        "  cleanup(mono_file_path)"
      ],
      "metadata": {
        "id": "Qsen1dPxl7Fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PROCESO TRANSCRIPCION"
      ],
      "metadata": {
        "id": "-eqb5y4zHTD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wav_files = ['0c1dacc20d21474f9f300b2bc3069d1a_20230401t16_11_utc.wav']\n",
        "\n",
        "# vocal_target = audio_path\n",
        "language = None\n",
        "batch_size = 8\n",
        "whisper_model_name = \"large-v3\"\n",
        "compute_type = \"float16\"\n",
        "suppress_numerals = True\n",
        "device = \"cuda\"\n",
        "\n",
        "for vocal_target in wav_files:\n",
        "\n",
        "  whisper_results, language = transcribe_batched(\n",
        "      vocal_target,\n",
        "      language,\n",
        "      batch_size,\n",
        "      whisper_model_name,\n",
        "      compute_type,\n",
        "      suppress_numerals,\n",
        "      device,\n",
        "  )\n",
        "\n",
        "######################################\n",
        "#########      WAV2VEC2      #########\n",
        "######################################\n",
        "\n",
        "  alignment_model, metadata = whisperx.load_align_model(\n",
        "      language_code=language, device=device\n",
        "  )\n",
        "  result_aligned = whisperx.align(\n",
        "      whisper_results, alignment_model, metadata, vocal_target, device\n",
        "  )\n",
        "  word_timestamps = filter_missing_timestamps(result_aligned[\"word_segments\"])\n",
        "\n",
        "  # clear gpu vram\n",
        "  del alignment_model\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "######################################\n",
        "######  CONVERSION A MONO   ##########\n",
        "######################################\n",
        "\n",
        "  sound = AudioSegment.from_file(vocal_target).set_channels(1)\n",
        "  ROOT = os.getcwd()\n",
        "  temp_path = os.path.join(ROOT, \"temp_outputs\")\n",
        "  os.makedirs(temp_path, exist_ok=True)\n",
        "  sound.export(os.path.join(temp_path, \"mono_file.wav\"), format=\"wav\")\n",
        "\n",
        "#######################################\n",
        "########  DIARIZACION AUDIO   #########\n",
        "#######################################\n",
        "\n",
        "  msdd_model = NeuralDiarizer(cfg=create_config(temp_path, DOMAIN_TYPE=\"telephonic\")).to(\"cuda\")\n",
        "  msdd_model.diarize()\n",
        "\n",
        "  del msdd_model\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "#######################################\n",
        "####  MAPEO HABLANTES POR TIEMPO   ####\n",
        "#######################################\n",
        "\n",
        "\n",
        "  speaker_ts = []\n",
        "  with open(os.path.join(temp_path, \"pred_rttms\", \"mono_file.rttm\"), \"r\") as f:\n",
        "      lines = f.readlines()\n",
        "      for line in lines:\n",
        "          line_list = line.split(\" \")\n",
        "          s = int(float(line_list[5]) * 1000)\n",
        "          e = s + int(float(line_list[8]) * 1000)\n",
        "          speaker_ts.append([s, e, int(line_list[11].split(\"_\")[-1])])\n",
        "\n",
        "  wsm = get_words_speaker_mapping(word_timestamps, speaker_ts, \"start\")\n",
        "\n",
        "#######################################\n",
        "#######  ESTRUCTURA HABLANTES   #######\n",
        "#######################################\n",
        "\n",
        "  punct_model = PunctuationModel(model=\"kredor/punctuate-all\")\n",
        "\n",
        "  words_list = list(map(lambda x: x[\"word\"], wsm))\n",
        "\n",
        "  labled_words = punct_model.predict(words_list)\n",
        "\n",
        "  ending_puncts = \".?!\"\n",
        "  model_puncts = \".,;:!?\"\n",
        "\n",
        "  # We don't want to punctuate U.S.A. with a period. Right?\n",
        "  is_acronym = lambda x: re.fullmatch(r\"\\b(?:[a-zA-Z]\\.){2,}\", x)\n",
        "\n",
        "  for word_dict, labeled_tuple in zip(wsm, labled_words):\n",
        "      word = word_dict[\"word\"]\n",
        "      if (\n",
        "          word\n",
        "          and labeled_tuple[1] in ending_puncts\n",
        "          and (word[-1] not in model_puncts or is_acronym(word))\n",
        "      ):\n",
        "          word += labeled_tuple[1]\n",
        "          if word.endswith(\"..\"):\n",
        "              word = word.rstrip(\".\")\n",
        "          word_dict[\"word\"] = word\n",
        "\n",
        "  wsm = get_realigned_ws_mapping_with_punctuation(wsm)\n",
        "  ssm = get_sentences_speaker_mapping(wsm, speaker_ts)\n",
        "\n",
        "\n",
        "#######################################\n",
        "######  EXPORTACION RESULTADOS   ######\n",
        "#######################################\n",
        "\n",
        "  path_textfile_with_speakers = f\"/content/drive/MyDrive/audios/2023-06-10a/{os.path.splitext(vocal_target)[0]}.txt\"  #JSON #Pandas(Speaker 1 - Speaker 2))\n",
        "  # path_srtfile_with_speakers = f\"/content/drive/MyDrive/audios/{os.path.splitext(vocal_target)[0]}.srt\"\n",
        "\n",
        "  with open(path_textfile_with_speakers, \"w\", encoding=\"utf-8-sig\") as f:\n",
        "      get_speaker_aware_transcript(ssm, f)\n",
        "\n",
        "  # with open(path_srtfile_with_speakers, \"w\", encoding=\"utf-8-sig\") as srt:\n",
        "  #     write_srt(ssm, srt)\n",
        "\n",
        "  mono_file_path = os.path.join(temp_path, \"mono_file.wav\")\n",
        "  cleanup(mono_file_path)\n",
        "\n",
        "  print(f'archivo {vocal_target} listo')\n",
        "# print(whisper_results)\n",
        "# print(word_timestamps)\n",
        "# print(wsm)\n",
        "# print(ssm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRJnc2U-aBfZ",
        "outputId": "db87993a-52e2-44d0-a746-da3ec112628b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Detected language: es (0.98) in first 30s of audio...\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:36:10 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:36:10 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:36:10 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:36:10 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:36:11 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:36:11 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:36:11 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:11 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:36:12 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:36:12 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:36:13 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:36:14 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:36:14 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:36:14 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:36:14 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:36:14 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:36:14 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:36:14 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:14 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:36:14 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:36:14 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:36:14 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:36:14 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:14 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:36:14 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 30.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:14 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:36:14 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:36:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:36:14 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n",
            "[NeMo I 2024-08-26 03:36:14 collections:304] # 4 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 4/4 [00:00<00:00,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:15 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:16 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:16 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:36:17 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:36:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:36:17 collections:302] Dataset loaded with 201 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 03:36:17 collections:304] # 201 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  7.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:17 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:36:17 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:36:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:36:17 collections:302] Dataset loaded with 244 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 03:36:17 collections:304] # 244 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  7.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:18 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:36:18 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:36:18 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:36:18 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:36:18 collections:302] Dataset loaded with 306 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 03:36:18 collections:304] # 306 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:18 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:36:18 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:36:18 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:36:18 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:36:18 collections:302] Dataset loaded with 418 items, total duration of  0.09 hours.\n",
            "[NeMo I 2024-08-26 03:36:18 collections:304] # 418 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 7/7 [00:00<00:00, 10.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:19 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:36:19 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:36:19 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:19 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:36:19 collections:302] Dataset loaded with 630 items, total duration of  0.09 hours.\n",
            "[NeMo I 2024-08-26 03:36:19 collections:304] # 630 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 10/10 [00:00<00:00, 10.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:20 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:20 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:36:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:20 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:36:20 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:36:20 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:36:20 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:36:20 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:36:20 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:36:21 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:36:21 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 35.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:21 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:36:21 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:36:21 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:36:21 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:21 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:36:21 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:21 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:36:21 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:36:21 msdd_models:1431]   \n",
            "    \n",
            "archivo b3067024c98b48888d1b93992535ae9a_20230610t14_15_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:37:01 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:37:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:37:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:37:02 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:37:03 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:37:03 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:37:03 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:03 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:37:04 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:37:05 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:37:05 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:37:06 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:37:06 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:37:06 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:37:06 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:37:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:37:06 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:37:06 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:06 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:37:06 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:37:06 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:37:06 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:37:06 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:06 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:37:06 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 58.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:06 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:37:06 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:37:06 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:37:06 collections:302] Dataset loaded with 2 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:37:06 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:07 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:07 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 21.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:37:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:37:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:37:07 collections:302] Dataset loaded with 42 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:37:07 collections:304] # 42 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:37:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:37:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:37:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:37:07 collections:302] Dataset loaded with 51 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:37:07 collections:304] # 51 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:37:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:37:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:37:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:37:07 collections:302] Dataset loaded with 63 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:37:07 collections:304] # 63 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:08 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:37:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:37:08 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:37:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:37:08 collections:302] Dataset loaded with 88 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:37:08 collections:304] # 88 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00, 12.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:08 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:37:08 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:37:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:37:08 collections:302] Dataset loaded with 134 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:37:08 collections:304] # 134 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00, 12.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:08 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:08 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:37:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:08 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:37:08 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:37:08 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:37:08 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:37:08 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:37:08 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:37:08 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:37:08 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 53.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:08 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:37:08 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:37:08 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:37:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:08 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:37:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:08 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:37:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:37:08 msdd_models:1431]   \n",
            "    \n",
            "archivo 18b2b93c2953487c97c8b73ce36135fb_20230610t15_48_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:38:10 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:38:10 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:38:10 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:38:10 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:38:11 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:38:11 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:38:11 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:11 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:38:11 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:38:12 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:38:12 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:38:13 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:38:13 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:38:13 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:38:13 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:38:13 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:38:13 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:38:13 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:13 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:38:13 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:38:13 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:38:13 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:38:13 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:13 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:38:13 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:13 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:38:13 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:38:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:38:13 collections:302] Dataset loaded with 9 items, total duration of  0.12 hours.\n",
            "[NeMo I 2024-08-26 03:38:13 collections:304] # 9 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 9/9 [00:02<00:00,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:16 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:20 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:21 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:38:21 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:38:21 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:38:21 collections:302] Dataset loaded with 378 items, total duration of  0.14 hours.\n",
            "[NeMo I 2024-08-26 03:38:21 collections:304] # 378 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  6.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:22 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:38:22 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:38:22 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:38:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:38:22 collections:302] Dataset loaded with 462 items, total duration of  0.15 hours.\n",
            "[NeMo I 2024-08-26 03:38:22 collections:304] # 462 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 8/8 [00:00<00:00,  8.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:23 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:38:23 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:38:23 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:38:23 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:38:23 collections:302] Dataset loaded with 573 items, total duration of  0.15 hours.\n",
            "[NeMo I 2024-08-26 03:38:23 collections:304] # 573 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:24 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:38:24 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:38:24 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:38:24 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:38:24 collections:302] Dataset loaded with 780 items, total duration of  0.16 hours.\n",
            "[NeMo I 2024-08-26 03:38:24 collections:304] # 780 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 13/13 [00:01<00:00, 10.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:25 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:38:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:25 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:38:25 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:38:25 collections:302] Dataset loaded with 1192 items, total duration of  0.16 hours.\n",
            "[NeMo I 2024-08-26 03:38:25 collections:304] # 1192 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 19/19 [00:01<00:00, 11.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:27 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:27 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:38:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:28 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:38:28 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:38:28 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:38:28 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:38:28 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:38:28 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:38:28 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:38:28 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:28 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:38:28 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:38:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:38:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:38:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:38:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:38:28 msdd_models:1431]   \n",
            "    \n",
            "archivo 033864c87c5f4a4fab44a201563fd968_20230610t15_05_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:39:12 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:39:12 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:39:12 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:39:12 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:39:13 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:39:13 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:39:13 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:13 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:39:13 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:39:14 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:39:14 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:39:15 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:39:15 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:39:15 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:39:15 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:39:15 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:39:15 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:39:15 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:15 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:39:15 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:39:15 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:39:15 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:39:15 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:15 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:39:15 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 46.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:15 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:39:15 classification_models:273] Perform streaming frame-level VAD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:15 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:39:15 collections:302] Dataset loaded with 2 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:39:15 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 2/2 [00:00<00:00,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:15 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:16 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 14.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:16 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:39:16 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:39:16 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:39:16 collections:302] Dataset loaded with 90 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:39:16 collections:304] # 90 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:17 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:39:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:39:17 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:39:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:39:17 collections:302] Dataset loaded with 114 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:39:17 collections:304] # 114 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:17 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:39:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:39:17 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:39:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:39:17 collections:302] Dataset loaded with 142 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:39:17 collections:304] # 142 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  9.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:17 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:39:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:39:17 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:39:17 collections:302] Dataset loaded with 190 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:39:17 collections:304] # 190 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  9.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:18 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:39:18 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:39:18 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:39:18 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:39:18 collections:302] Dataset loaded with 296 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:39:18 collections:304] # 296 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00, 11.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:18 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:18 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:39:18 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:18 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:39:18 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:39:18 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:39:18 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:39:18 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:39:18 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:39:18 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:39:18 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 49.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:18 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:39:18 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:39:18 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:39:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:19 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:39:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:19 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:39:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:39:19 msdd_models:1431]   \n",
            "    \n",
            "archivo 3030567b3ee042bb8a838d1c76b6b916_20230610t14_01_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:39:59 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:39:59 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:39:59 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:39:59 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:40:00 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:40:00 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:40:00 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:00 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:40:01 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:40:01 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:40:01 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:40:02 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:40:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:40:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:40:02 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:40:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:40:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:40:02 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:02 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:40:02 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:40:02 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:40:02 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:40:02 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:02 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:40:02 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 38.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:02 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:02 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:40:02 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:02 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:40:02 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 2/2 [00:00<00:00,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:03 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:04 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:40:04 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:40:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:04 collections:302] Dataset loaded with 35 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:40:04 collections:304] # 35 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:04 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:40:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:40:04 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:04 collections:302] Dataset loaded with 40 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:40:04 collections:304] # 40 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:04 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:40:04 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:40:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:04 collections:302] Dataset loaded with 51 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:40:04 collections:304] # 51 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:05 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:40:05 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:05 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:40:05 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:05 collections:302] Dataset loaded with 70 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:40:05 collections:304] # 70 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:05 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:05 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:40:05 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:40:05 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:05 collections:302] Dataset loaded with 102 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:40:05 collections:304] # 102 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:05 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:06 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:40:06 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:06 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:40:06 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:40:06 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:40:06 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:40:06 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:40:06 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:40:06 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:40:06 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:06 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:40:06 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:40:06 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:40:06 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:06 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:40:06 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:06 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:40:06 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:06 msdd_models:1431]   \n",
            "    \n",
            "archivo 7561a59a1cc24d3f9dcb726bda6b777e_20230610t14_18_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:40:47 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:40:47 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:40:47 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:40:47 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:40:49 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:40:49 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:40:49 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:49 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:40:49 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:40:50 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:40:51 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:40:51 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:40:51 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:40:51 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:40:51 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:40:52 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:40:52 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:40:52 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:52 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:40:52 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:40:52 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:40:52 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:40:52 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:52 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:40:52 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 71.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:52 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:40:52 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:40:52 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:52 collections:302] Dataset loaded with 2 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:40:52 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  6.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:52 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 20.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:40:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:53 collections:302] Dataset loaded with 52 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:40:53 collections:304] # 52 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:40:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:53 collections:302] Dataset loaded with 63 items, total duration of  0.02 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:53 collections:304] # 63 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:40:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:53 collections:302] Dataset loaded with 78 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:40:53 collections:304] # 78 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:40:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:53 collections:302] Dataset loaded with 106 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:40:53 collections:304] # 106 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:40:53 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:40:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:40:53 collections:302] Dataset loaded with 162 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:40:53 collections:304] # 162 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00, 11.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:54 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:54 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:40:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:54 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:40:54 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:40:54 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:40:54 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:40:54 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:40:54 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:40:54 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:40:54 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 59.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:54 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:40:54 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:40:54 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:40:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:54 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:40:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:54 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:40:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:40:54 msdd_models:1431]   \n",
            "    \n",
            "archivo 2423c4d401d1424ab3843e5ddda79e7a_20230610t16_50_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:41:38 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:41:38 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:41:38 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:41:38 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:41:39 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:41:39 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:41:39 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:39 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:41:40 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:41:40 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:41:40 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:41:41 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:41:41 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:41:41 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:41:41 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:41:41 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:41:41 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:41:41 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:41 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:41:41 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:41:41 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:41:41 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:41:41 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:41 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:41:41 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 38.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:41 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:41:41 classification_models:273] Perform streaming frame-level VAD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:41:41 collections:302] Dataset loaded with 2 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:41:41 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 2/2 [00:00<00:00,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:42 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:43 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 13.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:41:43 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:41:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:41:43 collections:302] Dataset loaded with 91 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:41:43 collections:304] # 91 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:43 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:41:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:41:43 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:41:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:41:43 collections:302] Dataset loaded with 109 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:41:43 collections:304] # 109 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:43 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:41:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:41:43 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:41:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:41:43 collections:302] Dataset loaded with 140 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:41:43 collections:304] # 140 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00, 10.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:44 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:41:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:41:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:41:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:41:44 collections:302] Dataset loaded with 191 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:41:44 collections:304] # 191 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:44 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:41:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:41:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:41:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:41:44 collections:302] Dataset loaded with 290 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:41:44 collections:304] # 290 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:45 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:45 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:41:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:45 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:41:45 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:41:45 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:41:45 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:41:45 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:41:45 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:41:45 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:41:45 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 26.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:45 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:41:45 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:41:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:41:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:41:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:41:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:41:45 msdd_models:1431]   \n",
            "    \n",
            "archivo 975df3115269486098f522a3eb856dfd_20230610t15_05_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:42:27 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:42:27 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:42:27 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:42:27 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:42:29 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:42:29 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:42:29 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:29 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:42:29 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:42:30 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:42:30 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:42:30 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:42:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:42:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:42:30 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:42:31 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:42:31 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:42:31 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:31 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:42:31 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:42:31 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:42:31 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:42:31 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:31 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:42:31 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 47.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:31 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:42:31 classification_models:273] Perform streaming frame-level VAD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:42:31 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:42:31 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 2/2 [00:00<00:00,  5.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:31 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:32 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:32 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:42:32 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:42:32 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:42:32 collections:302] Dataset loaded with 67 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:42:32 collections:304] # 67 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:32 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:42:32 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:42:32 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:42:32 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:42:32 collections:302] Dataset loaded with 80 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:42:32 collections:304] # 80 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:32 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:42:32 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:42:32 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:42:32 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:42:32 collections:302] Dataset loaded with 101 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:42:32 collections:304] # 101 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:33 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:42:33 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:42:33 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:42:33 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:42:33 collections:302] Dataset loaded with 136 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:42:33 collections:304] # 136 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00, 10.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:33 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:42:33 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:42:33 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:42:33 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:42:33 collections:302] Dataset loaded with 209 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:42:33 collections:304] # 209 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00, 10.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:33 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:34 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:42:34 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:34 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:42:34 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:42:34 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:42:34 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:42:34 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:42:34 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:42:34 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:42:34 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 52.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:34 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:42:34 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:42:34 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:42:34 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:34 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:42:34 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:34 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:42:34 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:42:34 msdd_models:1431]   \n",
            "    \n",
            "archivo 34958b78223b449782e44c3afd0d0fd7_20230610t14_27_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:43:31 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:43:31 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:43:31 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:43:31 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:43:32 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:43:32 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:43:32 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:32 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:43:32 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:43:33 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:43:33 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:43:34 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:43:34 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:43:34 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:43:34 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:43:34 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:43:34 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:43:34 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:34 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:43:34 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:43:34 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:43:34 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:43:34 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:34 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:43:34 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 17.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:34 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:34 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:43:34 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:43:34 collections:302] Dataset loaded with 6 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:43:34 collections:304] # 6 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 6/6 [00:01<00:00,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:35 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:38 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:38 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:43:38 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:43:38 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:43:38 collections:302] Dataset loaded with 264 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 03:43:38 collections:304] # 264 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:39 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:43:39 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:43:39 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:43:39 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:43:39 collections:302] Dataset loaded with 319 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 03:43:39 collections:304] # 319 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:40 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:43:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:43:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:43:40 collections:302] Dataset loaded with 402 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 03:43:40 collections:304] # 402 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 7/7 [00:00<00:00,  7.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:43:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:42 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:43:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:43:42 collections:302] Dataset loaded with 541 items, total duration of  0.11 hours.\n",
            "[NeMo I 2024-08-26 03:43:42 collections:304] # 541 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  7.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:43 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:43:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:43:43 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:43:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:43:43 collections:302] Dataset loaded with 829 items, total duration of  0.11 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:43 collections:304] # 829 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 13/13 [00:01<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:45 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:45 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:43:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:45 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:43:45 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:43:45 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:43:45 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:43:45 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:43:45 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:43:45 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:43:45 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 24.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:45 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:43:45 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:43:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:43:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:46 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:43:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:46 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:43:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:43:46 msdd_models:1431]   \n",
            "    \n",
            "archivo d32ed68f007043a4a4eb582c82015c33_20230610t14_59_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:44:34 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:44:34 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:44:34 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:44:34 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:44:36 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:44:36 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:44:36 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:36 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:44:36 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:44:36 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:44:36 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:44:37 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:44:37 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:44:37 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:44:37 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:44:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:44:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:44:37 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:44:37 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:44:37 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:44:37 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:44:37 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:37 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:44:37 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 23.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:37 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:37 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:44:37 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:44:37 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n",
            "[NeMo I 2024-08-26 03:44:37 collections:304] # 4 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 4/4 [00:01<00:00,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:38 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:41 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:44:41 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:44:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:44:41 collections:302] Dataset loaded with 176 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:44:41 collections:304] # 176 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:44:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:44:42 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:44:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:44:42 collections:302] Dataset loaded with 211 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:44:42 collections:304] # 211 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:44:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:44:42 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:44:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:44:42 collections:302] Dataset loaded with 266 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:44:42 collections:304] # 266 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:43 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:44:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:44:43 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:44:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:44:43 collections:302] Dataset loaded with 358 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:44:43 collections:304] # 358 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  7.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:44 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:44:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:44:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:44:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:44:44 collections:302] Dataset loaded with 547 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:44:44 collections:304] # 547 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 9/9 [00:00<00:00, 10.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:45 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:45 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:44:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:45 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:44:45 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:44:45 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:44:45 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:44:45 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:44:45 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:44:45 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:44:45 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 29.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:45 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:44:45 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:44:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:44:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:44:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:45 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:44:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:44:45 msdd_models:1431]   \n",
            "    \n",
            "archivo 3fde7eca0a2f4b188a3fd81fce9a9d09_20230610t14_48_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:45:41 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:45:41 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:45:41 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:45:41 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:45:43 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:45:43 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:45:43 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:43 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:45:43 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:45:44 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:45:44 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:45:44 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:45:44 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:45:44 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:45:44 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:45:45 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:45:45 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:45:45 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:45 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:45:45 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:45:45 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:45:45 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:45:45 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:45 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:45:45 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 15.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:45 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:45:45 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:45:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:45:45 collections:302] Dataset loaded with 7 items, total duration of  0.09 hours.\n",
            "[NeMo I 2024-08-26 03:45:45 collections:304] # 7 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 7/7 [00:01<00:00,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:46 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:49 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:50 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:45:50 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:45:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:45:50 collections:302] Dataset loaded with 289 items, total duration of  0.11 hours.\n",
            "[NeMo I 2024-08-26 03:45:50 collections:304] # 289 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:50 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:45:50 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:45:50 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:45:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:45:50 collections:302] Dataset loaded with 354 items, total duration of  0.11 hours.\n",
            "[NeMo I 2024-08-26 03:45:50 collections:304] # 354 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:51 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:45:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:45:51 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:45:51 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:45:51 collections:302] Dataset loaded with 443 items, total duration of  0.11 hours.\n",
            "[NeMo I 2024-08-26 03:45:51 collections:304] # 443 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 7/7 [00:00<00:00,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:52 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:45:52 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:45:52 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:45:52 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:45:52 collections:302] Dataset loaded with 596 items, total duration of  0.12 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:52 collections:304] # 596 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 10/10 [00:01<00:00,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:53 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:45:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:45:53 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:45:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:45:54 collections:302] Dataset loaded with 911 items, total duration of  0.12 hours.\n",
            "[NeMo I 2024-08-26 03:45:54 collections:304] # 911 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 15/15 [00:01<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:55 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:56 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:45:56 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:56 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:45:56 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:45:56 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:45:56 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:45:56 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:45:56 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:45:56 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:45:56 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 16.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:57 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:45:57 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:45:57 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:45:57 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:57 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:45:57 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:57 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:45:57 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:45:57 msdd_models:1431]   \n",
            "    \n",
            "archivo ca04630280544cbf8b9bee6854a2f681_20230610t14_13_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:46:36 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:46:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:46:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:46:36 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:46:38 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:46:38 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:46:38 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:38 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:46:38 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:46:39 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:46:39 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:46:40 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:46:40 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:46:40 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:46:40 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:46:40 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:46:40 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:46:40 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:40 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:46:40 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:46:40 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:46:40 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:46:40 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:40 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:46:40 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 48.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:40 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:40 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:46:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:46:40 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:46:40 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 19.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:46:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:46:41 collections:302] Dataset loaded with 24 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:46:41 collections:304] # 24 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 12.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:46:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:46:41 collections:302] Dataset loaded with 31 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:46:41 collections:304] # 31 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 10.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:46:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:46:41 collections:302] Dataset loaded with 38 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:46:41 collections:304] # 38 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:46:41 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:46:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:46:41 collections:302] Dataset loaded with 50 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:46:41 collections:304] # 50 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:46:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:46:42 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:46:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:46:42 collections:302] Dataset loaded with 81 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:46:42 collections:304] # 81 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00, 11.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  9.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:42 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:46:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:42 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:46:42 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:46:42 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:46:42 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:46:42 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:46:42 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:46:42 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:46:42 collections:620] Total 10 session files loaded accounting to # 10 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 25.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:42 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:46:42 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:46:42 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:46:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:42 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:46:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:42 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:46:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:46:42 msdd_models:1431]   \n",
            "    \n",
            "archivo 5fab44f212e3402d99638a5dc9d97701_20230610t14_26_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:47:24 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:47:24 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:47:24 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:47:24 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:47:25 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:47:25 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:47:25 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:25 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:47:25 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:47:26 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:47:26 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:47:26 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:47:26 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:47:26 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:47:26 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:47:27 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:47:27 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:47:27 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:27 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:47:27 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:47:27 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:47:27 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:47:27 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:27 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:47:27 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 55.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:27 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:27 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:47:27 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:47:27 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:47:27 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:27 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 17.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:47:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:47:28 collections:302] Dataset loaded with 48 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:47:28 collections:304] # 48 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:47:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:47:28 collections:302] Dataset loaded with 61 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:47:28 collections:304] # 61 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:47:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:47:28 collections:302] Dataset loaded with 74 items, total duration of  0.02 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:28 collections:304] # 74 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:47:28 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:47:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:47:28 collections:302] Dataset loaded with 101 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:47:28 collections:304] # 101 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:29 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:47:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:47:29 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:47:29 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:47:29 collections:302] Dataset loaded with 154 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:47:29 collections:304] # 154 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00, 10.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:29 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:29 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:47:29 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:29 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:47:29 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:47:29 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:47:29 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:47:29 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:47:29 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:47:29 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:47:29 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 49.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:29 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:47:29 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:47:29 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:47:29 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:29 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:47:29 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:29 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:47:29 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:47:29 msdd_models:1431]   \n",
            "    \n",
            "archivo e091c45596054f6ea5fac6b7388e115c_20230610t15_13_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:48:10 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:48:10 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:48:10 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:48:10 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:48:12 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:48:12 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:48:12 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:12 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:48:12 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:48:13 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:48:13 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:48:14 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:48:14 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:48:14 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:48:14 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:48:15 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:48:15 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:48:15 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:15 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:48:15 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:48:15 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:48:15 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:48:15 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:15 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:48:15 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 55.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:15 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:48:15 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:48:15 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:48:15 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:48:15 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:15 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:16 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 12.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:16 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:48:16 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:48:16 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:48:16 collections:302] Dataset loaded with 50 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:48:16 collections:304] # 50 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:48:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:48:17 collections:302] Dataset loaded with 59 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:48:17 collections:304] # 59 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:48:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:48:17 collections:302] Dataset loaded with 74 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:48:17 collections:304] # 74 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:48:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:48:17 collections:302] Dataset loaded with 99 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:48:17 collections:304] # 99 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:48:17 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:48:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:48:17 collections:302] Dataset loaded with 152 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:48:17 collections:304] # 152 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00, 10.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:18 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:18 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:48:18 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:18 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:48:18 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:48:18 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:48:18 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:48:18 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:48:18 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:48:18 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:48:18 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 32.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:18 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:48:18 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:48:18 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:48:18 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:18 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:48:18 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:18 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:48:18 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:48:18 msdd_models:1431]   \n",
            "    \n",
            "archivo d9553adbba9c45bead6e1a2bded61ad8_20230610t16_33_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:49:09 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:49:09 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:49:09 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:49:09 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:49:10 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:49:10 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:49:10 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:10 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:49:10 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:49:11 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:49:12 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:49:13 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:49:13 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:49:13 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:49:13 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:49:13 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:49:13 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:49:13 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:13 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:49:13 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:49:13 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:49:13 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:49:13 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:13 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:49:13 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:13 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:49:13 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:49:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:49:13 collections:302] Dataset loaded with 5 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-26 03:49:13 collections:304] # 5 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 5/5 [00:01<00:00,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:15 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:17 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:49:17 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:49:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:49:17 collections:302] Dataset loaded with 240 items, total duration of  0.09 hours.\n",
            "[NeMo I 2024-08-26 03:49:17 collections:304] # 240 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:18 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:49:18 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:49:18 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:49:18 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:49:18 collections:302] Dataset loaded with 282 items, total duration of  0.09 hours.\n",
            "[NeMo I 2024-08-26 03:49:18 collections:304] # 282 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:18 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:49:18 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:49:18 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:49:18 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:49:18 collections:302] Dataset loaded with 359 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 03:49:18 collections:304] # 359 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  7.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:19 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:49:19 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:49:19 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:49:19 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:49:19 collections:302] Dataset loaded with 485 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 03:49:19 collections:304] # 485 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 8/8 [00:00<00:00,  8.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:20 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:49:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:49:20 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:49:20 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:49:20 collections:302] Dataset loaded with 738 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 03:49:20 collections:304] # 738 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 12/12 [00:01<00:00, 10.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:22 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:22 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:49:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:22 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:49:22 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:49:22 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:49:22 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:49:22 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:49:22 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:49:22 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:49:22 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 23.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:22 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:49:22 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:49:22 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:49:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:22 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:49:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:22 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:49:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:49:23 msdd_models:1431]   \n",
            "    \n",
            "archivo 934de5177dd94afd8f8a198b2226c2e5_20230610t15_00_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:50:03 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:50:03 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:50:03 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:50:03 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:50:05 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:50:05 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:50:05 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:05 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:50:05 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:50:05 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:50:06 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:50:06 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:50:06 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:50:06 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:50:06 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:50:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:50:06 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:50:06 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:06 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:50:06 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:50:06 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:50:06 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:50:06 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:06 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:50:06 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 66.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:06 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:06 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:50:06 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:50:06 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:50:06 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:07 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:07 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 16.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:50:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:50:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:50:07 collections:302] Dataset loaded with 47 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:50:07 collections:304] # 47 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:50:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:50:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:50:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:07 collections:302] Dataset loaded with 58 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:50:07 collections:304] # 58 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:08 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:50:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:50:08 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:50:08 collections:302] Dataset loaded with 72 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:50:08 collections:304] # 72 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00, 10.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:08 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:50:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:50:08 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:50:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:50:08 collections:302] Dataset loaded with 97 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:50:08 collections:304] # 97 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:08 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:50:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:50:08 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:50:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:50:08 collections:302] Dataset loaded with 148 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:50:08 collections:304] # 148 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:09 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:09 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:50:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:09 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:50:09 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:50:09 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:50:09 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:50:09 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:50:09 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:50:09 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:50:09 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 53.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:09 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:50:09 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:50:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:50:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:50:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:50:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:50:09 msdd_models:1431]   \n",
            "    \n",
            "archivo 45adf080f3e24793900699ada4592d63_20230610t15_47_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:51:02 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:51:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:51:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:51:02 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:51:03 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:51:03 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:51:03 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:03 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:51:04 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:51:04 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:51:04 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:51:05 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:51:05 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:51:05 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:51:05 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:51:06 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:51:06 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:51:06 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:06 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:51:06 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:51:06 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:51:06 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:51:06 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:06 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:51:06 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 14.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:06 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:51:06 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:51:06 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:51:06 collections:302] Dataset loaded with 6 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:51:06 collections:304] # 6 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 6/6 [00:01<00:00,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:08 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:11 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:11 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:51:11 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:51:11 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:51:11 collections:302] Dataset loaded with 264 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 03:51:11 collections:304] # 264 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:12 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:51:12 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:51:12 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:51:12 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:51:12 collections:302] Dataset loaded with 317 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 03:51:12 collections:304] # 317 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:13 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:51:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:51:13 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:51:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:51:13 collections:302] Dataset loaded with 402 items, total duration of  0.11 hours.\n",
            "[NeMo I 2024-08-26 03:51:13 collections:304] # 402 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 7/7 [00:00<00:00,  8.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:14 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:51:14 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:51:14 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:51:14 collections:302] Dataset loaded with 539 items, total duration of  0.11 hours.\n",
            "[NeMo I 2024-08-26 03:51:14 collections:304] # 539 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 9/9 [00:00<00:00,  9.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:15 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:51:15 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:15 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:51:15 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:51:15 collections:302] Dataset loaded with 825 items, total duration of  0.11 hours.\n",
            "[NeMo I 2024-08-26 03:51:15 collections:304] # 825 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 13/13 [00:01<00:00, 10.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:16 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:17 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:51:17 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:17 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:51:17 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:51:17 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:51:17 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:51:17 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:51:17 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:51:17 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:51:17 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 25.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:17 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:51:17 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:51:17 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:51:17 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:17 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:51:17 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:17 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:51:17 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:51:17 msdd_models:1431]   \n",
            "    \n",
            "archivo eda880c7ca6f4e40835aa372d01627c0_20230610t14_59_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:51:59 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:51:59 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:51:59 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:51:59 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:52:01 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:52:01 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:52:01 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:01 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:52:01 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:52:03 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:52:03 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:52:04 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:52:04 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:52:04 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:52:04 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:52:04 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:52:04 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:52:04 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:04 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:52:04 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:52:04 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:52:04 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:52:04 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:04 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:52:04 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 30.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:04 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:52:04 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:52:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:52:04 collections:302] Dataset loaded with 2 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:52:04 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:05 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:06 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:52:06 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:52:06 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:52:06 collections:302] Dataset loaded with 87 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:52:06 collections:304] # 87 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:06 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:52:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:52:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:52:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:52:07 collections:302] Dataset loaded with 106 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:52:07 collections:304] # 106 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:52:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:52:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:52:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:52:07 collections:302] Dataset loaded with 132 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:52:07 collections:304] # 132 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:52:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:52:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:52:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:52:07 collections:302] Dataset loaded with 179 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:52:07 collections:304] # 179 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  6.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:08 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:52:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:52:08 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:52:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:52:08 collections:302] Dataset loaded with 273 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:52:08 collections:304] # 273 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:08 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:09 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:52:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:09 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:52:09 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:52:09 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:52:09 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:52:09 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:52:09 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:52:09 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:52:09 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 47.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:09 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:52:09 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:52:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:52:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:52:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:52:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:52:09 msdd_models:1431]   \n",
            "    \n",
            "archivo c7e11bdfad064aae944c4ce1a11dc2d7_20230610t14_02_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:52:59 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:52:59 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:52:59 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:52:59 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:53:00 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:53:00 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:53:00 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:00 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:53:01 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:53:01 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:53:01 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:53:02 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:53:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:53:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:53:02 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:53:03 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:53:03 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:53:03 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:03 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:53:03 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:53:03 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:53:03 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:53:03 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:03 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:53:03 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 13.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:03 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:53:03 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:53:03 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:53:03 collections:302] Dataset loaded with 6 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:53:03 collections:304] # 6 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 6/6 [00:01<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:05 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:08 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:53:08 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:53:08 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:53:08 collections:302] Dataset loaded with 218 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:53:08 collections:304] # 218 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:09 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:53:09 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:53:09 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:53:09 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:53:09 collections:302] Dataset loaded with 259 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:53:09 collections:304] # 259 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:10 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:53:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:53:10 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:10 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:53:10 collections:302] Dataset loaded with 316 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 03:53:10 collections:304] # 316 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:10 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:53:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:53:10 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:53:10 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:53:10 collections:302] Dataset loaded with 419 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 03:53:10 collections:304] # 419 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 7/7 [00:00<00:00,  9.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:11 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:53:11 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:11 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:53:11 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:53:11 collections:302] Dataset loaded with 627 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 03:53:11 collections:304] # 627 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 10/10 [00:00<00:00, 10.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:12 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:13 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:53:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:13 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:53:13 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:53:13 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:53:13 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:53:13 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:53:13 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:53:13 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:53:13 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:13 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:53:13 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:53:13 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:53:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:13 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:53:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:13 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:53:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:13 msdd_models:1431]   \n",
            "    \n",
            "archivo 6eb352d2758049f09c9619ac9df008e5_20230610t14_29_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:53:56 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:53:56 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:53:56 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:53:56 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:53:57 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:53:57 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:53:57 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:57 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:53:57 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:53:58 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:53:58 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:53:58 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:53:58 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:53:58 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:53:58 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:53:58 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:53:58 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:53:58 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:58 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:53:59 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:53:59 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:53:59 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:53:59 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:59 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:53:59 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 29.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:59 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:59 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:53:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:53:59 collections:302] Dataset loaded with 3 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:53:59 collections:304] # 3 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 3/3 [00:00<00:00,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:53:59 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:01 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:54:01 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:54:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:54:01 collections:302] Dataset loaded with 84 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:54:01 collections:304] # 84 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:02 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:54:02 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:54:02 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:54:02 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:54:02 collections:302] Dataset loaded with 97 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:54:02 collections:304] # 97 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:02 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:54:02 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:54:02 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:54:02 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:54:02 collections:302] Dataset loaded with 127 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:54:02 collections:304] # 127 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:02 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:54:02 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:54:02 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:54:02 collections:301] Filtered duration for loading collection is  0.00 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:02 collections:302] Dataset loaded with 171 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:54:02 collections:304] # 171 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:03 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:54:03 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:54:03 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:54:03 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:54:03 collections:302] Dataset loaded with 261 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:54:03 collections:304] # 261 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:03 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:04 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:54:04 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:04 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:54:04 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:54:04 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:54:04 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:54:04 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:54:04 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:54:04 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:54:04 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 36.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:04 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:54:04 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:54:04 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:54:04 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:04 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:54:04 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:04 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:54:04 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:04 msdd_models:1431]   \n",
            "    \n",
            "archivo 6eb42d94dfb3406faf290fe85feffbfe_20230610t16_55_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:54:44 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:54:44 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:54:44 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:54:44 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:54:46 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:54:46 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:54:46 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:46 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:54:46 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:54:47 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:54:47 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:54:48 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:54:48 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:54:48 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:54:48 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:54:48 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:54:48 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:54:48 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:48 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:54:48 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:54:48 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:54:48 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:54:48 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:48 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:54:48 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 67.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:48 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:48 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:54:48 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:54:48 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:54:48 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:48 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 16.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:54:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:54:49 collections:302] Dataset loaded with 44 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:54:49 collections:304] # 44 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:54:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:49 collections:302] Dataset loaded with 56 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:54:49 collections:304] # 56 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:54:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:54:49 collections:302] Dataset loaded with 67 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:54:49 collections:304] # 67 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:54:49 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:54:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:54:49 collections:302] Dataset loaded with 92 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:54:49 collections:304] # 92 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:50 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:54:50 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:54:50 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:54:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:54:50 collections:302] Dataset loaded with 137 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:54:50 collections:304] # 137 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00, 11.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:50 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:50 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:54:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:50 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:54:50 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:54:50 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:54:50 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:54:50 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:54:50 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:54:50 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:54:50 collections:620] Total 6 session files loaded accounting to # 6 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 25.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:50 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:54:50 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:54:50 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:54:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:50 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:54:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:50 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:54:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:54:50 msdd_models:1431]   \n",
            "    \n",
            "archivo d15a221c5dce4a34ac2d8bda6ed71ebd_20230610t13_57_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:55:34 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:55:34 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:55:34 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:55:34 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:55:35 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:55:35 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:55:35 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:35 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:55:35 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:55:36 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:55:36 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:55:37 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:55:37 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:55:37 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:55:37 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:55:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:55:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:55:37 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:55:37 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:55:37 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:55:37 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:55:37 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:37 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:55:37 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 40.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:37 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:37 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:55:37 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:55:37 collections:302] Dataset loaded with 2 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:55:37 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 2/2 [00:01<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:38 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:39 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:39 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:55:39 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:55:39 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:55:39 collections:302] Dataset loaded with 76 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:55:39 collections:304] # 76 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:39 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:55:39 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:55:39 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:55:39 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:55:39 collections:302] Dataset loaded with 94 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:55:39 collections:304] # 94 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:40 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:55:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:55:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:55:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:55:40 collections:302] Dataset loaded with 117 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:55:40 collections:304] # 117 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:40 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:55:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:55:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:55:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:55:40 collections:302] Dataset loaded with 157 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:55:40 collections:304] # 157 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:55:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:55:41 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:55:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:55:41 collections:302] Dataset loaded with 246 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:55:41 collections:304] # 246 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  7.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:42 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:55:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:42 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:55:42 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:55:42 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:55:42 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:55:42 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:55:42 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:55:42 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:55:42 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 40.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:42 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:55:42 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:55:42 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:55:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:42 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:55:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:42 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:55:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:55:42 msdd_models:1431]   \n",
            "    \n",
            "archivo d554a73b18c84f35866c98565d703d21_20230610t16_41_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:56:25 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:56:25 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:56:25 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:56:25 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:56:26 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:56:26 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:56:26 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:26 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:56:27 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:56:27 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:56:27 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:56:28 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:56:28 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:56:28 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:56:28 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:56:28 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:56:28 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:56:28 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:28 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:56:28 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:56:28 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:56:28 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:56:28 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:28 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:56:28 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 31.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:28 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:28 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:56:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:56:28 collections:302] Dataset loaded with 3 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:56:28 collections:304] # 3 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 3/3 [00:00<00:00,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:29 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:30 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:56:30 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:56:30 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:56:30 collections:302] Dataset loaded with 92 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:56:30 collections:304] # 92 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:30 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:56:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:56:30 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:56:30 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:56:30 collections:302] Dataset loaded with 111 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:56:30 collections:304] # 111 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:31 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:56:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:56:31 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:56:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:56:31 collections:302] Dataset loaded with 140 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:56:31 collections:304] # 140 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  9.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:31 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:56:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:56:31 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:56:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:56:31 collections:302] Dataset loaded with 186 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:56:31 collections:304] # 186 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:31 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:56:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:56:31 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:56:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:56:31 collections:302] Dataset loaded with 287 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 03:56:31 collections:304] # 287 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00, 11.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:32 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:32 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:56:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:32 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:56:32 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:56:32 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:56:32 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:56:32 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:56:32 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:56:32 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:56:32 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 44.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:32 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:56:32 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:56:32 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:56:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:32 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:56:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:32 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:56:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:56:32 msdd_models:1431]   \n",
            "    \n",
            "archivo 463aea85483f442fa152796bbe6412f0_20230610t13_52_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:57:13 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:57:13 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:57:13 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:57:13 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:57:14 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:57:14 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:57:14 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:14 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:57:14 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:57:15 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:57:15 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:57:16 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:57:16 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:57:16 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:57:16 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:57:17 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:57:17 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:57:17 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:17 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:57:17 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:57:17 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:57:17 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:57:17 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:17 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:57:17 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 51.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:17 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:57:17 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:57:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:57:17 collections:302] Dataset loaded with 2 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 03:57:17 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:17 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:18 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 10.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:18 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:57:18 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:57:18 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:57:18 collections:302] Dataset loaded with 47 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:57:18 collections:304] # 47 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:18 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:57:18 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:18 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:57:18 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:57:18 collections:302] Dataset loaded with 58 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:57:18 collections:304] # 58 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:19 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:57:19 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:57:19 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:19 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:57:19 collections:302] Dataset loaded with 72 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:57:19 collections:304] # 72 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:19 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:57:19 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:57:19 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:57:19 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:57:19 collections:302] Dataset loaded with 97 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:57:19 collections:304] # 97 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:19 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:57:19 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:57:19 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:57:19 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:57:19 collections:302] Dataset loaded with 148 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:57:19 collections:304] # 148 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:20 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:20 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:57:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:20 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:57:20 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:57:20 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:57:20 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:57:20 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:57:20 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:57:20 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:57:20 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 41.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:20 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:57:20 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:57:20 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:57:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:20 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:57:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:20 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:57:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:57:20 msdd_models:1431]   \n",
            "    \n",
            "archivo ed011e99f19e4257b0cc08f003decd8c_20230610t16_21_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:58:01 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:58:01 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:58:01 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:58:01 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:58:03 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:58:03 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:58:03 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:03 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:58:03 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:58:04 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:58:04 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:58:04 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:58:04 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:58:04 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:58:04 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:58:04 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:58:04 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:58:04 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:04 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:58:04 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:58:04 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:58:04 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:58:04 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:04 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:58:04 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 37.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:05 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:05 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:58:05 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:58:05 collections:302] Dataset loaded with 2 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:58:05 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 2/2 [00:00<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:05 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:06 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 10.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:58:06 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:58:06 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:58:06 collections:302] Dataset loaded with 59 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:58:06 collections:304] # 59 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:06 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:58:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:58:06 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:58:06 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:58:06 collections:302] Dataset loaded with 73 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:58:06 collections:304] # 73 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00, 10.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:06 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:58:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:58:06 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:58:06 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:58:07 collections:302] Dataset loaded with 89 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:58:07 collections:304] # 89 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:58:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:58:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:58:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:58:07 collections:302] Dataset loaded with 120 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 03:58:07 collections:304] # 120 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:58:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:58:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:58:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:58:07 collections:302] Dataset loaded with 184 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:58:07 collections:304] # 184 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:08 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:58:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:08 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:58:08 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:58:08 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:58:08 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:58:08 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:58:08 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:58:08 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:58:08 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 40.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:08 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:58:08 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:58:08 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:58:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:08 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:58:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:08 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:58:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:58:08 msdd_models:1431]   \n",
            "    \n",
            "archivo 29a70da7b6b4483d85fd483e814378b1_20230610t14_41_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:58:58 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:58:58 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:58:58 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:58:58 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:59:00 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:59:00 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:59:00 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:00 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:59:00 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:59:01 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:59:01 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:59:01 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:59:01 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:59:01 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:59:01 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:59:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:59:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:59:02 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:02 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:59:02 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:59:02 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:59:02 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:59:02 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:02 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:59:02 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 20.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:02 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 03:59:02 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:59:02 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:02 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n",
            "[NeMo I 2024-08-26 03:59:02 collections:304] # 4 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 4/4 [00:00<00:00,  4.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:03 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:04 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:05 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:59:05 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:05 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:05 collections:302] Dataset loaded with 178 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:59:05 collections:304] # 178 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:05 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:59:05 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:59:05 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:59:05 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:05 collections:302] Dataset loaded with 219 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:59:05 collections:304] # 219 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:06 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:59:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:59:06 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:59:06 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:06 collections:302] Dataset loaded with 272 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:59:06 collections:304] # 272 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:06 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:59:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:06 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:59:06 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:06 collections:302] Dataset loaded with 367 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 03:59:06 collections:304] # 367 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  9.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:07 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:59:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 03:59:07 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:59:07 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:07 collections:302] Dataset loaded with 559 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 03:59:07 collections:304] # 559 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 9/9 [00:00<00:00, 10.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:08 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:08 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:59:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:08 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:59:08 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:59:08 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:59:08 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:59:08 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 03:59:08 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 03:59:08 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 03:59:08 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 27.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:08 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 03:59:08 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:59:08 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 03:59:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:59:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:09 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:59:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:09 msdd_models:1431]   \n",
            "    \n",
            "archivo 7f77a99fac1b4dabbcce2f408995b9bf_20230610t13_04_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 03:59:52 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 03:59:52 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:59:52 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 03:59:52 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:59:53 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:59:53 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 03:59:53 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:54 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:59:54 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:59:55 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 03:59:55 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:59:56 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 03:59:56 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:59:56 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 03:59:56 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:59:56 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:59:56 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 03:59:56 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:56 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 03:59:56 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 03:59:56 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 03:59:56 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 03:59:56 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:56 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 03:59:56 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 29.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:56 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:56 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 03:59:56 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:56 collections:302] Dataset loaded with 3 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:59:56 collections:304] # 3 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 3/3 [00:00<00:00,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:57 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:58 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 03:59:58 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:59:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:58 collections:302] Dataset loaded with 85 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:59:58 collections:304] # 85 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:59 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:59:59 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 03:59:59 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:59:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:59 collections:302] Dataset loaded with 98 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:59:59 collections:304] # 98 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:59 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:59:59 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 03:59:59 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:59:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:59 collections:302] Dataset loaded with 122 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:59:59 collections:304] # 122 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 03:59:59 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 03:59:59 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 03:59:59 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 03:59:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 03:59:59 collections:302] Dataset loaded with 167 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 03:59:59 collections:304] # 167 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:00:00 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:00:00 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:00:00 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:00:00 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:00:00 collections:302] Dataset loaded with 252 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:00:00 collections:304] # 252 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  9.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:00:00 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:00:00 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:00:00 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:00:00 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:00:00 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:00:00 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:00:00 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:00:00 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:00:00 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:00:00 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:00:00 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 39.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:00:00 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:00:00 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:00:00 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:00:00 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:00:00 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:00:01 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:00:01 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:00:01 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:00:01 msdd_models:1431]   \n",
            "    \n",
            "archivo 3790e2a16369420295cd1456849101ac_20230610t16_51_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:01:01 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:01:01 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:01:01 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:01:01 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:01:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:01:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:01:02 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:02 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:01:02 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:01:03 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:01:03 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:01:04 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:01:04 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:01:04 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:01:04 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:01:05 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:01:05 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:01:05 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:05 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:01:05 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:01:05 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:01:05 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:01:05 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:05 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:01:05 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:05 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:01:05 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:01:05 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:01:05 collections:302] Dataset loaded with 8 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 04:01:05 collections:304] # 8 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 8/8 [00:02<00:00,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:07 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:10 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:11 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:01:11 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:01:11 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:01:11 collections:302] Dataset loaded with 365 items, total duration of  0.14 hours.\n",
            "[NeMo I 2024-08-26 04:01:11 collections:304] # 365 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:12 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:01:12 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:01:12 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:01:12 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:01:12 collections:302] Dataset loaded with 449 items, total duration of  0.15 hours.\n",
            "[NeMo I 2024-08-26 04:01:12 collections:304] # 449 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 8/8 [00:01<00:00,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:13 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:01:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:01:13 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:01:13 collections:302] Dataset loaded with 565 items, total duration of  0.15 hours.\n",
            "[NeMo I 2024-08-26 04:01:13 collections:304] # 565 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:14 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:01:14 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:01:14 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:01:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:01:14 collections:302] Dataset loaded with 761 items, total duration of  0.15 hours.\n",
            "[NeMo I 2024-08-26 04:01:14 collections:304] # 761 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 12/12 [00:01<00:00,  8.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:16 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:01:16 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:16 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:01:16 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:01:16 collections:302] Dataset loaded with 1161 items, total duration of  0.16 hours.\n",
            "[NeMo I 2024-08-26 04:01:16 collections:304] # 1161 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 19/19 [00:01<00:00, 10.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:18 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:18 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:01:18 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:18 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:01:18 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:01:18 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:01:18 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:01:18 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:01:18 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:01:18 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:01:18 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:18 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:01:18 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:01:18 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:01:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:19 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:01:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:19 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:01:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:01:19 msdd_models:1431]   \n",
            "    \n",
            "archivo 2ee89ca6b151452d80fafc0031248b5c_20230610t15_18_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:02:12 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:02:12 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:02:12 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:02:12 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:02:14 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:02:14 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:02:14 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:14 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:02:14 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:02:15 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:02:15 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:02:16 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:02:16 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:02:16 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:02:16 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:02:17 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:02:17 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:02:17 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:17 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:02:17 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:02:17 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:02:17 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:02:17 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:17 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:02:17 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 12.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:17 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:02:17 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:02:17 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:02:17 collections:302] Dataset loaded with 7 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 04:02:17 collections:304] # 7 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 7/7 [00:02<00:00,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:19 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:22 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:22 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:02:22 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:02:22 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:02:22 collections:302] Dataset loaded with 286 items, total duration of  0.11 hours.\n",
            "[NeMo I 2024-08-26 04:02:22 collections:304] # 286 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:23 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:02:23 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:02:23 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:02:23 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:02:23 collections:302] Dataset loaded with 346 items, total duration of  0.11 hours.\n",
            "[NeMo I 2024-08-26 04:02:23 collections:304] # 346 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  7.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:24 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:02:24 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:02:24 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:02:24 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:02:24 collections:302] Dataset loaded with 435 items, total duration of  0.12 hours.\n",
            "[NeMo I 2024-08-26 04:02:24 collections:304] # 435 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 7/7 [00:00<00:00,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:25 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:02:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:02:25 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:02:25 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:02:25 collections:302] Dataset loaded with 595 items, total duration of  0.12 hours.\n",
            "[NeMo I 2024-08-26 04:02:25 collections:304] # 595 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 10/10 [00:01<00:00,  9.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:26 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:02:26 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:26 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:02:26 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:02:26 collections:302] Dataset loaded with 910 items, total duration of  0.12 hours.\n",
            "[NeMo I 2024-08-26 04:02:26 collections:304] # 910 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 15/15 [00:01<00:00, 11.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:27 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:28 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:02:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:28 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:02:28 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:02:28 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:02:28 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:02:28 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:02:28 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:02:28 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:02:28 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 27.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:28 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:02:28 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:02:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:02:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:02:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:02:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:02:28 msdd_models:1431]   \n",
            "    \n",
            "archivo f189dbfe6981414087b0500db982a3e7_20230610t13_45_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:03:36 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:03:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:03:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:03:36 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:03:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:03:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:03:37 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:03:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:03:38 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:03:38 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:03:39 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:03:39 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:03:39 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:03:39 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:03:40 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:03:40 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:03:40 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:40 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:03:41 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:03:41 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:03:41 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:03:41 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:41 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:03:41 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:41 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:03:41 classification_models:273] Perform streaming frame-level VAD\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:03:41 collections:302] Dataset loaded with 10 items, total duration of  0.13 hours.\n",
            "[NeMo I 2024-08-26 04:03:41 collections:304] # 10 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 10/10 [00:02<00:00,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:44 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:48 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:48 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:03:48 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:03:48 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:03:48 collections:302] Dataset loaded with 451 items, total duration of  0.16 hours.\n",
            "[NeMo I 2024-08-26 04:03:48 collections:304] # 451 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 8/8 [00:01<00:00,  6.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:50 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:03:50 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:03:50 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:03:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:03:50 collections:302] Dataset loaded with 539 items, total duration of  0.17 hours.\n",
            "[NeMo I 2024-08-26 04:03:50 collections:304] # 539 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  7.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:51 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:03:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:03:51 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:03:51 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:03:51 collections:302] Dataset loaded with 680 items, total duration of  0.18 hours.\n",
            "[NeMo I 2024-08-26 04:03:51 collections:304] # 680 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 11/11 [00:01<00:00,  8.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:52 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:03:52 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:03:52 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:03:52 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:03:52 collections:302] Dataset loaded with 924 items, total duration of  0.18 hours.\n",
            "[NeMo I 2024-08-26 04:03:52 collections:304] # 924 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 15/15 [00:01<00:00,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:54 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:03:54 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:54 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:03:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:03:54 collections:302] Dataset loaded with 1415 items, total duration of  0.19 hours.\n",
            "[NeMo I 2024-08-26 04:03:54 collections:304] # 1415 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 23/23 [00:02<00:00,  8.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:57 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:58 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:03:58 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:58 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:03:58 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:03:58 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:03:58 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:03:58 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:03:58 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:03:59 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:03:59 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:59 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:03:59 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:03:59 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:03:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:59 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:03:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:59 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:03:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:03:59 msdd_models:1431]   \n",
            "    \n",
            "archivo f1e80f376a024fac8912df9b9df04df0_20230610t13_44_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:04:36 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:04:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:04:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:04:36 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:04:38 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:04:38 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:04:38 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:38 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:04:39 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:04:40 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:04:40 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:04:41 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:04:41 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:04:41 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:04:41 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:04:41 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:04:41 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:04:41 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:41 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:04:41 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:04:41 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:04:41 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:04:41 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:41 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:04:41 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 75.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:41 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:04:41 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:04:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:04:41 collections:302] Dataset loaded with 1 items, total duration of  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:04:41 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:41 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 55.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:04:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:04:42 collections:302] Dataset loaded with 7 items, total duration of  0.00 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 collections:304] # 7 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 19.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:04:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:04:42 collections:302] Dataset loaded with 8 items, total duration of  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:04:42 collections:304] # 8 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 27.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:04:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:04:42 collections:302] Dataset loaded with 10 items, total duration of  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:04:42 collections:304] # 10 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 25.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:04:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:04:42 collections:302] Dataset loaded with 14 items, total duration of  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:04:42 collections:304] # 14 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:04:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:04:42 collections:302] Dataset loaded with 22 items, total duration of  0.00 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 collections:304] # 22 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 14.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:04:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:04:42 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:04:42 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:04:42 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:04:42 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:04:42 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:04:42 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:04:42 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 54.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:04:42 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:04:42 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:04:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:04:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:04:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:04:42 msdd_models:1431]   \n",
            "    \n",
            "archivo 5d6b0bcd9801457bb62733de21e565f2_20230610t15_44_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:05:22 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:05:22 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:05:22 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:05:22 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:05:24 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:05:24 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:05:24 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:24 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:05:24 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:05:25 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:05:25 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:05:25 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:05:25 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:05:25 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:05:25 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:05:25 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:05:25 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:05:25 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:25 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:05:25 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:05:26 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:05:26 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:05:26 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:26 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:05:26 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 47.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:26 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:05:26 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:05:26 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:05:26 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:05:26 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:26 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:26 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 17.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:26 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:05:26 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:05:26 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:05:26 collections:302] Dataset loaded with 41 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:05:26 collections:304] # 41 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:05:27 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:05:27 collections:302] Dataset loaded with 50 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:05:27 collections:304] # 50 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:05:27 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:05:27 collections:302] Dataset loaded with 63 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:05:27 collections:304] # 63 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:05:27 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:05:27 collections:302] Dataset loaded with 86 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:05:27 collections:304] # 86 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:05:27 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:05:27 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:05:27 collections:302] Dataset loaded with 131 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:05:27 collections:304] # 131 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  9.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:28 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:28 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:05:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:28 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:05:28 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:05:28 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:05:28 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:05:28 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:05:28 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:05:28 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:05:28 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 48.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:28 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:05:28 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:05:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:05:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:05:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:28 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:05:28 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:05:28 msdd_models:1431]   \n",
            "    \n",
            "archivo 9adc604104c341d9adc92db9665fb992_20230610t15_10_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:06:10 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:06:10 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:06:10 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:06:10 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:06:11 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:06:11 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:06:11 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:11 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:06:12 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:06:12 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:06:12 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:06:13 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:06:13 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:06:13 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:06:13 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:06:13 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:06:13 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:06:13 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:13 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:06:13 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:06:13 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:06:13 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:06:13 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:13 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:06:13 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 40.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:13 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:06:13 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:06:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:06:13 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:06:13 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:14 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:14 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 13.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:14 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:06:14 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:06:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:06:14 collections:302] Dataset loaded with 53 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:06:14 collections:304] # 53 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:06:15 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:06:15 collections:302] Dataset loaded with 67 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:06:15 collections:304] # 67 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:06:15 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:06:15 collections:302] Dataset loaded with 81 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:06:15 collections:304] # 81 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:06:15 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:06:15 collections:302] Dataset loaded with 111 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:06:15 collections:304] # 111 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:06:15 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:06:15 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:06:15 collections:302] Dataset loaded with 168 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:06:15 collections:304] # 168 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  9.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:16 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:16 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:06:16 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:16 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:06:16 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:06:16 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:06:16 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:06:16 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:06:16 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:06:16 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:06:16 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 46.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:16 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:06:16 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:06:16 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:06:16 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:16 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:06:16 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:16 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:06:16 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:16 msdd_models:1431]   \n",
            "    \n",
            "archivo ad0946be1ed543acbf3ca01df5fc6b25_20230610t14_38_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:06:57 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:06:57 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:06:57 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:06:57 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:06:59 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:06:59 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:06:59 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:06:59 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:06:59 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:07:01 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:07:01 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:07:02 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:07:02 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:07:02 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:07:02 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:07:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:07:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:07:02 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:02 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:07:02 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:07:02 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:07:02 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:07:02 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:02 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:07:02 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 33.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:02 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:07:02 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:07:02 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:02 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:07:02 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:03 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:03 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 11.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:03 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:07:03 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:07:03 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:03 collections:302] Dataset loaded with 55 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:07:03 collections:304] # 55 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:03 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:07:03 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:03 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:07:03 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:04 collections:302] Dataset loaded with 68 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:07:04 collections:304] # 68 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:04 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:07:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:07:04 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:07:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:04 collections:302] Dataset loaded with 84 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:07:04 collections:304] # 84 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:04 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:07:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:07:04 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:07:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:04 collections:302] Dataset loaded with 113 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:07:04 collections:304] # 113 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:04 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:07:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:07:04 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:07:04 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:04 collections:302] Dataset loaded with 171 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:07:04 collections:304] # 171 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:05 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:05 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:07:05 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:05 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:07:05 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:07:05 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:07:05 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:07:05 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:07:05 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:07:05 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:07:05 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 29.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:05 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:07:05 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:07:05 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:07:05 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:05 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:07:05 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:05 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:07:05 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:05 msdd_models:1431]   \n",
            "    \n",
            "archivo de226de0f8c94183b0fc1b26c2a7a637_20230610t16_49_utc.wav listo\n",
            "No language specified, language will be first be detected for each audio file (increases inference time).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:07:48 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:07:48 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:07:48 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:07:48 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:07:50 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:07:50 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:07:50 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:50 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:07:50 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:07:51 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:07:51 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:07:52 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:07:52 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:07:52 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:07:52 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:07:52 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:07:52 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:07:52 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:52 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:07:52 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:07:52 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:07:52 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:07:52 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:52 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:07:52 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 33.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:52 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:07:52 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:07:52 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:52 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:07:52 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:53 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:53 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 10.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:07:53 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:07:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:53 collections:302] Dataset loaded with 86 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:07:53 collections:304] # 86 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:54 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:07:54 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:07:54 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:07:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:54 collections:302] Dataset loaded with 102 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:07:54 collections:304] # 102 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:54 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:07:54 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:07:54 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:07:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:54 collections:302] Dataset loaded with 129 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:07:54 collections:304] # 129 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:54 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:07:54 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:07:54 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:07:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:54 collections:302] Dataset loaded with 175 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:07:54 collections:304] # 175 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:55 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:07:55 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:07:55 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:07:55 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:07:55 collections:302] Dataset loaded with 267 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:07:55 collections:304] # 267 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:55 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:56 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:07:56 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:56 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:07:56 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:07:56 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:07:56 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:07:56 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:07:56 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:07:56 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:07:56 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 39.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:56 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:07:56 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:07:56 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:07:56 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:56 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:07:56 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:56 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:07:56 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:07:56 msdd_models:1431]   \n",
            "    \n",
            "archivo 42df394a0d744909b694f4139d4b8c09_20230610t15_37_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:08:40 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:08:40 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:08:40 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:08:40 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:08:41 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:08:41 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:08:41 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:41 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:08:41 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:08:42 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:08:42 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:08:43 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:08:43 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:08:43 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:08:43 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:08:43 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:08:43 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:08:43 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:43 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:08:43 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:08:43 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:08:43 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:08:43 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:43 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:08:43 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 31.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:43 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:08:43 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:08:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:08:43 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:08:43 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:44 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:44 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  9.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:08:45 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:08:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:08:45 collections:302] Dataset loaded with 79 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:08:45 collections:304] # 79 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:45 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:08:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:08:45 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:08:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:08:45 collections:302] Dataset loaded with 101 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:08:45 collections:304] # 101 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:45 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:08:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:08:45 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:08:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:08:45 collections:302] Dataset loaded with 126 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:08:45 collections:304] # 126 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:45 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:08:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:08:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:08:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:08:46 collections:302] Dataset loaded with 171 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:08:46 collections:304] # 171 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:46 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:08:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:08:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:08:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:08:46 collections:302] Dataset loaded with 262 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:08:46 collections:304] # 262 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00, 10.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:46 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:47 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:08:47 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:47 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:08:47 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:08:47 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:08:47 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:08:47 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:08:47 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:08:47 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:08:47 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 28.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:47 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:08:47 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:08:47 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:08:47 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:47 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:08:47 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:47 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:08:47 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:08:47 msdd_models:1431]   \n",
            "    \n",
            "archivo 8273dce465a54e99a47d92da2d1af7ad_20230610t14_54_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:09:30 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:09:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:09:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:09:30 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:09:31 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:09:31 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:09:31 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:31 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:09:32 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:09:33 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:09:33 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:09:34 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:09:34 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:09:34 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:09:34 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:09:34 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:09:34 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:09:34 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:34 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:09:34 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:09:34 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:09:34 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:09:34 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:34 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:09:34 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 26.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:34 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:09:34 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:09:34 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:09:34 collections:302] Dataset loaded with 2 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:09:34 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:35 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:36 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:09:36 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:09:36 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:09:36 collections:302] Dataset loaded with 90 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:09:36 collections:304] # 90 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:37 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:09:37 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:09:37 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:09:37 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:09:37 collections:302] Dataset loaded with 107 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:09:37 collections:304] # 107 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:37 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:09:37 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:09:37 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:09:37 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:09:37 collections:302] Dataset loaded with 137 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:09:37 collections:304] # 137 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:38 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:09:38 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:09:38 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:09:38 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:09:38 collections:302] Dataset loaded with 183 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:09:38 collections:304] # 183 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  6.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:38 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:09:38 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:09:38 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:09:38 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:09:38 collections:302] Dataset loaded with 278 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:09:38 collections:304] # 278 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:39 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:39 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:09:39 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:39 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:09:39 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:09:39 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:09:39 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:09:39 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:09:39 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:09:39 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:09:39 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 36.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:39 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:09:39 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:09:39 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:09:39 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:39 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:09:39 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:39 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:09:40 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:09:40 msdd_models:1431]   \n",
            "    \n",
            "archivo a7b3a1c2f26c464d97dbec49d46b75f1_20230610t14_25_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:10:41 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:10:41 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:10:41 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:10:41 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:10:42 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:10:42 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:10:42 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:42 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:10:42 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:10:43 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:10:43 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:10:44 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:10:44 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:10:44 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:10:44 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:10:44 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:10:44 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:10:44 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:44 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:10:44 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:10:44 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:10:44 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:10:44 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:44 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:10:44 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:44 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:10:44 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:10:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:10:44 collections:302] Dataset loaded with 8 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 04:10:44 collections:304] # 8 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 8/8 [00:01<00:00,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:46 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:50 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:10:51 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:10:51 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:10:51 collections:302] Dataset loaded with 356 items, total duration of  0.14 hours.\n",
            "[NeMo I 2024-08-26 04:10:51 collections:304] # 356 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:52 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:10:52 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:10:52 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:10:52 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:10:52 collections:302] Dataset loaded with 425 items, total duration of  0.14 hours.\n",
            "[NeMo I 2024-08-26 04:10:52 collections:304] # 425 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  6.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:53 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:10:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:10:53 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:10:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:10:53 collections:302] Dataset loaded with 543 items, total duration of  0.14 hours.\n",
            "[NeMo I 2024-08-26 04:10:53 collections:304] # 543 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:54 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:10:54 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:10:54 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:10:54 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:10:54 collections:302] Dataset loaded with 734 items, total duration of  0.15 hours.\n",
            "[NeMo I 2024-08-26 04:10:54 collections:304] # 734 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 12/12 [00:01<00:00,  9.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:56 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:10:56 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:10:56 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:10:56 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:10:56 collections:302] Dataset loaded with 1123 items, total duration of  0.15 hours.\n",
            "[NeMo I 2024-08-26 04:10:56 collections:304] # 1123 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 18/18 [00:01<00:00, 10.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:58 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:58 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:10:58 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:58 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:10:58 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:10:58 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:10:58 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:10:58 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:10:58 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:10:58 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:10:58 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:59 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:10:59 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:10:59 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:10:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:59 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:10:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:59 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:10:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:10:59 msdd_models:1431]   \n",
            "    \n",
            "archivo 26746b7e69e140b3b3a11b973330ce96_20230610t14_35_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:11:40 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:11:40 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:11:40 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:11:40 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:11:41 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:11:41 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:11:41 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:41 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:11:41 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:11:42 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:11:42 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:11:43 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:11:43 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:11:43 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:11:43 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:11:43 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:11:43 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:11:43 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:43 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:11:43 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:11:43 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:11:43 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:11:43 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:43 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:11:43 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 47.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:43 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:43 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:11:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:11:43 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:11:43 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:44 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:44 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 17.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:11:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:11:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:11:44 collections:302] Dataset loaded with 39 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:11:44 collections:304] # 39 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:44 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:11:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:11:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:11:44 collections:302] Dataset loaded with 46 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:11:44 collections:304] # 46 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:45 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:11:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:11:45 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:11:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:11:45 collections:302] Dataset loaded with 58 items, total duration of  0.01 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:45 collections:304] # 58 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:45 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:11:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:11:45 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:11:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:11:45 collections:302] Dataset loaded with 76 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:11:45 collections:304] # 76 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:45 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:11:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:11:45 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:11:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:11:45 collections:302] Dataset loaded with 115 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:11:45 collections:304] # 115 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:45 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:46 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:11:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:46 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:11:46 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:11:46 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:11:46 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:11:46 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:11:46 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:11:46 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:11:46 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 42.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:46 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:11:46 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:11:46 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:11:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:46 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:11:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:46 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:11:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:11:46 msdd_models:1431]   \n",
            "    \n",
            "archivo 269d7a90316042169c14e767e8b4ec18_20230610t15_41_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:12:25 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:12:25 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:12:25 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:12:25 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:12:26 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:12:26 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:12:26 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:26 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:12:27 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:12:28 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:12:28 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:12:29 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:12:29 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:12:29 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:12:29 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:12:29 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:12:29 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:12:29 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:29 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:12:29 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:12:29 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:12:29 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:12:29 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:29 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:12:29 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 56.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:29 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:12:29 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:12:29 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:12:29 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:12:29 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:30 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:30 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 17.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:12:30 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:12:30 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:12:30 collections:302] Dataset loaded with 20 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:12:30 collections:304] # 20 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:30 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:12:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:12:30 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:12:30 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:12:30 collections:302] Dataset loaded with 25 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:12:30 collections:304] # 25 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:30 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:12:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:12:30 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:12:30 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:12:30 collections:302] Dataset loaded with 31 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:12:30 collections:304] # 31 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:31 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:12:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:12:31 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:12:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:12:31 collections:302] Dataset loaded with 43 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:12:31 collections:304] # 43 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:31 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:12:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:12:31 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:12:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:12:31 collections:302] Dataset loaded with 66 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:12:31 collections:304] # 66 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00, 11.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:31 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:31 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:12:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:31 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:12:31 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:12:31 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:12:31 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:12:31 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:12:31 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:12:31 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:12:31 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 39.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:31 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:12:31 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:12:31 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:12:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:31 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:12:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:31 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:12:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:12:31 msdd_models:1431]   \n",
            "    \n",
            "archivo 640807edf3f74283a7295a888a93aaf7_20230610t16_54_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:13:08 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:13:08 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:13:08 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:13:08 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:13:09 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:13:09 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:13:09 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:09 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:13:10 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:13:11 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:13:11 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:13:12 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:13:12 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:13:12 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:13:12 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:13:12 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:13:12 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:13:12 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:12 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:13:12 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:13:12 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:13:12 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:13:12 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:12 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:13:12 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 57.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:12 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:13:12 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:13:12 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:12 collections:302] Dataset loaded with 1 items, total duration of  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:12 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 35.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:13:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:13 collections:302] Dataset loaded with 20 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:13 collections:304] # 20 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 11.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:13:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:13 collections:302] Dataset loaded with 24 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:13 collections:304] # 24 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:13:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:13 collections:302] Dataset loaded with 31 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:13 collections:304] # 31 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:13:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:13 collections:302] Dataset loaded with 41 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:13 collections:304] # 41 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:13:13 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:13:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:13 collections:302] Dataset loaded with 63 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:13 collections:304] # 63 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:14 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:14 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:13:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:14 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:13:14 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:13:14 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:13:14 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:13:14 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:13:14 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:13:14 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:13:14 collections:620] Total 21 session files loaded accounting to # 21 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:14 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:13:14 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:13:14 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:13:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:14 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:13:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:14 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:13:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:14 msdd_models:1431]   \n",
            "    \n",
            "archivo 52217898a6d84b0f9022c9d33b2f273f_20230610t13_28_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:13:53 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:13:53 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:13:53 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:13:53 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:13:55 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:13:55 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:13:55 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:55 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:13:55 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:13:56 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:13:56 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:13:57 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:13:57 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:13:57 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:13:57 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:13:57 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:13:57 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:13:57 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:57 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:13:57 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:13:57 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:13:57 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:13:57 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:57 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:13:57 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 47.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:57 vad_utils:107] The prepared manifest file exists. Overwriting!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:57 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:13:57 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:57 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:57 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:57 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 20.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:13:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:58 collections:302] Dataset loaded with 24 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:58 collections:304] # 24 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 11.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:13:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:58 collections:302] Dataset loaded with 29 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:58 collections:304] # 29 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 10.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:13:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:58 collections:302] Dataset loaded with 37 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:58 collections:304] # 37 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:13:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:58 collections:302] Dataset loaded with 50 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:58 collections:304] # 50 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:13:58 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:13:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:13:58 collections:302] Dataset loaded with 78 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:13:58 collections:304] # 78 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00, 11.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:59 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:59 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:13:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:59 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:13:59 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:13:59 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:13:59 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:13:59 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:13:59 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:13:59 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:13:59 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 52.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:59 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:13:59 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:13:59 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:13:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:59 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:13:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:59 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:13:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:13:59 msdd_models:1431]   \n",
            "    \n",
            "archivo f189e55691f04a0cbca711f6ee0bac4a_20230610t13_18_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:14:42 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:14:42 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:14:42 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:14:42 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:14:43 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:14:43 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:14:43 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:43 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:14:43 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:14:44 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:14:44 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:14:44 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:14:44 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:14:44 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:14:44 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:14:44 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:14:44 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:14:44 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:44 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:14:45 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:14:45 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:14:45 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:14:45 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:45 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:14:45 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 42.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:45 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:14:45 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:14:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:14:45 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:14:45 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:45 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:45 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:14:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:14:46 collections:302] Dataset loaded with 39 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:14:46 collections:304] # 39 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:14:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:14:46 collections:302] Dataset loaded with 47 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:14:46 collections:304] # 47 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:14:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:14:46 collections:302] Dataset loaded with 61 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:14:46 collections:304] # 61 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:14:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:14:46 collections:302] Dataset loaded with 81 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:14:46 collections:304] # 81 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00, 10.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:14:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:14:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:14:46 collections:302] Dataset loaded with 126 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:14:46 collections:304] # 126 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:47 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:47 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:14:47 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:47 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:14:47 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:14:47 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:14:47 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:14:47 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:14:47 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:14:47 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:14:47 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 28.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:47 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:14:47 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:14:47 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:14:47 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:47 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:14:47 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:47 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:14:47 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:14:47 msdd_models:1431]   \n",
            "    \n",
            "archivo f399f79640f94bfebba1323714013e12_20230610t16_49_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:15:36 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:15:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:15:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:15:36 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:15:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:15:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:15:37 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:15:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:15:38 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:15:38 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:15:38 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:15:38 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:15:38 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:15:38 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:15:39 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:15:39 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:15:39 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:39 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:15:39 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:15:39 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:15:39 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:15:39 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:39 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:15:39 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 15.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:39 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:15:39 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:15:39 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:15:39 collections:302] Dataset loaded with 5 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-26 04:15:39 collections:304] # 5 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 5/5 [00:01<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:40 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:42 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:15:42 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:15:42 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:15:42 collections:302] Dataset loaded with 189 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 04:15:42 collections:304] # 189 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:43 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:15:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:15:43 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:15:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:15:43 collections:302] Dataset loaded with 226 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 04:15:43 collections:304] # 226 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:43 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:15:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:15:43 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:15:43 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:15:43 collections:302] Dataset loaded with 289 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 04:15:43 collections:304] # 289 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:44 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:15:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:45 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:15:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:15:45 collections:302] Dataset loaded with 389 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 04:15:45 collections:304] # 389 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:46 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:15:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:15:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:15:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:15:46 collections:302] Dataset loaded with 591 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 04:15:46 collections:304] # 591 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 10/10 [00:01<00:00,  8.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:48 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:48 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:15:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:48 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:15:48 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:15:48 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:15:48 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:15:48 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:15:48 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:15:48 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:15:48 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 26.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:48 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:15:48 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:15:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:15:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:48 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:15:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:49 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:15:49 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:15:49 msdd_models:1431]   \n",
            "    \n",
            "archivo 1f948c343dac4d099d6cbb9a648403ff_20230610t16_57_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:16:40 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:16:40 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:16:40 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:16:40 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:16:42 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:16:42 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:16:42 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:42 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:16:42 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:16:43 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:16:43 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:16:44 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:16:44 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:16:44 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:16:44 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:16:44 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:16:44 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:16:44 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:44 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:16:45 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:16:45 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:16:45 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:16:45 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:45 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:16:45 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 10.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:45 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:16:45 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:16:45 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:16:45 collections:302] Dataset loaded with 7 items, total duration of  0.09 hours.\n",
            "[NeMo I 2024-08-26 04:16:45 collections:304] # 7 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 7/7 [00:01<00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:47 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:50 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:50 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:16:50 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:16:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:16:50 collections:302] Dataset loaded with 192 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-26 04:16:50 collections:304] # 192 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:51 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:16:51 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:16:51 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:16:51 collections:302] Dataset loaded with 234 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 04:16:51 collections:304] # 234 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:51 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:16:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:16:51 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:16:51 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:16:51 collections:302] Dataset loaded with 292 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 04:16:51 collections:304] # 292 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:52 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:52 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:16:52 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:16:52 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:16:52 collections:302] Dataset loaded with 383 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 04:16:52 collections:304] # 383 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:53 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:16:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:16:53 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:16:53 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:16:53 collections:302] Dataset loaded with 586 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 04:16:53 collections:304] # 586 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 10/10 [00:00<00:00, 10.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:54 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:54 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:16:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:54 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:16:54 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:16:54 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:16:54 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:16:54 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:16:54 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:16:54 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:16:54 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 29.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:54 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:16:54 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:16:54 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:16:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:54 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:16:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:54 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:16:55 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:16:55 msdd_models:1431]   \n",
            "    \n",
            "archivo 18eff36f759c4d73965c2a229beecfee_20230610t16_24_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:17:35 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:17:35 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:17:35 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:17:35 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:17:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:17:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:17:37 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:17:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:17:37 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:17:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:17:38 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:17:38 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:17:38 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:17:38 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:17:38 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:17:38 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:17:38 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:38 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:17:38 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:17:38 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:17:38 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:17:39 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:39 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:17:39 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 48.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:39 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:17:39 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:17:39 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:17:39 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:17:39 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:39 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:39 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 20.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:39 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:17:39 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:17:39 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:17:39 collections:302] Dataset loaded with 31 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:17:39 collections:304] # 31 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:17:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:17:40 collections:302] Dataset loaded with 39 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:17:40 collections:304] # 39 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:17:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:17:40 collections:302] Dataset loaded with 50 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:17:40 collections:304] # 50 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:17:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:17:40 collections:302] Dataset loaded with 67 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:17:40 collections:304] # 67 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:17:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:17:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:17:40 collections:302] Dataset loaded with 104 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:17:40 collections:304] # 104 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:41 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:17:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:41 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:17:41 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:17:41 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:17:41 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:17:41 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:17:41 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:17:41 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:17:41 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 44.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:41 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:17:41 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:17:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:17:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:17:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:17:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:17:41 msdd_models:1431]   \n",
            "    \n",
            "archivo 0c027942655e4f1183614bb47a282aea_20230610t13_32_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:18:25 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:18:25 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:18:25 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:18:25 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:18:26 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:18:26 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:18:26 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:26 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:18:26 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:18:27 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:18:27 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:18:27 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:18:27 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:18:28 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:18:28 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:18:28 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:18:28 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:18:28 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:28 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:18:28 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:18:28 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:18:28 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:18:28 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:28 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:18:28 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 26.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:28 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:18:28 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:18:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:18:28 collections:302] Dataset loaded with 3 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:18:28 collections:304] # 3 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 3/3 [00:00<00:00,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:29 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:30 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  7.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:18:30 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:18:30 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:18:30 collections:302] Dataset loaded with 84 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:18:30 collections:304] # 84 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:30 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:18:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:18:30 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:18:30 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:18:30 collections:302] Dataset loaded with 105 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:18:30 collections:304] # 105 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:30 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:18:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:18:30 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:18:30 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:18:30 collections:302] Dataset loaded with 131 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:18:30 collections:304] # 131 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:31 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:18:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:18:31 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:18:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:18:31 collections:302] Dataset loaded with 178 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:18:31 collections:304] # 178 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:31 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:18:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:18:31 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:18:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:18:31 collections:302] Dataset loaded with 271 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:18:31 collections:304] # 271 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  9.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:32 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:32 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:18:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:32 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:18:32 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:18:32 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:18:32 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:18:32 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:18:32 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:18:32 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:18:32 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 42.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:32 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:18:32 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:18:32 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:18:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:32 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:18:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:32 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:18:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:18:32 msdd_models:1431]   \n",
            "    \n",
            "archivo 822671d3fd8d4b468ca3fe67162b0e18_20230610t15_03_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:19:21 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:19:21 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:19:21 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:19:21 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:19:22 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:19:22 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:19:22 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:22 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:19:23 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:19:23 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:19:23 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:19:24 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:19:24 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:19:24 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:19:24 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:19:24 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:19:24 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:19:24 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:24 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:19:24 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:19:24 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:19:24 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:19:24 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:24 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:19:24 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 18.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:24 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:19:24 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:19:24 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:19:24 collections:302] Dataset loaded with 4 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:19:24 collections:304] # 4 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 4/4 [00:00<00:00,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:25 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:27 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  5.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:19:27 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:27 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:19:27 collections:302] Dataset loaded with 153 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-26 04:19:27 collections:304] # 153 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  6.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:27 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:19:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:19:27 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:19:27 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:19:27 collections:302] Dataset loaded with 190 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-26 04:19:27 collections:304] # 190 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  6.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:28 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:19:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:19:28 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:19:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:19:28 collections:302] Dataset loaded with 235 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-26 04:19:28 collections:304] # 235 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:28 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:19:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:19:28 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:19:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:19:28 collections:302] Dataset loaded with 317 items, total duration of  0.06 hours.\n",
            "[NeMo I 2024-08-26 04:19:28 collections:304] # 317 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:29 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:19:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:19:29 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:19:29 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:19:29 collections:302] Dataset loaded with 485 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 04:19:29 collections:304] # 485 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 8/8 [00:00<00:00,  9.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:30 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:30 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:19:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:31 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:19:31 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:19:31 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:19:31 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:19:31 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:19:31 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:19:31 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:19:31 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 25.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:31 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:19:31 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:19:31 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:19:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:31 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:19:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:31 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:19:31 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:19:31 msdd_models:1431]   \n",
            "    \n",
            "archivo 18710ae2ed9842aabdb637eae2a858c1_20230610t16_04_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:20:13 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:20:13 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:20:13 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:20:13 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:20:15 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:20:15 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:20:15 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:15 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:20:16 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:20:17 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:20:17 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:20:18 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:20:18 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:20:18 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:20:18 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:20:18 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:20:18 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:20:18 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:18 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:20:18 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:20:18 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:20:18 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:20:18 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:18 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:20:18 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 33.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:18 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:20:18 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:20:18 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:20:18 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:20:18 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:19 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:19 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 10.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:19 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:20:19 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:20:19 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:20:19 collections:302] Dataset loaded with 69 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:20:19 collections:304] # 69 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:20 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:20:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:20:20 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:20:20 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:20:20 collections:302] Dataset loaded with 86 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:20:20 collections:304] # 86 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:20 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:20:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:20:20 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:20:20 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:20:20 collections:302] Dataset loaded with 107 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:20:20 collections:304] # 107 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:20 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:20:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:20:20 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:20:20 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:20:20 collections:302] Dataset loaded with 145 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:20:20 collections:304] # 145 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  9.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:21 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:20:21 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:20:21 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:20:21 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:20:21 collections:302] Dataset loaded with 223 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:20:21 collections:304] # 223 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  9.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:21 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:22 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:20:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:22 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:20:22 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:20:22 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:20:22 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:20:22 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:20:22 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:20:22 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:20:22 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 44.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:22 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:20:22 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:20:22 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:20:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:22 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:20:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:22 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:20:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:20:22 msdd_models:1431]   \n",
            "    \n",
            "archivo e0913f30a77847f89585f9219bb14dd5_20230610t16_29_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:21:05 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:21:05 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:21:05 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:21:05 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:21:07 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:21:07 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:21:07 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:07 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:21:07 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:21:07 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:21:08 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:21:08 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:21:08 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:21:08 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:21:08 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:21:08 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:21:08 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:21:08 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:08 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:21:09 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:21:09 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:21:09 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:21:09 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:09 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:21:09 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 24.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:09 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:21:09 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:21:09 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:21:09 collections:302] Dataset loaded with 3 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:21:09 collections:304] # 3 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 3/3 [00:00<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:10 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:11 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:11 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:11 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:21:11 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:21:11 collections:302] Dataset loaded with 95 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:21:11 collections:304] # 95 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:12 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:21:12 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:21:12 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:21:12 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:21:12 collections:302] Dataset loaded with 115 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:21:12 collections:304] # 115 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:12 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:21:12 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:12 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:21:12 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:21:12 collections:302] Dataset loaded with 142 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:21:12 collections:304] # 142 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:12 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:21:12 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:21:12 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:21:12 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:21:12 collections:302] Dataset loaded with 189 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:21:12 collections:304] # 189 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  6.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:13 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:21:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:21:13 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:21:13 collections:302] Dataset loaded with 289 items, total duration of  0.04 hours.\n",
            "[NeMo I 2024-08-26 04:21:13 collections:304] # 289 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  7.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:14 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:14 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:21:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:14 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:21:14 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:21:14 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:21:14 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:21:14 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:21:14 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:21:14 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:21:14 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 36.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:14 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:21:14 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:21:14 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:21:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:14 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:21:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:14 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:21:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:14 msdd_models:1431]   \n",
            "    \n",
            "archivo d8363b1bbb1f46579cb66073a1423ad3_20230610t15_06_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:21:56 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:21:56 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:21:56 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:21:56 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:21:57 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:21:57 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:21:57 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:57 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:21:58 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:21:58 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:21:58 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:21:59 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:21:59 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:21:59 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:21:59 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:21:59 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:21:59 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:21:59 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:59 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:21:59 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:21:59 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:21:59 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:21:59 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:59 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:21:59 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 35.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:21:59 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:21:59 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:21:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:21:59 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:21:59 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:00 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:00 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 13.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:00 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:22:00 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:22:00 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:00 collections:302] Dataset loaded with 53 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:00 collections:304] # 53 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:22:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:01 collections:302] Dataset loaded with 63 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:01 collections:304] # 63 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:22:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:01 collections:302] Dataset loaded with 78 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:01 collections:304] # 78 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:22:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:01 collections:302] Dataset loaded with 103 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:01 collections:304] # 103 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:22:01 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:22:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:01 collections:302] Dataset loaded with 156 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:01 collections:304] # 156 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  9.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:02 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:02 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:22:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:02 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:22:02 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:22:02 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:22:02 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:22:02 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:22:02 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:22:02 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:22:02 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 49.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:02 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:22:02 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:22:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:22:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:22:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:22:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:02 msdd_models:1431]   \n",
            "    \n",
            "archivo a8de54e7217b43bf9222236fe3a35143_20230610t15_59_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:22:45 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:22:45 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:22:45 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:22:45 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:22:46 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:22:46 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:22:46 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:46 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:22:46 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:22:47 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:22:47 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:22:47 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:22:47 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:22:47 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:22:47 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:22:48 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:22:48 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:22:48 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:48 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:22:48 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:22:48 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:22:48 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:22:48 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:48 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:22:48 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 38.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:48 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:22:48 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:22:48 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:48 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:48 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  4.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:48 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:49 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:22:49 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:22:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:49 collections:302] Dataset loaded with 51 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:49 collections:304] # 51 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:49 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:22:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:22:49 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:22:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:49 collections:302] Dataset loaded with 64 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:49 collections:304] # 64 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:49 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:22:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:22:49 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:22:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:49 collections:302] Dataset loaded with 79 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:49 collections:304] # 79 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:50 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:22:50 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:22:50 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:22:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:50 collections:302] Dataset loaded with 107 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:50 collections:304] # 107 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:50 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:22:50 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:22:50 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:22:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:22:50 collections:302] Dataset loaded with 166 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:22:50 collections:304] # 166 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:50 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:51 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:22:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:51 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:22:51 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:22:51 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:22:51 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:22:51 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:22:51 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:22:51 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:22:51 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 42.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:51 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:22:51 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:22:51 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:22:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:51 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:22:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:51 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:22:51 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:22:51 msdd_models:1431]   \n",
            "    \n",
            "archivo bab93478e7374a7da7ca383c9090a498_20230610t16_15_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:23:30 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:23:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:23:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:23:30 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:23:32 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:23:32 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:23:32 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:32 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:23:32 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:23:33 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:23:33 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:23:34 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:23:34 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:23:34 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:23:34 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:23:34 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:23:34 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:23:34 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:34 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:23:35 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:23:35 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:23:35 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:23:35 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:35 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:23:35 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 39.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:35 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:23:35 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:23:35 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:23:35 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:23:35 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:35 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 16.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:23:36 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:23:36 collections:302] Dataset loaded with 28 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:23:36 collections:304] # 28 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 10.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:23:36 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:23:36 collections:302] Dataset loaded with 34 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:23:36 collections:304] # 34 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:23:36 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:23:36 collections:302] Dataset loaded with 42 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:23:36 collections:304] # 42 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:23:36 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:23:36 collections:302] Dataset loaded with 57 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:23:36 collections:304] # 57 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:23:36 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:23:36 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:23:36 collections:302] Dataset loaded with 87 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:23:36 collections:304] # 87 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:37 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:37 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:23:37 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:37 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:23:37 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:23:37 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:23:37 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:23:37 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:23:37 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:23:37 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:23:37 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 42.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:37 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:23:37 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:23:37 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:23:37 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:37 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:23:37 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:37 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:23:37 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:23:37 msdd_models:1431]   \n",
            "    \n",
            "archivo 3e389aa8839748e78e57f6eb8ce0812a_20230610t13_55_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:24:36 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:24:36 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:24:36 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:24:36 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:24:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:24:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:24:37 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:24:38 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:24:38 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:24:39 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:24:40 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:24:40 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:24:40 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:24:40 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:24:40 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:24:40 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:24:40 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:40 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:24:40 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:24:40 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:24:40 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:24:40 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:40 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:24:40 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:40 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:24:40 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:24:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:24:40 collections:302] Dataset loaded with 8 items, total duration of  0.10 hours.\n",
            "[NeMo I 2024-08-26 04:24:40 collections:304] # 8 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 8/8 [00:02<00:00,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:42 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:45 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:24:46 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:24:46 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:24:46 collections:302] Dataset loaded with 332 items, total duration of  0.12 hours.\n",
            "[NeMo I 2024-08-26 04:24:46 collections:304] # 332 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  6.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:47 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:24:47 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:24:47 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:24:47 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:24:47 collections:302] Dataset loaded with 407 items, total duration of  0.13 hours.\n",
            "[NeMo I 2024-08-26 04:24:47 collections:304] # 407 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:48 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:24:48 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:24:48 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:24:48 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:24:48 collections:302] Dataset loaded with 506 items, total duration of  0.13 hours.\n",
            "[NeMo I 2024-08-26 04:24:48 collections:304] # 506 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 8/8 [00:01<00:00,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:49 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:24:49 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:49 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:24:49 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:24:49 collections:302] Dataset loaded with 687 items, total duration of  0.14 hours.\n",
            "[NeMo I 2024-08-26 04:24:49 collections:304] # 687 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[4/5] extract embeddings: 100%|██████████| 11/11 [00:01<00:00,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:51 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:24:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:51 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:24:51 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:24:51 collections:302] Dataset loaded with 1047 items, total duration of  0.14 hours.\n",
            "[NeMo I 2024-08-26 04:24:51 collections:304] # 1047 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 17/17 [00:02<00:00,  8.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:53 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:54 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:24:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:54 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:24:54 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:24:54 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:24:54 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:24:54 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:24:54 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:24:54 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:24:54 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 15.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:54 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:24:54 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:24:54 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:24:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:54 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:24:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:54 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:24:54 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:24:54 msdd_models:1431]   \n",
            "    \n",
            "archivo f332b3326cb34bddb0989e865a5831e4_20230610t14_13_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:25:35 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:25:35 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:25:35 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:25:35 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:25:37 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:25:37 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:25:37 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:25:37 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:25:38 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:25:38 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:25:38 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:25:38 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:25:38 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:25:38 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:25:39 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:25:39 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:25:39 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:39 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:25:39 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:25:39 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:25:39 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:25:39 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:39 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:25:39 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 44.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:39 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:25:39 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:25:39 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:25:39 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:25:39 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:39 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 18.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:25:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:25:40 collections:302] Dataset loaded with 43 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:25:40 collections:304] # 43 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:25:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:25:40 collections:302] Dataset loaded with 55 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:25:40 collections:304] # 55 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:25:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:25:40 collections:302] Dataset loaded with 69 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:25:40 collections:304] # 69 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:25:40 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:25:40 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:25:40 collections:302] Dataset loaded with 93 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:25:40 collections:304] # 93 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:25:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:25:41 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:25:41 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:25:41 collections:302] Dataset loaded with 141 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:25:41 collections:304] # 141 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00, 10.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:41 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:25:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:41 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:25:41 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:25:41 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:25:41 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:25:41 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:25:41 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:25:41 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:25:41 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 38.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:41 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:25:41 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:25:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:25:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:25:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:41 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:25:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:25:41 msdd_models:1431]   \n",
            "    \n",
            "archivo e56abe4fb3ae4c0cbc1b1cdfc8d80cb3_20230610t15_15_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:26:23 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:26:23 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:26:23 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:26:23 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:26:24 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:26:24 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:26:24 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:24 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:26:25 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:26:25 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:26:25 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:26:26 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:26:26 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:26:26 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:26:26 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:26:26 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:26:26 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:26:26 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:26 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:26:26 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:26:26 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:26:26 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:26:26 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:26 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:26:26 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 36.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:26 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:26:26 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:26:26 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:26:26 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:26:26 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:27 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:27 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 12.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:26:28 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:26:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:26:28 collections:302] Dataset loaded with 67 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:26:28 collections:304] # 67 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:28 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:26:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:26:28 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:26:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:26:28 collections:302] Dataset loaded with 82 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:26:28 collections:304] # 82 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:28 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:26:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:26:28 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:26:28 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:26:28 collections:302] Dataset loaded with 101 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:26:28 collections:304] # 101 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  5.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:29 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:26:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:26:29 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:26:29 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:26:29 collections:302] Dataset loaded with 138 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:26:29 collections:304] # 138 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:29 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:26:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:26:29 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:26:29 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:26:29 collections:302] Dataset loaded with 206 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:26:29 collections:304] # 206 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:29 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:30 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:26:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:30 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:26:30 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:26:30 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:26:30 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:26:30 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:26:30 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:26:30 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:26:30 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 46.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:30 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:26:30 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:26:30 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:26:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:30 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:26:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:30 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:26:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:26:30 msdd_models:1431]   \n",
            "    \n",
            "archivo bdc1679b294f4d60844c566fef78c4c8_20230610t16_16_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:27:08 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:27:08 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:27:08 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:27:08 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:27:10 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:27:10 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:27:10 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:10 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:27:10 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:27:11 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:27:11 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:27:12 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:27:12 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:27:12 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:27:12 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:27:12 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:27:12 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:27:12 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:12 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:27:12 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:27:13 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:27:13 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:27:13 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:13 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:27:13 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 51.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:13 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:27:13 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:27:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:27:13 collections:302] Dataset loaded with 1 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:27:13 collections:304] # 1 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:13 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:13 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 25.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:27:13 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:27:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:27:13 collections:302] Dataset loaded with 20 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:27:13 collections:304] # 20 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:13 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:27:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:27:13 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:27:13 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:27:13 collections:302] Dataset loaded with 24 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:27:13 collections:304] # 24 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 10.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:27:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:27:14 collections:302] Dataset loaded with 31 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:27:14 collections:304] # 31 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:27:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:27:14 collections:302] Dataset loaded with 39 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:27:14 collections:304] # 39 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:27:14 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:27:14 collections:302] Dataset loaded with 62 items, total duration of  0.01 hours.\n",
            "[NeMo I 2024-08-26 04:27:14 collections:304] # 62 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:27:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:27:14 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:27:14 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:27:14 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:27:14 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:27:14 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:27:14 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:27:14 collections:620] Total 28 session files loaded accounting to # 28 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 15.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:27:14 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:27:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:27:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:27:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:14 msdd_models:1431]   \n",
            "    \n",
            "archivo 2bf1748f6df24d4494ad8a137f33ed77_20230610t15_22_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:27:56 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:27:56 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:27:56 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:27:56 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:27:57 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:27:57 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:27:57 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:57 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:27:57 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:27:58 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:27:58 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:27:59 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:27:59 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:27:59 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:27:59 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:27:59 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:27:59 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:27:59 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:59 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:27:59 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:27:59 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:27:59 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:27:59 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:59 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:27:59 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 32.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:27:59 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:27:59 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:27:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:27:59 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:27:59 collections:304] # 2 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 2/2 [00:00<00:00,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:00 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:00 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:00 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:28:00 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:28:00 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:28:00 collections:302] Dataset loaded with 56 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:28:00 collections:304] # 56 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  5.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:343] Extracting embeddings for Diarization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:28:01 collections:302] Dataset loaded with 70 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:28:01 collections:304] # 70 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:28:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:28:01 collections:302] Dataset loaded with 88 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:28:01 collections:304] # 88 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  9.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:28:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:28:01 collections:302] Dataset loaded with 121 items, total duration of  0.02 hours.\n",
            "[NeMo I 2024-08-26 04:28:01 collections:304] # 121 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:28:01 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:28:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:28:01 collections:302] Dataset loaded with 185 items, total duration of  0.03 hours.\n",
            "[NeMo I 2024-08-26 04:28:01 collections:304] # 185 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:02 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:02 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:28:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:02 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:28:02 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:28:02 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:28:02 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:28:02 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:28:02 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:28:02 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:28:02 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 30.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:02 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:28:02 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:28:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:28:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:28:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:02 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:28:02 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:02 msdd_models:1431]   \n",
            "    \n",
            "archivo 60e1b8f07eb844c8b7014251b86ecea1_20230610t13_35_utc.wav listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No language specified, language will be first be detected for each audio file (increases inference time).\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.0.1+cu117. Bad things might happen unless you revert torch to 1.x.\n",
            "Suppressing numeral and symbol tokens: [3, 4, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 502, 568, 628, 805, 945, 1017, 1025, 1266, 1294, 1360, 1386, 1525, 1614, 1649, 1722, 1848, 1958, 2009, 2119, 2217, 2272, 2319, 2331, 2443, 2625, 2803, 2975, 3165, 3279, 3282, 3356, 3405, 3446, 3499, 3552, 3705, 4022, 4060, 4289, 4303, 4436, 4550, 4688, 4702, 4762, 4808, 5080, 5211, 5254, 5285, 5348, 5853, 5867, 5923, 6071, 6074, 6096, 6375, 6494, 6549, 6591, 6641, 6673, 6856, 6866, 6879, 6905, 6976, 7143, 7201, 7271, 7490, 7526, 7546, 7551, 7560, 7562, 7629, 7634, 7668, 7771, 7773, 7911, 7998, 8132, 8227, 8423, 8451, 8465, 8494, 8652, 8794, 8858, 8923, 9012, 9125, 9356, 9413, 9562, 9657, 9714, 9754, 10076, 10154, 10191, 10353, 10389, 10411, 10607, 10858, 10880, 11174, 11205, 11309, 11440, 11453, 11592, 11624, 11650, 11803, 11816, 11849, 11871, 11901, 11971, 12145, 12249, 12330, 12493, 12566, 12625, 12656, 12756, 12790, 12791, 12843, 12851, 12967, 13083, 13318, 13328, 13384, 13420, 13435, 13622, 13626, 13711, 13741, 13811, 13898, 13912, 14034, 14060, 14062, 14189, 14378, 14394, 14423, 14565, 14577, 14695, 14938, 15204, 15237, 15238, 15628, 15707, 15718, 15817, 16133, 16157, 16169, 16231, 16382, 16408, 16416, 16513, 16824, 16919, 16953, 17201, 17344, 17512, 17602, 17822, 17835, 17914, 18065, 18079, 18141, 18173, 18197, 18317, 18485, 18682, 18731, 19004, 19287, 19395, 19563, 19584, 19600, 19687, 19952, 19966, 20120, 20154, 20229, 20419, 20793, 20860, 20984, 21055, 21115, 21126, 21199, 21243, 21404, 21423, 21548, 21786, 21821, 21860, 22003, 22016, 22046, 22193, 22350, 22383, 22427, 22452, 22516, 22601, 22671, 22690, 22736, 22962, 23095, 23185, 23247, 23317, 23399, 23538, 23777, 23853, 23879, 23943, 23952, 24097, 24124, 24158, 24327, 24536, 24547, 24587, 24624, 24733, 25026, 25082, 25137, 25276, 25494, 25546, 25743, 26034, 26369, 26372, 26687, 26837, 26901, 27032, 27102, 27127, 27228, 27816, 27895, 27990, 28052, 28225, 28253, 28267, 28294, 28387, 28638, 28829, 28868, 28876, 28890, 28898, 28962, 29008, 29018, 29097, 29139, 29387, 29491, 29810, 29925, 29930, 29985, 30595, 30620, 30693, 30827, 30849, 30908, 30942, 30997, 31064, 31104, 31352, 31537, 31682, 31758, 31849, 31877, 32042, 32090, 32454, 32803, 32848, 32875, 32952, 33117, 33191, 33193, 33202, 33396, 33422, 33530, 33705, 33809, 33978, 34026, 34099, 34314, 34466, 34578, 35016, 35023, 35092, 35133, 35311, 35364, 36027, 36588, 36885, 37078, 37202, 37510, 37549, 37609, 37785, 38308, 38566, 38698, 38833, 38882, 38987, 39157, 39209, 39436, 39498, 40402, 40417, 40774, 40881, 41103, 41165, 41171, 41229, 41342, 41720, 41789, 42429, 42438, 42514, 42652, 42692, 42757, 43160, 43373, 43435, 43677, 44158, 44377, 44557, 44624, 45131, 45218, 45237, 45374, 45396, 45608, 45835, 45868, 45937, 46062, 46081, 46256, 46379, 46398, 46476, 46484, 46590, 46795, 46881, 47520, 47561, 47725, 47757, 48156, 48390, 48528, 48729, 48784, 48804, 48957, 49017, 49167, 49258, 50022]\n",
            "[NeMo I 2024-08-26 04:28:51 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
            "[NeMo I 2024-08-26 04:28:51 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:28:51 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
            "[NeMo I 2024-08-26 04:28:51 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:28:53 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:28:53 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    \n",
            "[NeMo W 2024-08-26 04:28:53 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    emb_dir: null\n",
            "    sample_rate: 16000\n",
            "    num_spks: 2\n",
            "    soft_label_thres: 0.5\n",
            "    labels: null\n",
            "    batch_size: 15\n",
            "    emb_batch_size: 0\n",
            "    shuffle: false\n",
            "    seq_eval_mode: false\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:53 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:28:53 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:28:54 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
            "[NeMo I 2024-08-26 04:28:54 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:28:54 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
            "[NeMo I 2024-08-26 04:28:54 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:28:54 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
            "[NeMo I 2024-08-26 04:28:54 common:913] Instantiating model from pre-trained checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:28:54 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: true\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    tarred_shard_strategy: scatter\n",
            "    augmentor:\n",
            "      shift:\n",
            "        prob: 0.5\n",
            "        min_shift_ms: -10.0\n",
            "        max_shift_ms: 10.0\n",
            "      white_noise:\n",
            "        prob: 0.5\n",
            "        min_level: -90\n",
            "        max_level: -46\n",
            "        norm: true\n",
            "      noise:\n",
            "        prob: 0.5\n",
            "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
            "        min_snr_db: 0\n",
            "        max_snr_db: 30\n",
            "        max_gain_db: 300.0\n",
            "        norm: true\n",
            "      gain:\n",
            "        prob: 0.5\n",
            "        min_gain_dbfs: -10.0\n",
            "        max_gain_dbfs: 10.0\n",
            "        norm: true\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:28:54 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 256\n",
            "    shuffle: false\n",
            "    val_loss_idx: 0\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2024-08-26 04:28:54 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    labels:\n",
            "    - background\n",
            "    - speech\n",
            "    batch_size: 128\n",
            "    shuffle: false\n",
            "    test_loss_idx: 0\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:54 features:289] PADDING: 16\n",
            "[NeMo I 2024-08-26 04:28:55 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.21.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
            "[NeMo I 2024-08-26 04:28:55 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
            "[NeMo I 2024-08-26 04:28:55 msdd_models:865] Clustering Parameters: {\n",
            "        \"oracle_num_speakers\": false,\n",
            "        \"max_num_speakers\": 8,\n",
            "        \"enhanced_count_thres\": 80,\n",
            "        \"max_rp_threshold\": 0.25,\n",
            "        \"sparse_search_volume\": 30,\n",
            "        \"maj_vote_spk_count\": false,\n",
            "        \"chunk_cluster_count\": 50,\n",
            "        \"embeddings_per_chunk\": 10000\n",
            "    }\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:28:55 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:55 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:28:55 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:55 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
            "[NeMo I 2024-08-26 04:28:55 classification_models:273] Perform streaming frame-level VAD\n",
            "[NeMo I 2024-08-26 04:28:55 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:28:55 collections:302] Dataset loaded with 4 items, total duration of  0.05 hours.\n",
            "[NeMo I 2024-08-26 04:28:55 collections:304] # 4 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "vad: 100%|██████████| 4/4 [00:01<00:00,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:56 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:57 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
            "[NeMo I 2024-08-26 04:28:58 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:28:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:28:58 collections:302] Dataset loaded with 185 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 04:28:58 collections:304] # 185 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[1/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:58 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:28:58 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
            "[NeMo I 2024-08-26 04:28:58 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:28:58 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:28:58 collections:302] Dataset loaded with 222 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 04:28:58 collections:304] # 222 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:28:59 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:28:59 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
            "[NeMo I 2024-08-26 04:28:59 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:28:59 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:28:59 collections:302] Dataset loaded with 277 items, total duration of  0.07 hours.\n",
            "[NeMo I 2024-08-26 04:28:59 collections:304] # 277 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:29:00 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:29:00 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
            "[NeMo I 2024-08-26 04:29:00 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:29:00 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
            "[NeMo I 2024-08-26 04:29:00 collections:302] Dataset loaded with 379 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 04:29:00 collections:304] # 379 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[4/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  6.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:29:01 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n",
            "[NeMo I 2024-08-26 04:29:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
            "[NeMo I 2024-08-26 04:29:01 clustering_diarizer:343] Extracting embeddings for Diarization\n",
            "[NeMo I 2024-08-26 04:29:01 collections:301] Filtered duration for loading collection is  0.00 hours.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:29:01 collections:302] Dataset loaded with 574 items, total duration of  0.08 hours.\n",
            "[NeMo I 2024-08-26 04:29:01 collections:304] # 574 files loaded accounting to # 1 labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[5/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:29:02 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:29:03 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:29:03 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:29:03 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:29:03 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:29:03 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:29:03 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:29:03 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
            "[NeMo I 2024-08-26 04:29:03 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
            "[NeMo I 2024-08-26 04:29:03 collections:617] Filtered duration for loading collection is 0.000000.\n",
            "[NeMo I 2024-08-26 04:29:03 collections:620] Total 3 session files loaded accounting to # 3 audio clips\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:29:03 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
            "[NeMo I 2024-08-26 04:29:03 speaker_utils:93] Number of files to diarize: 1\n",
            "[NeMo I 2024-08-26 04:29:03 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[NeMo W 2024-08-26 04:29:03 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:29:03 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:29:03 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:29:03 speaker_utils:93] Number of files to diarize: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2024-08-26 04:29:03 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2024-08-26 04:29:03 msdd_models:1431]   \n",
            "    \n",
            "archivo 2debb7328d994ecdb89a0a7afd03cb2e_20230610t16_57_utc.wav listo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Limpieza Cache\n",
        "import gc\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Xin0kox6gQq",
        "outputId": "d7393856-af90-4cd3-aa5e-0171d6672c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30686"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YvJ3VVUOv14T",
        "jbsUt3SwyhjD",
        "B7qWQb--1Xcw",
        "7ZS4xXmE2NGP",
        "UYg9VWb22Tz8",
        "uRJFzumCxd-I",
        "7EEaJPsQ21Rx",
        "D1gkViCf2-CV",
        "NmkZYaDAEOAg",
        "8Ruxc8S1EXtW"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7804b32e55784165abad6e91ce95253a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00b0ded93cec4ea2897261ae0b81c98a",
              "IPY_MODEL_739ad7ba6b9f4719b1e099890eeb0fc2",
              "IPY_MODEL_ca018c1daefe4aecb390bb76f87f0a28"
            ],
            "layout": "IPY_MODEL_ea53fd9f9564421e95d837ac1585ad56"
          }
        },
        "00b0ded93cec4ea2897261ae0b81c98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0463281965614b818900fca48032ba30",
            "placeholder": "​",
            "style": "IPY_MODEL_396328b5d96d438082e99a7922328573",
            "value": "config.json: 100%"
          }
        },
        "739ad7ba6b9f4719b1e099890eeb0fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cc829ae815d4595875c33e294dad8eb",
            "max": 914,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ba6f81e0be74a529b35bf279fa619d4",
            "value": 914
          }
        },
        "ca018c1daefe4aecb390bb76f87f0a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7fba5eecb974ab39fef405abd56d442",
            "placeholder": "​",
            "style": "IPY_MODEL_0512760b3c574326bd26914bd9fb0dd9",
            "value": " 914/914 [00:00&lt;00:00, 22.5kB/s]"
          }
        },
        "ea53fd9f9564421e95d837ac1585ad56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0463281965614b818900fca48032ba30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396328b5d96d438082e99a7922328573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cc829ae815d4595875c33e294dad8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba6f81e0be74a529b35bf279fa619d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7fba5eecb974ab39fef405abd56d442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0512760b3c574326bd26914bd9fb0dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a28b47772b94fd78de612a3e027b96c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffed692863bd40408a5dd1a27b57d97a",
              "IPY_MODEL_f7105121e9bb42eb8f4073751f73be0c",
              "IPY_MODEL_716cdd2d4f4e40e2be07a73a322e62b2"
            ],
            "layout": "IPY_MODEL_79526b987072410b91d18c77884796bd"
          }
        },
        "ffed692863bd40408a5dd1a27b57d97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f9a8856d3249e39e04b2bada2a0224",
            "placeholder": "​",
            "style": "IPY_MODEL_a2d982fbca7d4e3b88982ec785fe43c9",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "f7105121e9bb42eb8f4073751f73be0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92f29d594e3d4debb7fad47a18d0ff2f",
            "max": 1109901745,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1da3c50f534741f1a9a8d7c06d3e1122",
            "value": 1109901745
          }
        },
        "716cdd2d4f4e40e2be07a73a322e62b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db81cd424253471e9c32dbddc2717bed",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa6d016c6a94c4e96781e52d2cb394e",
            "value": " 1.11G/1.11G [00:10&lt;00:00, 56.2MB/s]"
          }
        },
        "79526b987072410b91d18c77884796bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f9a8856d3249e39e04b2bada2a0224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d982fbca7d4e3b88982ec785fe43c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92f29d594e3d4debb7fad47a18d0ff2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da3c50f534741f1a9a8d7c06d3e1122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db81cd424253471e9c32dbddc2717bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa6d016c6a94c4e96781e52d2cb394e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b65741d2ebb94003b1cf2c12d04f3d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eef8f13c3aba43fdbdf9857de7ef2209",
              "IPY_MODEL_0d2387bfe4014a359e3b4142bc839f1a",
              "IPY_MODEL_3dd938d27ef34150b30f185f7a31dc92"
            ],
            "layout": "IPY_MODEL_5d8699facbf94132bc45922c6f5adaba"
          }
        },
        "eef8f13c3aba43fdbdf9857de7ef2209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fcb9cbf37bb42fab8c63f52179a84ad",
            "placeholder": "​",
            "style": "IPY_MODEL_5ba2024463b5403894df8de9ec907523",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0d2387bfe4014a359e3b4142bc839f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ca0bae6bb74bbf89f6891193f3070a",
            "max": 447,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca48d213dbcc43faa408b1506614d899",
            "value": 447
          }
        },
        "3dd938d27ef34150b30f185f7a31dc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd2dbf24ec3f4f74a638adc330b502b5",
            "placeholder": "​",
            "style": "IPY_MODEL_ffcdcddd045b4018bda632292f034a09",
            "value": " 447/447 [00:00&lt;00:00, 17.6kB/s]"
          }
        },
        "5d8699facbf94132bc45922c6f5adaba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fcb9cbf37bb42fab8c63f52179a84ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ba2024463b5403894df8de9ec907523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9ca0bae6bb74bbf89f6891193f3070a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca48d213dbcc43faa408b1506614d899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd2dbf24ec3f4f74a638adc330b502b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffcdcddd045b4018bda632292f034a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d27f1f1b1d9b438a8a90fd63f9052eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1723cd4ca07147a6ab8f8116906efbdc",
              "IPY_MODEL_d134d5df4e3f4f919bdb7afe86a83cca",
              "IPY_MODEL_7b23caa1446e43088e6e6a0e5cf9eca8"
            ],
            "layout": "IPY_MODEL_d13ae54a0f8d4b00b660477d81c3f668"
          }
        },
        "1723cd4ca07147a6ab8f8116906efbdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b60fe8c182544d31b3c39885f7da6b8c",
            "placeholder": "​",
            "style": "IPY_MODEL_1b1c28f6fddd442cb4aa3f3b29f702c2",
            "value": "tokenizer.json: 100%"
          }
        },
        "d134d5df4e3f4f919bdb7afe86a83cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c790466c8b46c6abfee5dc257b78df",
            "max": 17082758,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b2a130378794e4d9f3834f836620523",
            "value": 17082758
          }
        },
        "7b23caa1446e43088e6e6a0e5cf9eca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f81e123bcbb845ba8fbb998dfc1cd084",
            "placeholder": "​",
            "style": "IPY_MODEL_8822166341414125b16ecc6cf6040fb7",
            "value": " 17.1M/17.1M [00:00&lt;00:00, 37.1MB/s]"
          }
        },
        "d13ae54a0f8d4b00b660477d81c3f668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b60fe8c182544d31b3c39885f7da6b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1c28f6fddd442cb4aa3f3b29f702c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64c790466c8b46c6abfee5dc257b78df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2a130378794e4d9f3834f836620523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f81e123bcbb845ba8fbb998dfc1cd084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8822166341414125b16ecc6cf6040fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8cb6f24f910452d9d062ed2e7892253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17023a4f10dc4df6a56975bdb616cd48",
              "IPY_MODEL_498ae801f830431c8322138e22a4e4b1",
              "IPY_MODEL_56164122d8464606b126f7f7dffea1b1"
            ],
            "layout": "IPY_MODEL_79dc6ad0078e46b1ae565f1c1fcff10c"
          }
        },
        "17023a4f10dc4df6a56975bdb616cd48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61392568360b42629762d61a445975a1",
            "placeholder": "​",
            "style": "IPY_MODEL_fccaee18ec824375ad1e552701373a5f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "498ae801f830431c8322138e22a4e4b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ade71e71e094619a856dfe37b6de8cc",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2302fc381f15427e9c1f560832e61b36",
            "value": 239
          }
        },
        "56164122d8464606b126f7f7dffea1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed1713926d954eec99197ca70af91953",
            "placeholder": "​",
            "style": "IPY_MODEL_871a115d294e45288cf45153d4156677",
            "value": " 239/239 [00:00&lt;00:00, 7.54kB/s]"
          }
        },
        "79dc6ad0078e46b1ae565f1c1fcff10c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61392568360b42629762d61a445975a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fccaee18ec824375ad1e552701373a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ade71e71e094619a856dfe37b6de8cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2302fc381f15427e9c1f560832e61b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed1713926d954eec99197ca70af91953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871a115d294e45288cf45153d4156677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "404e2ec0ab7a4735bcc96a2719847ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03bdc159423046fe9ea83676b03674bc",
              "IPY_MODEL_d977aa1edeaf43849a4072a2487679d2",
              "IPY_MODEL_56c75c10f38a4fd79b1cc5ca83881ccd"
            ],
            "layout": "IPY_MODEL_3a760dae306743f88c54a783119ea105"
          }
        },
        "03bdc159423046fe9ea83676b03674bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d03e56025add4853aeaf6e4e93c940ab",
            "placeholder": "​",
            "style": "IPY_MODEL_37f013907f4842e585723ba74d289791",
            "value": "model.bin: 100%"
          }
        },
        "d977aa1edeaf43849a4072a2487679d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b895d698e40e4c34bd8221086e5c5d0e",
            "max": 3087284237,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ec20086a8d54e9a81495555059c8c3a",
            "value": 3087284237
          }
        },
        "56c75c10f38a4fd79b1cc5ca83881ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26306b99c8eb404d9cbd9f41741dde45",
            "placeholder": "​",
            "style": "IPY_MODEL_c43c41c7d8fa4a6ab2d035471786174d",
            "value": " 3.09G/3.09G [00:21&lt;00:00, 231MB/s]"
          }
        },
        "3a760dae306743f88c54a783119ea105": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d03e56025add4853aeaf6e4e93c940ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37f013907f4842e585723ba74d289791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b895d698e40e4c34bd8221086e5c5d0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec20086a8d54e9a81495555059c8c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26306b99c8eb404d9cbd9f41741dde45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43c41c7d8fa4a6ab2d035471786174d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf43b48196694150bd31218bbb2e8050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e955d5489d1045c8af56a48077ee1b37",
              "IPY_MODEL_0d018eddf87c4f35a70aeb7327ec8511",
              "IPY_MODEL_98da45b17a064156b0393ae868317bd4"
            ],
            "layout": "IPY_MODEL_0aaa63999115472095e0ea060ec269f1"
          }
        },
        "e955d5489d1045c8af56a48077ee1b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_710e0b80643a4fad9214c1f63591c208",
            "placeholder": "​",
            "style": "IPY_MODEL_b7b3baa2828443b8a6fa2886500e1461",
            "value": "config.json: 100%"
          }
        },
        "0d018eddf87c4f35a70aeb7327ec8511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b080a7f09fe4ddbad3260f5e2a89b70",
            "max": 2394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1359cdd249164b80966011d94dafd635",
            "value": 2394
          }
        },
        "98da45b17a064156b0393ae868317bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1625f7d161df4655b9c61e6123f4c7cb",
            "placeholder": "​",
            "style": "IPY_MODEL_56a15dc4ed744567891d84006197bf4b",
            "value": " 2.39k/2.39k [00:00&lt;00:00, 32.4kB/s]"
          }
        },
        "0aaa63999115472095e0ea060ec269f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710e0b80643a4fad9214c1f63591c208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b3baa2828443b8a6fa2886500e1461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b080a7f09fe4ddbad3260f5e2a89b70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1359cdd249164b80966011d94dafd635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1625f7d161df4655b9c61e6123f4c7cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a15dc4ed744567891d84006197bf4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51532465ae3b4c21a15b2b77e6d3a308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a393836591408593488fbbb1440642",
              "IPY_MODEL_b1baa9617f514b96ada539a7079814da",
              "IPY_MODEL_e69a66fefa104ab88a5801c26d3616b8"
            ],
            "layout": "IPY_MODEL_ed2fd1f4a8504b3699c8cd51c3aa1ed9"
          }
        },
        "f4a393836591408593488fbbb1440642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_130b28c42cb74ce598eeef23dd3baf5a",
            "placeholder": "​",
            "style": "IPY_MODEL_93b10363791e4899a866413ab3aedb28",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "b1baa9617f514b96ada539a7079814da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df02a4048b8d4274a3dbfc999e9e8749",
            "max": 340,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7bde9c865084a1aa33fc9a05f8d3917",
            "value": 340
          }
        },
        "e69a66fefa104ab88a5801c26d3616b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfc6fa9504554c58967b2797af760309",
            "placeholder": "​",
            "style": "IPY_MODEL_ac9b55a4ce094b279a6433b5335c6180",
            "value": " 340/340 [00:00&lt;00:00, 4.93kB/s]"
          }
        },
        "ed2fd1f4a8504b3699c8cd51c3aa1ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130b28c42cb74ce598eeef23dd3baf5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93b10363791e4899a866413ab3aedb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df02a4048b8d4274a3dbfc999e9e8749": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7bde9c865084a1aa33fc9a05f8d3917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfc6fa9504554c58967b2797af760309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac9b55a4ce094b279a6433b5335c6180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22b50ee6f06d41edb84bfebea77dc54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b810d094b25a47fdb381d227be509971",
              "IPY_MODEL_22b701e82dd1405398eea537504970fe",
              "IPY_MODEL_a3b6729348304d8e9d4533aebec15743"
            ],
            "layout": "IPY_MODEL_443ddfad0e3f4b66bf5543e5d06a3c77"
          }
        },
        "b810d094b25a47fdb381d227be509971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54d448873108423c8d42edda401dc4c7",
            "placeholder": "​",
            "style": "IPY_MODEL_ffaa0d3154114b439ed4a2feab7cee35",
            "value": "tokenizer.json: 100%"
          }
        },
        "22b701e82dd1405398eea537504970fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87668cc97443484fa8c7f4e7167ff68c",
            "max": 2480617,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc384ba284d8430889e26d19290cdc6b",
            "value": 2480617
          }
        },
        "a3b6729348304d8e9d4533aebec15743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3e06b166a3e48adb7e5cdfa5e956dd9",
            "placeholder": "​",
            "style": "IPY_MODEL_649234e51c9249fcb77390136f235037",
            "value": " 2.48M/2.48M [00:00&lt;00:00, 10.9MB/s]"
          }
        },
        "443ddfad0e3f4b66bf5543e5d06a3c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d448873108423c8d42edda401dc4c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffaa0d3154114b439ed4a2feab7cee35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87668cc97443484fa8c7f4e7167ff68c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc384ba284d8430889e26d19290cdc6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3e06b166a3e48adb7e5cdfa5e956dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "649234e51c9249fcb77390136f235037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82ce3db711bb4df694f509bc89f79814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_524002c6ccb54322becee70596b2e838",
              "IPY_MODEL_ab2ada9c47ef4ea9a2b04127e4b58a5f",
              "IPY_MODEL_7cfe5eeaa38640969b0e16847082caaa"
            ],
            "layout": "IPY_MODEL_040e908918ac43edab2d2cdef6b1b9c4"
          }
        },
        "524002c6ccb54322becee70596b2e838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_548b57f056e841549e976b0eb88bb0e1",
            "placeholder": "​",
            "style": "IPY_MODEL_d84d953ace7e4176ab746e58a53841bb",
            "value": "vocabulary.json: 100%"
          }
        },
        "ab2ada9c47ef4ea9a2b04127e4b58a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29434cb665814faea734403aaa925fc3",
            "max": 1068114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b1a4eec8ccb4c5aada1c97a2f568ae3",
            "value": 1068114
          }
        },
        "7cfe5eeaa38640969b0e16847082caaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c76cfab2d6d47c2809119591b0f8d07",
            "placeholder": "​",
            "style": "IPY_MODEL_4d60bd791af24538a8d5b6cdec7a82ea",
            "value": " 1.07M/1.07M [00:00&lt;00:00, 4.80MB/s]"
          }
        },
        "040e908918ac43edab2d2cdef6b1b9c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "548b57f056e841549e976b0eb88bb0e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84d953ace7e4176ab746e58a53841bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29434cb665814faea734403aaa925fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1a4eec8ccb4c5aada1c97a2f568ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c76cfab2d6d47c2809119591b0f8d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d60bd791af24538a8d5b6cdec7a82ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7920268bb17e4e439f744deeab57ac3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d76b4e2020c4032a79e9f0629691e74",
              "IPY_MODEL_668120239829440da2f0863d564e221e",
              "IPY_MODEL_3a73f7cfc0f9471d93a3ef93fc712d80"
            ],
            "layout": "IPY_MODEL_4716eda28a4e40508ca05f1e6d25e25f"
          }
        },
        "2d76b4e2020c4032a79e9f0629691e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afa66ee52ebc419985e0d64f92f83ef3",
            "placeholder": "​",
            "style": "IPY_MODEL_394c109011764391996453cb55d76740",
            "value": "model.bin: 100%"
          }
        },
        "668120239829440da2f0863d564e221e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74943f0c603c47db836dab716bc72947",
            "max": 3087284237,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_608c5af1b34f4d4dba18ef38b1a5f1cb",
            "value": 3087284237
          }
        },
        "3a73f7cfc0f9471d93a3ef93fc712d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abf464d9128d49b79ae4569e9eb516e3",
            "placeholder": "​",
            "style": "IPY_MODEL_453778a8c3234e52bc9572ea4ae69f4d",
            "value": " 3.09G/3.09G [00:15&lt;00:00, 178MB/s]"
          }
        },
        "4716eda28a4e40508ca05f1e6d25e25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afa66ee52ebc419985e0d64f92f83ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394c109011764391996453cb55d76740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74943f0c603c47db836dab716bc72947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608c5af1b34f4d4dba18ef38b1a5f1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abf464d9128d49b79ae4569e9eb516e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "453778a8c3234e52bc9572ea4ae69f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5462145b917949979d5c5a4ac2eaaf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc4a91cc35244cf59327dacea1e32fbe",
              "IPY_MODEL_c5bcf01e5cb04973b4ac7b5c57034517",
              "IPY_MODEL_4cf873db3db044bd986b811ca2568673"
            ],
            "layout": "IPY_MODEL_3b0f8876ee054d68914763be73910284"
          }
        },
        "dc4a91cc35244cf59327dacea1e32fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79797638ba364a1c9f32f7f23be6d767",
            "placeholder": "​",
            "style": "IPY_MODEL_791fc496bd7f46408b392de5171c2c92",
            "value": "config.json: 100%"
          }
        },
        "c5bcf01e5cb04973b4ac7b5c57034517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_838c150755034f7da1d47ac72a47c473",
            "max": 2394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c356bdd6ea646fda453d543c3527c5b",
            "value": 2394
          }
        },
        "4cf873db3db044bd986b811ca2568673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4a90ba4e5254f419babdcd280f96d26",
            "placeholder": "​",
            "style": "IPY_MODEL_4f9de3e2aa9e40c88a86974324d1f15e",
            "value": " 2.39k/2.39k [00:00&lt;00:00, 34.2kB/s]"
          }
        },
        "3b0f8876ee054d68914763be73910284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79797638ba364a1c9f32f7f23be6d767": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "791fc496bd7f46408b392de5171c2c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "838c150755034f7da1d47ac72a47c473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c356bdd6ea646fda453d543c3527c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4a90ba4e5254f419babdcd280f96d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9de3e2aa9e40c88a86974324d1f15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8f7b41eecc34c58ab0e20b04d367a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8ea5b82b8d5489dad6498144f277910",
              "IPY_MODEL_4f05a9322f1b4139991fc596513d387a",
              "IPY_MODEL_cc7f7e4bc80645879c64ef2b81764f4c"
            ],
            "layout": "IPY_MODEL_80d75918bed04847ae607e752111f49d"
          }
        },
        "a8ea5b82b8d5489dad6498144f277910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58316d0d1ad246e59c328d7a197dada2",
            "placeholder": "​",
            "style": "IPY_MODEL_fd8e91964bbd4d118601f2c4204d1a4f",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "4f05a9322f1b4139991fc596513d387a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc77f9333077442bba1c6807d6a38f8e",
            "max": 340,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_332c6170b74c45a79778da0ff95bed16",
            "value": 340
          }
        },
        "cc7f7e4bc80645879c64ef2b81764f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61d45f8442604f259361aab962db0ebb",
            "placeholder": "​",
            "style": "IPY_MODEL_658dc48718e74dde94f2845839aee494",
            "value": " 340/340 [00:00&lt;00:00, 3.29kB/s]"
          }
        },
        "80d75918bed04847ae607e752111f49d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58316d0d1ad246e59c328d7a197dada2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8e91964bbd4d118601f2c4204d1a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc77f9333077442bba1c6807d6a38f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "332c6170b74c45a79778da0ff95bed16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61d45f8442604f259361aab962db0ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658dc48718e74dde94f2845839aee494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00686bdb7f2f4b859d6f3b75a4d52189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_374175c659f9467bbe277863b961e7d2",
              "IPY_MODEL_7adb45bdb2644e48ae97ad19c34c72e6",
              "IPY_MODEL_08133c800ddc4f8b942bc2fc30341339"
            ],
            "layout": "IPY_MODEL_6330b002abd84c95b118d7f711760937"
          }
        },
        "374175c659f9467bbe277863b961e7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6caec3a0322946429c7b00f5ae0e366e",
            "placeholder": "​",
            "style": "IPY_MODEL_afc9ca91a5984bafa33a177babea95a0",
            "value": "tokenizer.json: 100%"
          }
        },
        "7adb45bdb2644e48ae97ad19c34c72e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d435ded4114b0393ee482323deb7cd",
            "max": 2480617,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9b0b900c9a34dd894ff96f4147f77f9",
            "value": 2480617
          }
        },
        "08133c800ddc4f8b942bc2fc30341339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17bfc1853fc643cebdbc5ec19c92a684",
            "placeholder": "​",
            "style": "IPY_MODEL_ee0cb84e7f264fbab793a07b3a6f476d",
            "value": " 2.48M/2.48M [00:00&lt;00:00, 15.8MB/s]"
          }
        },
        "6330b002abd84c95b118d7f711760937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6caec3a0322946429c7b00f5ae0e366e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc9ca91a5984bafa33a177babea95a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76d435ded4114b0393ee482323deb7cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b0b900c9a34dd894ff96f4147f77f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17bfc1853fc643cebdbc5ec19c92a684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0cb84e7f264fbab793a07b3a6f476d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7abab0a5240e43cd97837ee2cb846f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ab75dadc4ee4e98ae25023c5ae073aa",
              "IPY_MODEL_f39c482566d54a47b7c10ffff0485105",
              "IPY_MODEL_3d9ca7192a1248cf8a70f6fa22d73f7f"
            ],
            "layout": "IPY_MODEL_117e4e10fd2f47d2983226e47c840aa3"
          }
        },
        "8ab75dadc4ee4e98ae25023c5ae073aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78bdf215bf064c3ba963bf830c4102ca",
            "placeholder": "​",
            "style": "IPY_MODEL_1b5964f616b14c5a83c57baa798abe55",
            "value": "vocabulary.json: 100%"
          }
        },
        "f39c482566d54a47b7c10ffff0485105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e84d5a69ece54549a8925f993a90761c",
            "max": 1068114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4aee9d493a444b16a86d5c66be62be59",
            "value": 1068114
          }
        },
        "3d9ca7192a1248cf8a70f6fa22d73f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d0dec0ba40486fa2954ff401c84bff",
            "placeholder": "​",
            "style": "IPY_MODEL_8e02f050833b4c63961df97e7ef9ab5f",
            "value": " 1.07M/1.07M [00:00&lt;00:00, 4.61MB/s]"
          }
        },
        "117e4e10fd2f47d2983226e47c840aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78bdf215bf064c3ba963bf830c4102ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b5964f616b14c5a83c57baa798abe55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e84d5a69ece54549a8925f993a90761c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aee9d493a444b16a86d5c66be62be59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7d0dec0ba40486fa2954ff401c84bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e02f050833b4c63961df97e7ef9ab5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3d98d94ee72407ebe570dbbd495b9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1390a2b0f956434498d57f98790fa399",
              "IPY_MODEL_7ecac59d0b934713a772712d0c3b5129",
              "IPY_MODEL_6880ef28c23840be85315ed0c1a47cbf"
            ],
            "layout": "IPY_MODEL_79132f46cf394bfe8d3e144c6a63fa9a"
          }
        },
        "1390a2b0f956434498d57f98790fa399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ccc3f18ad134783a8978263cc692d3d",
            "placeholder": "​",
            "style": "IPY_MODEL_eccc61f20e204cc2810fef5102a1a077",
            "value": "config.json: 100%"
          }
        },
        "7ecac59d0b934713a772712d0c3b5129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704dbfe9a5d941c0b4597c85a08d2d62",
            "max": 914,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4cafeaf3b094a4ca7ada27cb9c98327",
            "value": 914
          }
        },
        "6880ef28c23840be85315ed0c1a47cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e26ed8701857483a9e1992960c305db0",
            "placeholder": "​",
            "style": "IPY_MODEL_c116d0f4cc68493486ccd380da608675",
            "value": " 914/914 [00:00&lt;00:00, 40.3kB/s]"
          }
        },
        "79132f46cf394bfe8d3e144c6a63fa9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ccc3f18ad134783a8978263cc692d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eccc61f20e204cc2810fef5102a1a077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "704dbfe9a5d941c0b4597c85a08d2d62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4cafeaf3b094a4ca7ada27cb9c98327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e26ed8701857483a9e1992960c305db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c116d0f4cc68493486ccd380da608675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7180bd96e91a4281b366c15291a371cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a88b1f3ea5147d390d1031a890a54dc",
              "IPY_MODEL_51a264e931d44c5db1d57b6351c5fd67",
              "IPY_MODEL_4c2abf39e41c4bd5a9430fb85b29f46d"
            ],
            "layout": "IPY_MODEL_f44fe46c258146349022f098057d31b2"
          }
        },
        "1a88b1f3ea5147d390d1031a890a54dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a69cd19bed34612af2fd1d1581db520",
            "placeholder": "​",
            "style": "IPY_MODEL_0905e35a537a44819bcbaef1131e2610",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "51a264e931d44c5db1d57b6351c5fd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b52ef0dd1e4538b3239b4af5f68a08",
            "max": 1109901745,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_578e15741dbd4637b751fd1bb80abfe3",
            "value": 1109901745
          }
        },
        "4c2abf39e41c4bd5a9430fb85b29f46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9616bc2c570f446cb7248e2e1869da8c",
            "placeholder": "​",
            "style": "IPY_MODEL_c35924d6fbd74b778a042aa182fbb6c6",
            "value": " 1.11G/1.11G [00:20&lt;00:00, 95.1MB/s]"
          }
        },
        "f44fe46c258146349022f098057d31b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a69cd19bed34612af2fd1d1581db520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0905e35a537a44819bcbaef1131e2610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1b52ef0dd1e4538b3239b4af5f68a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "578e15741dbd4637b751fd1bb80abfe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9616bc2c570f446cb7248e2e1869da8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c35924d6fbd74b778a042aa182fbb6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "379d6729a2de4a329f6dde411a986620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fe3a5a1e0f340eb9a0e11bf4b1dbac5",
              "IPY_MODEL_809547a8d51649ea89825a1d9df09a4a",
              "IPY_MODEL_b26a5ff87a2d4cc794060ccdfac9bf90"
            ],
            "layout": "IPY_MODEL_71f57869685c485ca740c47920e318b6"
          }
        },
        "3fe3a5a1e0f340eb9a0e11bf4b1dbac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40d5c45643204d08805fe89ae7f2894d",
            "placeholder": "​",
            "style": "IPY_MODEL_d624ba17fd5c4e59bed0e45e92416d8b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "809547a8d51649ea89825a1d9df09a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6af5795fe68644c0b5f62994faef8655",
            "max": 447,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd4b5b9282a54dff9e68b20cbefa3a95",
            "value": 447
          }
        },
        "b26a5ff87a2d4cc794060ccdfac9bf90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2696610f048048e5a560762874e64b43",
            "placeholder": "​",
            "style": "IPY_MODEL_2081e91e173744278f397ae337e2ed28",
            "value": " 447/447 [00:00&lt;00:00, 26.0kB/s]"
          }
        },
        "71f57869685c485ca740c47920e318b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d5c45643204d08805fe89ae7f2894d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d624ba17fd5c4e59bed0e45e92416d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6af5795fe68644c0b5f62994faef8655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd4b5b9282a54dff9e68b20cbefa3a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2696610f048048e5a560762874e64b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2081e91e173744278f397ae337e2ed28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db204e6359b44ee78642239ba937907c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_027416c57ea4407ab9333f8097677d83",
              "IPY_MODEL_42a10a6a84574a13b2aef562ddb59e3a",
              "IPY_MODEL_06fdaa2461ca4ccc8b3d77eb15c34d34"
            ],
            "layout": "IPY_MODEL_497e8eda188642f999c933ce8088aca1"
          }
        },
        "027416c57ea4407ab9333f8097677d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2e9041aba554c0098ca149cdcaef9fe",
            "placeholder": "​",
            "style": "IPY_MODEL_9b1916de0cbd4efebb93c6c877da88e3",
            "value": "tokenizer.json: 100%"
          }
        },
        "42a10a6a84574a13b2aef562ddb59e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b813ed98a5d49f5995345ded187b313",
            "max": 17082758,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23a0caa93574420f80d2bf09be09c5a5",
            "value": 17082758
          }
        },
        "06fdaa2461ca4ccc8b3d77eb15c34d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_215ed2c72e3445a2a09092edd35fd4ea",
            "placeholder": "​",
            "style": "IPY_MODEL_e72cf8b1d50b44eaacbd61cd8b6d2d8e",
            "value": " 17.1M/17.1M [00:02&lt;00:00, 7.79MB/s]"
          }
        },
        "497e8eda188642f999c933ce8088aca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2e9041aba554c0098ca149cdcaef9fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b1916de0cbd4efebb93c6c877da88e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b813ed98a5d49f5995345ded187b313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a0caa93574420f80d2bf09be09c5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "215ed2c72e3445a2a09092edd35fd4ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72cf8b1d50b44eaacbd61cd8b6d2d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31134006548540cc8c3aaf6b40d73234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb5630b1369547e2b6e4baa967002010",
              "IPY_MODEL_2642168b4cba44e89c75a5acb06a25ad",
              "IPY_MODEL_6d3d27c6ea7a4f0b85d659852c2d7d79"
            ],
            "layout": "IPY_MODEL_4ad6c223e75449ddaf08ba62c6c940a8"
          }
        },
        "fb5630b1369547e2b6e4baa967002010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6fb36156bfc4df990e4d410eccc748b",
            "placeholder": "​",
            "style": "IPY_MODEL_7deca142ac6e4a10995b3631fd2779b0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "2642168b4cba44e89c75a5acb06a25ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_064f239408a3481b95a5a6c5cd43dd50",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_506f335658734e949746b8e62206e426",
            "value": 239
          }
        },
        "6d3d27c6ea7a4f0b85d659852c2d7d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a99d6c9b45b4cf69d553c6b11cbba75",
            "placeholder": "​",
            "style": "IPY_MODEL_80a48693c1aa438c90fb7af83111d284",
            "value": " 239/239 [00:00&lt;00:00, 12.7kB/s]"
          }
        },
        "4ad6c223e75449ddaf08ba62c6c940a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6fb36156bfc4df990e4d410eccc748b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7deca142ac6e4a10995b3631fd2779b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "064f239408a3481b95a5a6c5cd43dd50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "506f335658734e949746b8e62206e426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a99d6c9b45b4cf69d553c6b11cbba75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a48693c1aa438c90fb7af83111d284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}